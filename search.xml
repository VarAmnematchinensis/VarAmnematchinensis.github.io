<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>PyTorch基础教程及注意事项-基础篇</title>
      <link href="/2025/08/25/PyTorch%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B%E5%8F%8A%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9-%E5%9F%BA%E7%A1%80%E7%AF%87/"/>
      <url>/2025/08/25/PyTorch%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B%E5%8F%8A%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9-%E5%9F%BA%E7%A1%80%E7%AF%87/</url>
      
        <content type="html"><![CDATA[<h2 id="PyTorch安装和环境准备"><a href="#PyTorch安装和环境准备" class="headerlink" title="PyTorch安装和环境准备"></a>PyTorch安装和环境准备</h2><p>PyTorch下载地址：<a href="https://pytorch.org/">https://pytorch.org/</a></p><ol><li>pytorch可以同时安装GPU（CUDA）和CPU版本，使用时需要注意，不同版本pytorch不能安装在同一个Python解释器下，否则会报错。可以尝试一个安装在本地Python解释器下，另一个使用Anaconda Prompt安装在Anaconda环境中。</li><li>如果发现安装的cuda版本在pytorch中不存在预构建二进制文件，可以手动先安装低版本，例如电脑安装的是12.2版本cuda，pytorch可以先安装11.8版本，最后使用Pytorch命令检查按照按照的pytorch版本和cuda版本。</li></ol><h2 id="Anaconda专门环境配置"><a href="#Anaconda专门环境配置" class="headerlink" title="Anaconda专门环境配置"></a><a href="https://anaconda.org.cn/">Anaconda</a>专门环境配置</h2><p>介绍：数据科学和机器学习软件套装<br>环境管理功能：使用cnnda包管理器，在管理软件包的同时，可以创建管理不同的Python环境<br><a href="https://docs.conda.org.cn/projects/conda/en/stable/user-guide/tasks/manage-environments.html">常用环境管理命令</a>：</p><table><thead><tr><th>方法</th><th>conda命令</th></tr></thead><tbody><tr><td>创建新环境</td><td>conda create –name 环境名称</td></tr><tr><td>创建指定版本环境</td><td>conda create –name 环境名称 Python &#x3D; 版本号</td></tr><tr><td>激活环境</td><td>conda activate 环境名称</td></tr><tr><td>退出当前环境</td><td>deactivate</td></tr><tr><td>查看所有已创建环境</td><td>conda env list</td></tr><tr><td>复制环境</td><td>conda create –name 复制后环境新名 –clone 环境名</td></tr><tr><td>删除环境</td><td>conda env remove –name 环境名</td></tr><tr><td>查看帮助</td><td>conda –help</td></tr></tbody></table><p><a href="https://docs.conda.org.cn/projects/conda/en/stable/user-guide/tasks/manage-pkgs.html">常用包管理命令</a>：</p><table><thead><tr><th>方法</th><th>conda命令</th></tr></thead><tbody><tr><td>安装包</td><td>conda install 包名</td></tr><tr><td>安装指定版本包</td><td>conda install 包名 &#x3D; 版本号</td></tr><tr><td>更新包</td><td>conda update 包名</td></tr><tr><td>卸载包</td><td>conda remove 包名</td></tr><tr><td>查看已安装包</td><td>conda list</td></tr><tr><td>搜索包</td><td>conda search 包名</td></tr><tr><td>清理conda缓存，删除不需要使用的包</td><td>conda clean –all</td></tr><tr><td>查看conda版本</td><td>conda –version</td></tr></tbody></table><h2 id="PyTorch"><a href="#PyTorch" class="headerlink" title="PyTorch"></a>PyTorch</h2><p>介绍：动态计算图、可自动微分、张量计算、多语言多设备支持的开源Python深度学习框架，基于torch库，底层由C++实现<br>结构（从上到下）：  </p><ol><li>PyTorch生态系统（专业库）：  <ul><li><a href="https://docs.pytorch.org/vision/stable/index.html">torchvision</a>:用于计算机视觉的数据集和模型  </li><li><a href="https://docs.pytorch.org/text/stable/index.html">torchtext</a>:用于自然语言处理的数据集和模型  </li><li><a href="https://docs.pytorch.org/audio/stable/index.html">torchaudio</a>:用于音频处理的数据集和模型</li></ul></li><li>PyTorch核心：  <ul><li><a href="https://docs.pytorch.org/docs/stable/pytorch-api.html">PyTorch API</a>(顶层):开发者直接调用接口<br> torch: 张量核心计算<br> torch.nn:构建神经网络<br> torch.autograd: 自动微分，反向传播  </li><li><a href="https://docs.pytorch.org/cppdocs/">C++核心</a>（中层）：高性能计算，沟通Python代码和底层硬件<br> ATen: 基础张量和数学运算核心库<br> JIT: 即时编译优化模型，编译器和解释器的接口<br> Autograd引擎：自动微分计算引擎，增强ATen库  </li><li>基础层（底层）：直接操作硬件，实现高速优化<br> TN&#x2F;THNN: C&#x2F;C++实现的基础张量和神经网络操作库，非常底层<br> THC&#x2F;THCUNN: 对应模块的CUDA实现</li></ul></li><li>PyTorch运算流程：python代码-&gt;Python API接口-&gt;C++核心计算-&gt;底层CUDA&#x2F;C库加速计算-&gt;返回结果。</li></ol><h2 id="张量（Tensor）"><a href="#张量（Tensor）" class="headerlink" title="张量（Tensor）"></a>张量（Tensor）</h2><p>定义：数据核心表示形式，类似于NumPy多维数组，数据可存储在CPU&#x2F;GPU等计算设备<br>组成：  </p><ul><li>维度(Dimensionality)：定义张量的多维数组结构  </li><li>形状(shape)：定义张量每个维度的大小  </li><li>数据类型(Dtype)：定义张量上每个元素存储所需的内存大小和解释方式，包括整理、浮点型和布尔型。<br>张量属性&#x2F;方法工具如下：</li></ul><table><thead><tr><th>方法属性</th><th>说明</th></tr></thead><tbody><tr><td>.shape&#x2F;.size()</td><td>获取张量形状</td></tr><tr><td>.dtype</td><td>获取张量数据类型</td></tr><tr><td>.device</td><td>查看张量所在计算设备(CPU&#x2F;GPU)</td></tr><tr><td>.dim()</td><td>获取张量的维度数</td></tr><tr><td>.requires_grad</td><td>判断张量是否使用梯度计算</td></tr><tr><td>.numel()</td><td>获取张量元素总数</td></tr><tr><td>.is_cuda</td><td>判断张量是否在GPU上</td></tr><tr><td>.T</td><td>获取张量转置（二维及以下张量）</td></tr><tr><td>.item()</td><td>获取单元素张量值</td></tr><tr><td>.is_contiguous()</td><td>检查张量是否连续存储</td></tr><tr><td>.view(shape)&#x2F;.reshape(shape)</td><td>在不改变数据的情况下，改变张量形状</td></tr><tr><td>.unsqueeze(dim)</td><td>在指定维度添加一个维度</td></tr><tr><td>.squeeze(dim)</td><td>去掉指定维度为1的维度</td></tr><tr><td>.numpy()</td><td>将张量转换为Numpy数组,仅限CPU张量， 数组和张量共享内存，修改数据互相影响</td></tr><tr><td>.clone()</td><td>数据克隆，深复制，可存放在新内存地址中</td></tr><tr><td>.flatten()</td><td>张量展平，构成一维向量</td></tr><tr><td>Tensor创建</td><td></td></tr><tr><td>torch.tensor(data)</td><td>从Python列表和numpy数组中创建张量</td></tr><tr><td>torch.as_tensor(data)</td><td>数据转换为张量（共享内存）</td></tr><tr><td>torch.zeros(size)</td><td>创建全为零的张量</td></tr><tr><td>torch.ones(size)</td><td>创建全为1的张量</td></tr><tr><td>torch.empty(size)</td><td>创建未初始化的张量</td></tr><tr><td>torch.eye(size)</td><td>创建单位矩阵</td></tr><tr><td>torch.full(size, fill_value)</td><td>创建填充指定值的张量</td></tr><tr><td>torch.manual_seed(seed)</td><td>设置随机数种子</td></tr><tr><td>torch.initial_seed()</td><td>返回当前随机种子</td></tr><tr><td>torch.rand(size)</td><td>创建服从均匀分布的随机张量，值为[0, 1]</td></tr><tr><td>torch.randn(size)</td><td>创建服从标准正态分布的随机张量</td></tr><tr><td>torch.randint(low, high, size)</td><td>创建整数随机张量</td></tr><tr><td>torch.randperm(n)</td><td>创建0到n-1的随机配列</td></tr><tr><td>torch.arange(start, end, step)</td><td>创建一维序列张量，类似Python的range函数</td></tr><tr><td>torch.linspace(start, end, steps)</td><td>创建指定范围内等间隔序列张量</td></tr><tr><td>torch.logspace(start, end, steps)</td><td>创建对数间隔序列张量</td></tr><tr><td>torch.form_numpy(ndarray)</td><td>Numpy数组转换为张量，数组和张量共享内存，修改数据互相影响</td></tr><tr><td>Tensor操作</td><td></td></tr><tr><td>torch.stack()</td><td>沿着新维度堆叠张量</td></tr><tr><td>torch.cat((x, y), dim)</td><td>指定维度连接多个张量</td></tr><tr><td>torch.matmul(x, y)&#x2F;torch.mm(input, mat2)</td><td>矩阵乘法</td></tr><tr><td>torch.bmm(input, mat2)</td><td>批量矩阵乘法</td></tr><tr><td>torch.eig(input)</td><td>计算矩阵特征值和特征向量</td></tr><tr><td>torch.svd(input)</td><td>计算矩阵的奇异值分解</td></tr><tr><td>torch.inverse(input)</td><td>计算矩阵的逆</td></tr><tr><td>torch.det(input)</td><td>计算矩阵的行列式</td></tr><tr><td>torch.trance(input)</td><td>计算矩阵的迹</td></tr><tr><td>torch.dot(x, y)</td><td>向量点积（仅适用于一维张量）</td></tr><tr><td>torch.abs(x)</td><td>求绝对值</td></tr><tr><td>torch.sqrt(x)</td><td>求平方根</td></tr><tr><td>torch.pow(x)</td><td>求幂运算</td></tr><tr><td>torch.exp(x)</td><td>求指数函数</td></tr><tr><td>torch.log(x)</td><td>求自然对数</td></tr><tr><td>torch.sum(x)</td><td>求和</td></tr><tr><td>torch.mean(x)</td><td>求均值</td></tr><tr><td>torch.max(x)</td><td>求最大值</td></tr><tr><td>torch.min(x)</td><td>求最小值</td></tr><tr><td>torch.clamp(input, min, max)</td><td>张量限制在指定范围内</td></tr><tr><td>torch.round(input)</td><td>近似，四舍五入</td></tr><tr><td>torch.floor(input)</td><td>向下取整</td></tr><tr><td>torch.ceil(input)</td><td>向上取整</td></tr><tr><td>torch.argmax(x, dim)</td><td>返回指定维度下的最大值对应索引</td></tr><tr><td>torch.softmax(x, dim)</td><td>计算指定维度下的softmax</td></tr><tr><td>torch.meshgrid()</td><td>生成网络，可用于生成坐标</td></tr><tr><td>注意：</td><td></td></tr></tbody></table><ol><li>共享内存的使用，典型如张量和Numpy数组之间的转化存在共享内存，张量形状的改变也存在共享内存，共享内存存在数据互相影响。  </li><li>张量和Numpy有转换，是因为二者有相似的内存结构，所以有内置方法直接转换。如果pytorch中Tensor和pandas里的DataFrame进行转换，需要通过Numpy作为中间步骤实现。</li></ol><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] <a href="https://study.163.com/course/introduction/1208894818.htm">深度学习与PyTorch入门实战</a><br>[2] Zhang, A., Lipton, Z. C., Li, M., &amp; Smola, A. J. (2023). <a href="https://zh.d2l.ai/index.html">Dive into Deep Learning</a>. Cambridge University Press. URL: <a href="https://d2l.ai/">https://D2L.ai</a><br>[3] <a href="https://github.com/dragen1860/Deep-Learning-with-PyTorch-book">PyTorch深度学习</a><br>[4] <a href="https://www.runoob.com/pytorch/pytorch-tutorial.html">菜鸟教程</a><br>[5] <a href="https://datawhalechina.github.io/thorough-pytorch/index.html#">深入浅出PyTorch</a></p>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
            <tag> 算法 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> PyTorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorch基础教程及注意事项-数据和模型篇</title>
      <link href="/2025/08/25/PyTorch%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B%E5%8F%8A%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9-%E6%95%B0%E6%8D%AE%E5%92%8C%E6%A8%A1%E5%9E%8B%E7%AF%87/"/>
      <url>/2025/08/25/PyTorch%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B%E5%8F%8A%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9-%E6%95%B0%E6%8D%AE%E5%92%8C%E6%A8%A1%E5%9E%8B%E7%AF%87/</url>
      
        <content type="html"><![CDATA[<h2 id="数据ETL-提取、转换、加载"><a href="#数据ETL-提取、转换、加载" class="headerlink" title="数据ETL(提取、转换、加载)"></a>数据ETL(提取、转换、加载)</h2><p>数据集：  </p><ol><li>内置数据集：<br>  定义： PyTorch生态系统（专业库）中内置的常用数据集<br>  <a href="https://docs.pytorch.org/vision/stable/index.html">torchvision</a>:用于计算机视觉常用数据集<br>  torchvision.datasets 内部常用数据集</li></ol><table><thead><tr><th>数据集</th><th>名称</th><th>下载加载命令</th><th>数据量</th><th>用途</th></tr></thead><tbody><tr><td>MNIST</td><td>手写数字图像数据集</td><td>torchvision.datasets.MNIST(root, train, download, transform)</td><td>7万张手写数字0-9的灰度图像，其中，6万张用于训练，1万张用于测试。每张图像的大小为28×28像素</td><td>图像分类</td></tr><tr><td>CIFAR-10</td><td>彩色图像数据集</td><td>torchvision.datasets.CIFAR10(root, train, download, transform)</td><td>10个类别、每个类别有6000张图像，总共有5万张训练图像和1万张测试图像，6万张32×32像素彩色图像</td><td>图像分类</td></tr><tr><td>COCO</td><td>通用物体检测、分割、关键点检测数据集</td><td>torchvision.datasets.CocoCaptions(root, anaFile, transform)</td><td>33 万张图像、150 万目标实例、80 个目标类、91 个物品类以及 25 万关键点人物</td><td>图像分割</td></tr><tr><td>ImageNet</td><td>经典图像数据集</td><td>torchvision.datasets.ImageNet(root, split, transform, loader)</td><td>120万张训练图像，5万张验证图像和10万张测试图像</td><td>图像分类和物体检测</td></tr><tr><td>STL-10</td><td>彩色图像数据集</td><td>torchvision.datasets.STL10(root, split, download, transform)</td><td>10个类组成，总共约6000+张96*96像素图像</td><td>图像识别</td></tr><tr><td>Cityscapes</td><td>城市街道场景图像</td><td>torchvision.datasets.Cityscapes(root, split, mode, transform)</td><td>50 个不同城市街景中记录的视频序列，其包含 20000 个弱注释帧和 5000 帧的高质量像素级</td><td>城市街景语义理解</td></tr></tbody></table><ol start="2"><li>自定义数据集：<br>  工具：torch.utils.data.Dataset抽象类,从自己的数据源创建自定义数据集。<br>  用法：需要继承该抽象类，并实现如下方法：<strong>len</strong>(self)(返回数据集中的样本数量)，<strong>getitem</strong>(self, idx)(通过索引返回样本)</li><li>外置数据集：一般是外部数据库，可以使用<a href="https://www.psycopg.org/docs/">psycopg2</a>等模块</li></ol><table><thead><tr><th>数据库</th><th>模块工具</th><th>数据库驱动包</th></tr></thead><tbody><tr><td>GaussDB(DWS)</td><td><a href="https://support.huaweicloud.com/mgtg-dws/dws_01_0120.html">psycopg2</a>&#x2F;<a href="https://support.huaweicloud.com/mgtg-dws/dws_01_0171.html">PyGreSQL</a>&#x2F;psycopg2-binary</td><td>可使用开源驱动JDBC&#x2F;ODBC</td></tr><tr><td>GaussDB</td><td>psycopg2</td><td><a href="https://support.huaweicloud.com/distributed-devg-v8-gaussdb/gaussdb-12-0155.html">Psycopg</a></td></tr><tr><td>Opengauss</td><td>psycopg2</td><td><a href="https://docs.opengauss.org/zh/docs/6.0.0/docs/DeveloperGuide/%E5%8A%A0%E8%BD%BD%E9%A9%B1%E5%8A%A8_Psycopg.html">Psycopg</a></td></tr><tr><td>PostgreSQL</td><td>psycopg2&#x2F;psycopg3</td><td>Python模块工具安装后，不需要再单独在pg库侧安装驱动包</td></tr></tbody></table><ol start="4"><li>使用注意：</li></ol><ul><li>规格不同按需适配|使用时需要注意模块、模块接口、Python和数据库版本限制  </li><li>使用时需要注意防火墙等限制，防火墙即可以阻止下载，也可以阻止连接，一般会导致连接超时报错。  </li><li>账号密码和数据库配置等信息一般是单独放置，加密保存，可以使用Python模块Crypto、cryptodome或者<a href="https://www.cnblogs.com/zzkkk1h/p/18117606">pycryptodomex</a>库中的加解密方法，获取使用信息。  </li><li>除了使用连接模块psycopg2的psycopg2.connect()连接数据库外，还可以使用<a href="https://blog.csdn.net/xc_zhou/article/details/80893289">DBUtils.PooledDB</a>包（管理数据库连接池）连接数据库，DBUtils.PooledDB包使用的时候，需要和psycopg2或者importlib一起配合使用。</li></ul><h2 id="数据加载、处理和转换"><a href="#数据加载、处理和转换" class="headerlink" title="数据加载、处理和转换"></a>数据加载、处理和转换</h2><ol><li>数据加载器：<a href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader">torch.utils.data.DataLoader</a>，从数据集中按批次加载数据，支持多线程加载加速和数据打乱。</li></ol><ul><li>关键参数：torch.utils.data.DataLoader(dataset，batch_size, shuffle，num_workers，drop_last) <ul><li>batch_size: int类型的数据， 每次加载样本的数量，如默认设置为1，那就是一行一行的喂数据给模型，效率比较慢  </li><li>shuffle: bool数据类型， 是否需要对数据进行洗牌（通常用于训练时将数据打乱使用），如果数据有规律特征（顺序或倒序），则不应该设置为True.  </li><li>num_workers：int类型的数据，默认为0，表示使用主进程导入数据，非负数表示使用多少子进程导入数据。  </li><li>drop_last:bool数据类型, 默认为False，和batch_size配合使用，可用于数据集中不能被batch_size整除中，确认是否丢弃最后一批数据。</li></ul></li></ul><ol start="2"><li>多数据源加载：<a href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader">torch.utils.data.ConcatDataset</a>，自定义加载多数据源，可以将多数据源合并为一个数据集。</li></ol><h2 id="数据转换"><a href="#数据转换" class="headerlink" title="数据转换"></a>数据转换</h2><ol><li>目的：将原始数据转换为适合模型训练的数据格式  </li><li>组成：</li></ol><ul><li>数据预处理：数据归一化，调整数据格式、大小和数据范围，使其适合模型输入。  </li><li>数据增强：在训练时对数据做变换，例如随机剪裁&#x2F;翻转等，提高模型泛化能力，避免过拟合。</li></ul><ol start="3"><li>一般工具：torchvision视觉库，torchvision.transfroms工具，以下是典型数据转换和增强操作：<br>  基础数据变换操作</li></ol><table><thead><tr><th>函数</th><th>用途</th><th></th></tr></thead><tbody><tr><td>torchvision.transfroms.Compose()</td><td>多变换操作组合，按照顺序依次执行</td><td></td></tr><tr><td>torchvision.transfroms.Resize()</td><td>调整图像大小，保证输入到网络的图像大小一致</td><td></td></tr><tr><td>torchvision.transfroms.ToTensor()</td><td>图像转化为Tensor张量，像素数值归一化为[0,1]范围</td><td></td></tr><tr><td>torchvision.transfroms.Normalize()</td><td>图像数据标准化，使数据符合特定均值和标准差</td><td></td></tr><tr><td>torchvision.transfroms.CenterCrop()</td><td>从图像中心剪裁指定大小区域</td><td></td></tr><tr><td></td><td></td><td></td></tr></tbody></table><p>数据增强操作</p><table><thead><tr><th>函数</th><th>用途</th></tr></thead><tbody><tr><td>torchvision.transfroms.RandomHorizontalFlip()</td><td>随机水平翻转图像</td></tr><tr><td>torchvision.transfroms.RandomRotation()</td><td>随机旋转图像一定角度</td></tr><tr><td>torchvision.transfroms.ColorJitter()</td><td>调整图像亮度、对比度、饱和度和色调</td></tr><tr><td>torchvision.transfroms.RandomCrop()</td><td>随机裁剪指定大小的区域</td></tr><tr><td>torchvision.transfroms.RandomResizeCrop()</td><td>随机裁剪图像并调整到指定大小</td></tr></tbody></table><h2 id="模型保存，加载和部署"><a href="#模型保存，加载和部署" class="headerlink" title="模型保存，加载和部署"></a>模型保存，加载和部署</h2><ol><li>功能：训练中断时恢复训练；在不同的训练阶段比较模型性能；方便模型部署和成员之间的模型共享；可用于迁移学习。  </li><li>类型：</li></ol><ul><li>保存整个模型：torch.save(model, path), 保存模型架构和所有参数。<br>  优势：完整保留模型结构<br>  劣势：文件体积大，对模型类的定义有依赖。  </li><li>保存模型参数：torch.save(model.dict(), path), 只保留模型的状态字典信息。<br>  优势：文件小，可加载到不同模型架构中，兼容性好<br>  缺点：过程繁琐，使用前需要每次先创建相同架构的模型。</li></ul><ol start="3"><li>注意事项：</li></ol><ul><li>保存命名：模型和参数的保存要按照架构要求和命名规范进行，要有意义。  </li><li>设置定期保存命令，最好是每隔几轮训练迭代就保存一次检查点，防止训练出现问题。  </li><li>在保存完成后，需要测试加载能力，确保保存的模型能正常加载使用。  </li><li>训练和保存过程中，由于比较耗时，可以在此期间将模型架构、训练参数等信息做文档保存，以备查阅。  </li><li>模型文件等材料放入Git&#x2F;svn&#x2F;Dbox&#x2F;代码仓的版本管理系统中，做版本管理。  </li><li>如果无法加载保存旧的版本模型，可以查阅文档，确定当时使用的Pytorch版本后再加载，或者转换模型的格式。</li></ul><h3 id="模型加载"><a href="#模型加载" class="headerlink" title="模型加载"></a>模型加载</h3><p>跨设备模型加载：  </p><ol><li>CPU或GPU加载：先保存模型参数到指定路径中，设定模型使用设备（torch.device(“cpu)）,再将模型参数加载到模型中（torch.load(参数路径，map_location &#x3D; ‘cpu)）,最后将模型转移到指定的模型使用设备上。  </li><li>多GPU模型加载：</li></ol><ul><li>目的：调度GPU，实现计算加速， GPU 并行计算（DataParallel 或 torch.distributed）  </li><li>GPU方法和函数清单：</li></ul><table><thead><tr><th>方法函数</th><th>说明</th></tr></thead><tbody><tr><td>torch.cuda.is_available</td><td>判断GPU是否可用</td></tr><tr><td>torch.device()</td><td>创建设备对象，可用于张量设置在GPU上</td></tr><tr><td>torch.to(device)</td><td>将张量移动到指定设备上</td></tr><tr><td>torch.device(‘cuda’ if torch.cuda.is_available() else ‘cpu’)</td><td>优先使用GPU计算，没有GPU情况下用CPU计算</td></tr><tr><td>注意事项：</td><td></td></tr></tbody></table><ol><li>在设定本次计算使用的工具时，使用torch.device(‘cpu’),cpu需要小写。  </li><li>在使用GPU运算时，要求模型和数据都要在GPU或者CPU同一个设备上。  </li><li>模型和输入数据使用的设备确定时，可以在模型之前设定，也可以在使用过程中设置，张量和模型必须在同一个设备上可以使用torch.to（）工具来转移。  </li><li>GPU中专用GPU内存和共享GPU内存的差别:专用GPU内存我们通常称为“显存”，就是显卡上独立专门的物理内存。而共享GPU内存是指从系统内存中单独划出，供GPU使用的内存，是显存的补充。可以在CUDA中显式管理共享内存。</li></ol><h3 id="分布式模型训练框架和工具："><a href="#分布式模型训练框架和工具：" class="headerlink" title="分布式模型训练框架和工具："></a>分布式模型训练框架和工具：</h3><ol><li>PyTorch原生分布式能力：<a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html">torch.DistributedDataParallel</a>、<a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.DataParallel.html">torch.DataParallel</a>、<a href="https://docs.pytorch.ac.cn/docs/stable/distributed.html">torch.distributed</a>，torch.DistributedDataParallel效率更高。</li></ol><ul><li>数据并行模式支持：PyTorch支持数据并行模式，不支持流水线、Tensor、混合和自动并行模式，其1.9.0以上版本支持ZeRO，可以用于torch.DistributedDataParallel的communicationhook调用。torch.DistributedDataParallel支持通讯优化。  </li><li>计算加速支持：可以使用torch.amp实现低精度训练（1.6以上版本，FP16精度）  </li><li>内存优化支持：可以使用torch.utils.checkpointing进行重计算</li></ul><ol start="2"><li><a href="https://docs.nvidia.com/nemo-framework/user-guide/24.07/nemotoolkit/nlp/megatron.html">NeMo- Megatron</a>:英伟达开发的分布式训练模型开源框架，支持数据并行和模型并行。  </li><li><a href="https://blog.csdn.net/zwqjoy/article/details/130732601">DeepSpeed</a>:微软开发的分布式训练模型开源框架，可以和NeMo- Megatron兼容，是目前主要使用的分布式训练工具。<br>  大模型分布式训练并行技术：<a href="https://zhuanlan.zhihu.com/p/598714869">https://zhuanlan.zhihu.com/p/598714869</a></li></ol><h3 id="模型转换"><a href="#模型转换" class="headerlink" title="模型转换"></a>模型转换</h3><ol><li>版本兼容性：在<a href="https://docs.pytorch.org/docs/stable/generated/torch.save.html">torch.save()</a>中使用_use_new_zipfile_serialization来确保好的兼容性,可以确保仍然能使用1.6版本之前的旧格式。  </li><li>格式转换：可以使用torch.jit.scipt()将模型转换为TorchScript格式，再使用torch.jit.save()和torch.jit.load()加载模型。  可以解决旧版本模型加载失败的问题。  </li><li>导出格式：</li></ol><table><thead><tr><th>格式</th><th>使用命令</th><th>特点</th><th>适用场景</th></tr></thead><tbody><tr><td><a href="https://docs.pytorch.ac.cn/docs/stable/jit.html">TorchScript</a></td><td>torch.jit.trace() torch.jit.script()</td><td>Pytorch原生格式，保持动态图特性</td><td>Pytorch生态内部</td></tr><tr><td><a href="https://docs.pytorch.ac.cn/docs/stable/onnx.html">ONNX</a></td><td>torch.onnx.export()</td><td>开发标准，跨框架兼容</td><td>多框架协同环境</td></tr><tr><td><a href="https://developer.nvidia.com/zh-cn/blog/accelerating-inference-up-to-6x-faster-in-pytorch-with-torch-tensorrt/">Torch-TensorRT</a></td><td><a href="https://docs.pytorch.ac.cn/TensorRT/">import torch_tensorrt</a></td><td>nvidia优化格式</td><td>GPU推理加速</td></tr></tbody></table><ol start="4"><li>注意事项：</li></ol><ul><li>TorchScript导出前要使用model.eval()调用模型，以转换模型模式状态为评估。</li></ul><h3 id="模型部署"><a href="#模型部署" class="headerlink" title="模型部署"></a>模型部署</h3><ol><li>目的：使用AI平台(<a href="https://support.huaweicloud.com/modelarts/index.html">ModelArts</a>)，通过API调用的方式，将AI能力整合到Web等系统中，供调用使用。  </li><li>一般部署流程：训练模型-》模型优化-》格式转换-》部署环境选择-》服务封装-》性能监控  </li><li>部署方式：</li></ol><ul><li>本地部署：ONNX部署，使用onnxruntime模块(ONNX Runtime 是由微软维护的一个跨平台机器学习推理加速器)，使用onnxruntime.InferenceSession()加载模型，创建推理会话，再使用onnxruntime.InferenceSession().run()执行推理  </li><li>云端部署（优先）：使用<a href="https://fastapi.tiangolo.com/zh/tutorial/#_1">fastapi</a>模块构建REST API，通过API接口调用。  <a href="https://www.runoob.com/fastapi/fastapi-install.html">fastapi</a>工具使用。</li></ul><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] <a href="https://study.163.com/course/introduction/1208894818.htm">深度学习与PyTorch入门实战</a><br>[2] Zhang, A., Lipton, Z. C., Li, M., &amp; Smola, A. J. (2023). <a href="https://zh.d2l.ai/index.html">Dive into Deep Learning</a>. Cambridge University Press. URL: <a href="https://d2l.ai/">https://D2L.ai</a><br>[3] <a href="https://github.com/dragen1860/Deep-Learning-with-PyTorch-book">PyTorch深度学习</a><br>[4] <a href="https://www.runoob.com/pytorch/pytorch-tutorial.html">菜鸟教程</a><br>[5] <a href="https://datawhalechina.github.io/thorough-pytorch/index.html#">深入浅出PyTorch</a></p>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据 </tag>
            
            <tag> AI </tag>
            
            <tag> 算法 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> PyTorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorch基础教程及注意事项-神经网络篇</title>
      <link href="/2025/08/25/PyTorch%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B%E5%8F%8A%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AF%87/"/>
      <url>/2025/08/25/PyTorch%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B%E5%8F%8A%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AF%87/</url>
      
        <content type="html"><![CDATA[<h2 id="神经网络模型"><a href="#神经网络模型" class="headerlink" title="神经网络模型"></a>神经网络模型</h2><p>定义：模仿人脑的计算模型，由连接节点（神经元）组成，节点按照层次排列</p><ul><li>神经元（Neuron）:<ul><li>定义：神经网络基本单元，由输入（Input）、’权重（weights）、偏置(bias)、求和函数(summation function)、阈值(activation potential)、激活函数(activation function)、输出（output）构成。</li><li>用途：接收输入数据(起始点，特征向量)，将输入数据加权求和与偏置相加，通过阈值和激活函数处理后，产生输出数据（终点，预测结果）。</li></ul></li><li>网络层（Layer）:<ul><li>定义：由多个神经元组成，神经元之间的连接密度和类型构造网络配置。</li><li>组成（最简）：输入层(Input Layer，接收输入数据)、隐藏层(Hidden Layer, 数据处理)、输出层(Output Layer, 产生输出结果)</li></ul></li></ul><h3 id="前馈神经网络-Feedforward-Neural-Networks-FNN"><a href="#前馈神经网络-Feedforward-Neural-Networks-FNN" class="headerlink" title="前馈神经网络(Feedforward Neural Networks, FNN)"></a>前馈神经网络(Feedforward Neural Networks, FNN)</h3><ol><li>定义：基础神经网络，数据从输入到输出单向流动</li><li>特点：数据从输入层开始，经过隐藏层计算，最后到达输出层输出预测结果，数据单向流动，全过程没有反馈和循环等方向操作。</li><li>结构：输入层（网络数据入口，每个节点代表一种输入特征）、隐藏层（每层由多个神经元构成，每个神经元通过激活函数体现其非线性能力，用于获取数据的非线性特征）、输出层（网络预测结果出口，其节点个数和问题有关）</li></ol><h3 id="卷积神经网络-Convolutional-Neural-Networks-CNN"><a href="#卷积神经网络-Convolutional-Neural-Networks-CNN" class="headerlink" title="卷积神经网络(Convolutional Neural Networks, CNN)"></a>卷积神经网络(Convolutional Neural Networks, CNN)</h3><ol><li>定义：专门处理网络拓扑结构数据的神经网络模型，是机器视觉核心技术。可以使用卷积层提取空间特征</li><li>结构：</li></ol><ul><li>输入层（Input Layer）：原始数据图像入口，用于接收类似于图像的三维数组（图像高度、宽度和颜色通道）</li><li>卷积层(Convolutional Layer)：根据卷积公式，用卷积核(Kernel)提取局部特征，生成特征图。</li><li>非线性激活函数层(Activation Function)：引入非线性特征，增强网络适应性。</li><li>池化层(Pooling Layer)：在卷积层后，在保留最重要特征信息情况下，通过池化技术(最大池化-区域最大值&#x2F;平均池化-区域平均值)降低特征图空间维度，减少计算和参数数量，生成池化特征图。</li><li>归一化层（Normalization Layer, 可选）：采用归一化技术（局部响应归一化&#x2F;批归一化），使多维特征图转换为一维向量，加速训练，提高模型稳定性。</li><li>正则化（Regularization, 可选）：用于防止模型过拟合</li><li>损失函数层(Loss Function)：衡量模型预测和实际结果之间的差异。</li><li>优化器(Optimizer)：根据损失函数对参数的梯度更新模型参数。</li><li>全连接层(Fully Connected Layer)：用于综合所有提取的特征映射到输出，并进行最后的分类或回归</li><li>输出层(Output Layer)：模型预测结果出口</li></ul><h3 id="循环神经网络-Recurrent-Neural-Networks-RNN"><a href="#循环神经网络-Recurrent-Neural-Networks-RNN" class="headerlink" title="循环神经网络(Recurrent Neural Networks, RNN)"></a>循环神经网络(Recurrent Neural Networks, RNN)</h3><ol><li>定义：允许信息反馈循环，适用于序列数据（时间序列、语音识别、自然语言）</li><li>特点：“记忆能力”，使用隐状态(hidden state)，在隐藏层可以保留以前时间调用的信息，进而捕获数据中的时间等前后依赖关系</li><li>典型RNN模块：</li></ol><ul><li>torch.nn.RNN: 基本RNN单元</li><li>torch.nn.LSTM: 长短期记忆网络(Long short-Term Memory, LSTM)，RNN的变种，能学习长期依赖关系。</li><li>torch.nn.GRU: 门控循环单元，LSTM简化版本。</li></ul><h2 id="神经网络模型训练过程简介（Training-Process）"><a href="#神经网络模型训练过程简介（Training-Process）" class="headerlink" title="神经网络模型训练过程简介（Training Process）"></a>神经网络模型训练过程简介（Training Process）</h2><ol><li>数据ETL：</li></ol><ul><li>收集和处理数据，包括数据清洗、标准化和归一化。</li><li>数据分割，包括训练集、验证集和测试集</li></ul><ol start="2"><li>定义网络模型：</li></ol><ul><li>设计模型架构，在业务需求、设备支持、项目交付、行管规则等要求下，选择合适的模型，定义网络层、前向传播过程、激活函数等。</li><li>设置初始化模型参数（权重和偏置）</li><li>选择损失函数：根据问题特点选择合适的损失函数（分类或回归等）</li><li>选择优化器：根据需要选择优化算法，更新模型参数。</li></ul><ol start="3"><li>前向传播（Forward Propagation）：</li></ol><ul><li>在每次迭代中，根据输入数据通过模型传递，计算预测输出</li><li>开启训练前需要清除梯度，调整模型进入训练模式（model.train()）</li></ul><ol start="4"><li>计算损失(Calulate Loss)：</li></ol><ul><li>使用损失函数计算评估预测输出和实际输出之间的差异</li></ul><ol start="5"><li>反向传播(Backpropagation)：</li></ol><ul><li>利用自动求导计算损失函数相对于模型参数（权重和偏置）的梯度。</li><li>一般调度torch.nn.MSEloss().backward()等计算</li></ul><ol start="6"><li>参数更新(Parameter Update)：</li></ol><ul><li>调用优化器，根据计算出的梯度和优化器策略，更新模型参数。</li><li>一般通过optim.SGD().step()等更新参数。</li></ul><ol start="7"><li>迭代优化(Iteration)：</li></ol><ul><li>重新循环上述步骤，直到模型在验证集上是性能不能再提升，或者迭代达到预定次数。</li><li>此过程也是试算过程的开始，考虑到数据、方案、环境等因素的不完善，模型方案不一定有好的结果，需不断校验检查。</li></ul><ol start="8"><li>测试评估：</li></ol><ul><li>利用测试集评估模型性能，确保模型没有过拟合或者欠拟合</li><li>计算准确率(Accuracy):计算正确预测比例（分类问题）</li><li>测试评估前需要调整模型进入评估模式（model.eval()）,并且在评估过程中要禁用梯度计算（torch.no_grad(), 减少不必要的计算和内存开销）,以确保模型能正确推理。</li></ul><ol start="9"><li>模型调优：</li></ol><ul><li>根据模型在测试集上的表现调参，优化模型各项配置和参数。</li></ul><ol start="10"><li>部署模型：</li></ol><ul><li>将训练好的模型，根据部署平台的使用要求，部署到生产环境中，用于实际工作。</li></ul><h2 id="PyTorch神经网络工具字典"><a href="#PyTorch神经网络工具字典" class="headerlink" title="PyTorch神经网络工具字典"></a>PyTorch神经网络工具字典</h2><pre><code>关键模块：torch.nn（网络模块）、torch.optim（优化器模块）、 torch.autograd(自动微分)</code></pre><ol><li><a href="https://docs.pytorch.ac.cn/docs/stable/nn.html#module-torch.nn.parallel">torch.nn</a>模块组成：</li></ol><ul><li>关键类：torch.nn.Module类，是所有神经网络模块的基类，可以用来从这个基类派生出自己的模型类，并定义其中的网络层结构和前向传播过程。自定义神经网络模型时，需要定义这两部分：<strong>init</strong>()(定义网络层)、forward()(定义数据前向传播过程)</li><li>预定义层（Modules）:包含各种层组件，如卷积层、线性层、池化层、归一化层、循环神经网络层、嵌入层、Dropout层、非线性激活函数（Activation Function，决定神经元是否应该被激活）等</li><li>容器类(Containers)：由模块（torch.nn.Module）、序列(torch.nn.Sequential)、模块列表(torch.nn.ModuleList)、模块字典(torch.nn.ModuleDict)、参数列表(torch.nn.ParameterList)、参数字典(torch.nn.ParameterDict)组成。</li><li>损失函数（Loss Function）:衡量模型预测值和真实值之间的差异</li><li>实用函数（Functional Interface）：torch.nn.functional(作用于张量上的实现和层对象相同功能的函数)</li><li>初始化方法：torch.nn.init(权重初始化策略)</li></ul><ol start="2"><li>torch.nn常用组件：</li></ol><p>卷积层</p><table><thead><tr><th>组件</th><th>描述和特点</th></tr></thead><tbody><tr><td>torch.nn.Conv2d()</td><td>2D卷积层，常用于图像</td></tr></tbody></table><p>线性层</p><table><thead><tr><th>组件</th><th>描述和特点</th></tr></thead><tbody><tr><td>torch.nn.Linear(in_features，out_features)</td><td>输入in_features个特征，输出out_features个特征</td></tr></tbody></table><p>池化层</p><table><thead><tr><th>组件</th><th>描述和特点</th></tr></thead><tbody><tr><td>torch.nn.MaxPool2d()</td><td>2D最大池化层，常用于降维</td></tr></tbody></table><p>激活函数</p><table><thead><tr><th>组件</th><th>描述和特点</th></tr></thead><tbody><tr><td>torch.nn.functional.relu()</td><td>定义为f(x) &#x3D; max(0, x)，常用于隐藏层</td></tr><tr><td>torch.nn.functional.sigmoid()</td><td>输出值为0和1之间，适合二分类问题</td></tr><tr><td>torch.nn.functional.tanh()</td><td>输出值在-1和1之间，适合输出层使用</td></tr><tr><td>torch.nn.functional.softmax</td><td>将输出转换为概览分布，适用多分类的输出层</td></tr></tbody></table><p>损失函数</p><table><thead><tr><th>组件</th><th>描述和特点</th><th>适配场景</th></tr></thead><tbody><tr><td>torch.nn.MSELoss()</td><td>均方误差（L2范数），计算输出和目标值之间的平方差</td><td>回归问题</td></tr><tr><td>torch.nn.CrossEntropyLoss()</td><td>计算输出和目标值之间的交叉熵</td><td>分类问题</td></tr><tr><td>torch.nn.BCEWithLogitsLoss()</td><td>计算Sigmoid激活和二元交叉熵的损失</td><td>二分类问题</td></tr></tbody></table><ol start="3"><li><a href="https://docs.pytorch.ac.cn/docs/stable/optim.html">torch.optim</a></li></ol><ul><li>功能：根据损失函数的梯度，在训练过程中自动化更新网络模型参数（权重和偏置），在避免局部最优的情况下，参数加速收敛到最优解，进而使模型预测结果逐步优化逼近目标值。</li><li>优化器（Optimizer）选择判断：数据是否稀疏-&gt;是否需要快速收敛</li><li>常用优化器类型：</li></ul><table><thead><tr><th>优化器名称</th><th>中文名称</th><th>调度方法</th><th>收敛速度</th><th>内存占用</th><th>超参数敏感度</th><th>特点</th><th>适用场景</th></tr></thead><tbody><tr><td>SGD</td><td>随机梯度下降</td><td>torch.optim.SGD(params, lr &#x3D; 0.01, momentum &#x3D; 0, weight_decay &#x3D; 0)</td><td>慢</td><td>低</td><td>高</td><td>简单，可添加动量加速收敛，适合和基准比较，使用梯度的移动平均值（一阶矩）</td><td>基础简单模型</td></tr><tr><td>Adam</td><td>自适用矩估计</td><td>torch.optim.Adam(params, lr &#x3D; 0.001, betas &#x3D; (0.9, 0.999), eips &#x3D; 1e-08, amsgrad &#x3D; False)</td><td>快</td><td>中</td><td>低</td><td>可自适应学习率，可计算每个参数的学习率，结合SGD和RMSprop的特点</td><td>绝大多数的深度学习任务</td></tr><tr><td>RMSprop</td><td>均方根传递</td><td>torch.optim.RMSprop(params, lr &#x3D; 0.01, alpha &#x3D; 0.99)</td><td>快</td><td>中</td><td>中</td><td>适应学习率，使用平方梯度的移动平均值来缩放梯度（二阶矩）</td><td>RNN网络</td></tr><tr><td>Adagrad</td><td>自适应学习率应梯度下降</td><td>torch.optim.Adagrad(params, lr &#x3D; 0.01, initial_accumulator_value &#x3D; 0)</td><td>先快后慢</td><td>中</td><td>高</td><td>参数独立学习率，学习率随时间减小</td><td>稀疏数据</td></tr></tbody></table><p>4 <a href="https://docs.pytorch.ac.cn/docs/stable/autograd.html">torch.autograd</a></p><ul><li>功能：各种类和函数对任意标量函数计算数学函数的导数，主要用来自动计算梯度。深度学习自动求导主要用于在神经网络计算梯度和反向传播算法实现。</li></ul><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] <a href="https://study.163.com/course/introduction/1208894818.htm">深度学习与PyTorch入门实战</a><br>[2] Zhang, A., Lipton, Z. C., Li, M., &amp; Smola, A. J. (2023). <a href="https://zh.d2l.ai/index.html">Dive into Deep Learning</a>. Cambridge University Press. URL: <a href="https://d2l.ai/">https://D2L.ai</a><br>[3] <a href="https://github.com/dragen1860/Deep-Learning-with-PyTorch-book">PyTorch深度学习</a><br>[4] <a href="https://www.runoob.com/pytorch/pytorch-tutorial.html">菜鸟教程</a><br>[5] <a href="https://datawhalechina.github.io/thorough-pytorch/index.html#">深入浅出PyTorch</a></p>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
            <tag> 算法 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> PyTorch </tag>
            
            <tag> 神经网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>昇思MindSpore基础教程</title>
      <link href="/2025/08/18/%E6%98%87%E6%80%9DMindSpore%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/"/>
      <url>/2025/08/18/%E6%98%87%E6%80%9DMindSpore%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>全场景、深度学习计算框架，可支持CPU、GPU、华为AI昇腾系列处理器等硬件,可使用Linux、windows、MacOS系统。<br>教程目的：熟悉框架语法结构，熟悉从构建数据集到训练的全流程</p><h2 id="MindSpore安装"><a href="#MindSpore安装" class="headerlink" title="MindSpore安装"></a>MindSpore安装</h2><p><a href="https://www.mindspore.cn/install/#guide%5C">MindSpore安装</a><br>验证安装成功会显示如下信息：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">MindSpore version: 版本号</span><br><span class="line">The result of multiplication calculation is correct, MindSpore has been installed on platform [CPU] successfully!</span><br></pre></td></tr></table></figure><p>注意：<br>     - 版本选择2.7.0-rc1,选择2.6.0的时候会导致下载失败。<br>     - 下载请在管理员下的命令提示符下进行。</p><h2 id="Tensor-创建-属性-操作-NumPy"><a href="#Tensor-创建-属性-操作-NumPy" class="headerlink" title="Tensor: 创建-属性-操作-NumPy"></a>Tensor: 创建-属性-操作-NumPy</h2><p>张量（Tensor）是MindSpore中的基本数据结构，存储多维数组的数据结构。</p><ol><li>张量属性：形状(shape)和数据类型(dtype)<br> 形状：定义张量的维度，是tuple类型，使用张量.shape查看<br> 数据类型：使用张量.dtype查看，定义张量的数据类型和大小，包括基础数据类型、其他类型、类型转换规则，必须使用<a href="https://www.mindspore.cn/docs/zh-CN/r2.7.0rc1/api_python/mindspore/mindspore.dtype.html">mindspore.dtype</a>中定义的类型。</li><li>张量初始化：<ul><li>直接创建：mindspore.Tensor()。<a href="https://www.mindspore.cn/docs/zh-CN/r2.7.0rc1/api_python/mindspore/mindspore.Tensor.html">Tensor参考API文档</a></li><li>使用numpy创建：mindspore.Tensor(numpy.array())</li><li>从旧张量中创建新张量：mindspore.ops.OnesLike(Tensor())</li></ul></li><li>张量运算：涉及算术、线性代数、矩阵运算等。可使用类numpy的索引和切片使用方式，存在和pandas类似的连接(cancat)和合并使用方式.</li><li>与NumPy的数据转换：<ul><li>NumPy转换为Tensor: mindspore.Tensor(numpy.array())</li><li>Tensor转转换为NumPy：mindspore.Tensor.asnumpy(),Tensor和ndarray会共享内存地址。</li></ul></li><li>注意：<ul><li><p>使用前需要设置环境上下文，设置模式和目标设备类型，例如：</p></li><li><pre><code>from mindspore import contextcontext.set_context(mode=context.GRAPH_MODE, device_target=&quot;CPU&quot;)</code></pre><p>模式包括GRAPH_MODE（静态图模式）和PYNATIVE_MODE（动态图模式）两种。<br>目标设备类型包括CPU、GPU、Ascend(昇腾)</p></li><li><p><a href="https://www.mindspore.cn/docs/zh-CN/r2.7.0rc1/api_python/mindspore.ops.html#parameter%E6%93%8D%E4%BD%9C%E5%87%BD%E6%95%B0">mindspore.obs</a>提供function接口，涉及Tensor操作函数、数学运算函数、神经网络函数、微分函数、调试函数等。</p></li><li><p>使用时需要注意有些API函数中存在支持平台的限制，例如Ascend(昇腾)、GPU、CPU，有些函数只支持CPU或者GPU,有些实验性质的API只支持Ascend。</p></li><li><p>当使用 init 参数来初始化 Tensor 时，通常需要使用 Tensor.init_data 来加载 Tensor 的数据</p></li></ul></li></ol><h2 id="数据：创建-自定义-数据处理"><a href="#数据：创建-自定义-数据处理" class="headerlink" title="数据：创建-自定义-数据处理"></a>数据：创建-自定义-数据处理</h2><ol><li><a href="https://www.mindspore.cn/docs/zh-CN/r2.7.0rc1/api_python/mindspore.dataset.loading.html#%E9%87%87%E6%A0%B7%E5%99%A8-1">mindspore.dataset</a>：<br>性质：核心数据加载模块，基于Pipeline的数据引擎。<br>作用：提供数据采样、增强变换、数据批处理等功能，通过使用不同的数据加载方式，和数据集加载API配合使用。<br>数据加载方式三种：开源数据集加载、标准格式数据集加载、自定义数据集加载<br>开源数据集加载：视觉数据集、文本数据集、音频数据集<br>标准格式数据集加载：加载业界标准数据格式的数据集文件，例如TFRecord、MindRecord等格式。<br>自定义数据集加载（mindspore.dataset.GeneratorDataset）：自定义Python数据源，自定义数据读取和处理逻辑。</li><li>数据处理步骤：加载数据集、数据集操作、批处理、迭代器、数据增强（数据集样本变换）</li></ol><ul><li>数据加载：</li><li>加载数据集（自定义、开源和标准格式数据集）<ul><li>加载数据集(开源和标准格式)：先用模块提供的API加载和处理数据集import mindspore.dataset as ds。再通过使用jupyter notebook中运行linux命令下载数据集并解压，存放到指定路径中，注意数据集的目录结构。使用时需要注意使用的数据集文件所在的根目录路径，有些加载必须使用该路径才能使用数据。</li><li>加载自定义数据集：使用<a href="https://www.mindspore.cn/docs/zh-CN/r2.7.0rc1/api_python/dataset/mindspore.dataset.GeneratorDataset.html#mindspore.dataset.GeneratorDataset">GeneratorDataset接口</a>自定义数据集加载。可以先自定义数据集类(DatasetGenerator)，包含数据初始化操作__init__, 数据访问方法__getitem__, 数据量统计方法__len__等，再通过GeneratorDataset接口加载自定义数据集类访问数据集中的数据样本。</li></ul></li><li>数据集操作、批处理、迭代器、数据增强（数据集样本变换）<ul><li>数据集操作（filter&#x2F; skip）：通过使用对象方法  .filter &#x2F; .skip&#x2F; .shuffle来实现数据集的进一步过滤、跳过、混洗等操作。注意：.shuffle等方法是实例方法，使用时需要先创建实例，再调度数据集操作方法。</li><li>批处理(mindspore.dataset.Dataset.batch):将数据集中的多条数据组合为一个批数据。</li><li>迭代器(mindspore.dataset.Dataset.create_dict_iterator):创建数据集迭代器，返回字典样式的样本数据，可实现预处理过程中的数据循环输出。</li><li>数据增强：数据集样本变换（mindspore.dataset.transforms)，一种通用数据增强方法，特别是在数据量过小或在样本单一等问题场景下影响模型训练效果时，通过使用数据增强操作进一步扩展样本多样性和操作，从而提升模型的泛化能力。</li></ul></li></ul><h2 id="模型：定义-模型结构-模型层-模型参数"><a href="#模型：定义-模型结构-模型层-模型参数" class="headerlink" title="模型：定义-模型结构-模型层-模型参数"></a>模型：定义-模型结构-模型层-模型参数</h2><p>以神经网络模型的构建为例</p><ol><li>关键模块：<br> <a href="https://www.mindspore.cn/docs/zh-CN/r2.7.0rc1/api_python/mindspore.nn.html#%E5%9F%BA%E6%9C%AC%E6%9E%84%E6%88%90%E5%8D%95%E5%85%83">mindspore.nn</a>：神经网络模块，用于构建神经网络中的预定义构建块或者计算单元。<br> 其中包括基本构成单元、容器（构造神经元）、封装层、卷积神经网络层、循环神经网络层、Transformer层、嵌入层、非线性激活函数层、线性层、Dropout层（随机丢弃层）、归一化层、池化层、填充层、损失函数、优化器、动态学习率、图像处理层、公共层、工具等部分组成。</li><li>关键类：<br> mindspore.nn.Cell:MindSpore中神经网络的基本构成单元，是所有网络的基类，所有模型或神经网络层应当继承该基类，并重新其中的__init__方法和construct方法。Cell(神经元)在GRAPH_MODE（静态图模式）下将编译为一张计算图，在PYNATIVE_MODE（动态图模式）下作为神经网络的基础模块。</li></ol><ul><li>construct:定义要执行的计算逻辑，所有子类必须重写此方法。</li><li>parameters_and_names：返回当前Cell或所有子Cell的参数名称和参数本身</li></ul><ol start="3"><li>关键成员函数：</li></ol><ul><li>二维卷积神经网络层（mindspore.nn.Conv2d）：根据输入Tensor张量计算二维卷积。先根据参数建立卷积神经网络模型，再根据输入Tensor，输出Tensor.可用于在神经网络中提取特征。</li><li>全连接线性层（mindspore.nn.Dense）：根据输入Tensor，计算出线性变换后的输出Tensor， 可用于对输入张量做线性变换。使用的激活函数可以指定具体的激活函数名，例如mindspore.nn.ReLU</li><li>非线性激活函数层（mindspore.nn.ReLU）:逐元素计算修正线性单元激活函数，逐位输出各位中数值和零的最大值。输入和输出都是Tensor，在网络中添加非线性激活函数，可用于神经网络学习复杂特征。</li><li>池化层（mindspore.nn.MaxPool2d）：在输入Tensor上应用2D最大池化运算，组成2D平面，可用于数组降采样。</li><li>公共层（mindspore.nn.Flatten）：对输入的Tensor按照输入维到输出维进行展平。</li></ul><h2 id="自动微分：求导-梯度缩放-停止计算-梯度"><a href="#自动微分：求导-梯度缩放-停止计算-梯度" class="headerlink" title="自动微分：求导-梯度缩放-停止计算-梯度"></a>自动微分：求导-梯度缩放-停止计算-梯度</h2><ol><li>参数设置:<br> mindspore.Parameter：Tensor子类，当被绑定为Cell属性时，可以同Cell的方法获取。<br> mindspore.ParameterTuple：用于管理多个mindspore.Parameter，实现将网络参数存储到参数元祖集合中。</li><li>梯度计算：<br> mindspore.ops.matmul:计算输入的两个Tensor乘积，输入的两个Tensor数据类型必须一致。<br> mindspore.ops.GradOperation (get_all&#x3D;False, get_by_list&#x3D;False, sens_param&#x3D;False)，一阶导数方法，来自mindspore.ops.primitive的框架算子，一个高阶函数，为输入函数生成对应的梯度函数。可实现对输入求导（返回第一个输入的梯度和所有输入的梯度）、对参数求导和同时对输入和参数求导。其中</li></ol><ul><li>get_all为False时，只会对第一个输入求导，为True时，会对所有输入求导</li><li>get_by_list为False时，不会对权重求导，为True时，会对权重求导</li><li>sens_param对网络的输出值做缩放以改变最终梯度，配合缩放指数，确保缩放指数的维度和输出维度保持一致。</li><li>mindspore.ops.stop_gradient:用于消除某个值对梯度的影响，例如截断来自于函数输出的梯度传播，可以用来禁止网络内的算子对梯度的影响。</li></ul><ol start="3"><li>求导步骤：</li></ol><ul><li>定义使用算子定义网络结构、定义求导网络、根据具体输入值计算计算求导值。</li><li>对权重求一阶导，需要将mindspore.ops.GradOperation中的get_by_list设置为Trure.如果对某些权重不进行求导，则在定义网络结构中，对相应权重参数值mindspore.Parameter中的requires_grad设置为False.</li><li>对梯度值做缩放，需要将mindspore.ops.GradOperation中的sens_param设置为Trure，并在求导网络中定义缩放指数self.grad_wrt_output，再将该指数用于求导函数中。</li></ul><h2 id="优化模型：损失函数-优化器"><a href="#优化模型：损失函数-优化器" class="headerlink" title="优化模型：损失函数-优化器"></a>优化模型：损失函数-优化器</h2><ol><li>超参：可调整参数，用于控制模型训练优化过程，影响模型训练和收敛速度等。<br> 一般超参如下：</li></ol><ul><li>训练轮次（epoch）:训练时遍历数据集的次数，一般用于训练mindspore.train.Model.train方法中</li><li>批次大小（batch size）:用于构造训练数据集，数据集进行分批次读取训练，并设定每个批次数据大小。</li><li>学习率（learning rate）:用于优化器参数设置中，学习率偏小会导致收敛速度偏慢，过大则导致训练不收敛等不可预测问题。</li></ul><ol start="2"><li>损失函数：评价模型的预测值和真实值不一样的程度，损失函数可以直接使用mindspore.nn.L1Loss（计算预测值和目标值之间的平均绝对误差）这类损失函数定义。</li><li>优化器：用于计算和更新梯度，优化器的选择直接影响最终模型的性能。优化器在模块mindspore.nn中，mindspore的所有优化逻辑都封装在Optimizer对象中，要使用优化器，需要构建Optimizer对象，要能够保持参数状态并基于计算得到的梯度能进行参数更新。构造Optimizer对象前，需要先确定包含所有需要优化参数的迭代器，如网络中需要训练的参数parameter等。<br> 优化器可以直接使用mindspore.nn.SGD（随机梯度下降的实现）这类优化器函数定义。</li><li><a href="https://www.mindspore.cn/docs/zh-CN/r2.7.0rc1/api_python/train/mindspore.train.Model.html#mindspore.train.Model.train">mindspore.train.Model</a>：模型训练和推理高阶接口，根据用户的传入参数、损失函数、优化器，封装可训练或推理的实例。<br> train方法：模型训练接口，可根据训练执行轮次epoch，训练数据集train_dataset，开始模型训练。</li><li>模型训练四步骤：</li></ol><ul><li>定义神经网络</li><li>构建数据集</li><li>定义超参、损失函数和优化器</li><li>输入训练轮次和数据集开始模型训练。</li></ul><h2 id="保持加载：保存模型-加载权重-导出IR"><a href="#保持加载：保存模型-加载权重-导出IR" class="headerlink" title="保持加载：保存模型-加载权重-导出IR"></a>保持加载：保存模型-加载权重-导出IR</h2><h3 id="保存模型："><a href="#保存模型：" class="headerlink" title="保存模型："></a>保存模型：</h3><ol><li>主要使用Callback机制，使用API函数如下：</li></ol><ul><li><a href="https://www.mindspore.cn/docs/zh-CN/r2.7.0rc1/api_python/train/mindspore.train.ModelCheckpoint.html">mindspore.train.ModelCheckpoint</a>：checkpoint回调函数，用于在训练过程中，保存网络参数。注意：在分布式训练场景下，每个训练进程都需要指定不同的目录，保存checkpoint文件，否则可能训练失败。</li><li><a href="https://www.mindspore.cn/docs/zh-CN/r2.7.0rc1/api_python/train/mindspore.train.CheckpointConfig.html#mindspore.train.CheckpointConfig">mindspore.train.CheckpointConfig</a>：保存checkpoint配置策略</li></ul><ol start="2"><li>注意：</li></ol><ul><li>保存模型步骤：先设置checkpoint配置策略，再创建ModelCheckpoint对象，在将ModelCheckpoint对象传递给model.train训练方法，开始训练。</li><li>MindSpore为方便用户区分每次生成的CheckPoint文件，会在用户定义的前缀后添加”_”和数字加以区分。如果想要删除.ckpt文件时，请同步删除.meta 文件。</li></ul><h3 id="加载模型："><a href="#加载模型：" class="headerlink" title="加载模型："></a>加载模型：</h3><ol><li><a href="https://www.mindspore.cn/docs/zh-CN/r2.7.0rc1/api_python/mindspore/mindspore.load_checkpoint.html#mindspore.load_checkpoint">mindspore.load_checkpoint</a>:加载checkpoint文件，返回值是字典。主要用于将参数文件中的网络参数存入自定义的参数字典中，配合模型实例，将参数加载入网络中。</li><li><a href="https://www.mindspore.cn/tutorials/zh-CN/r1.3/save_load_model.html">mindspore.load_param_into_net</a>:将自定义参数字典中的参数加载到网络或优化器中，加载后，网络中的参数就是之前CheckPoint保存的参数，返回网络中没有被加载的参数列表。</li></ol><h3 id="验证模型："><a href="#验证模型：" class="headerlink" title="验证模型："></a>验证模型：</h3><ol><li>推理场景：<br> <a href="https://www.mindspore.cn/docs/zh-CN/r2.7.0rc1/api_python/train/mindspore.train.Model.html#mindspore.train.Model.train">mindspore.train.Model</a>：模型训练或推理高阶接口。 根据用户传入的参数，封装可训练或推理的实例。</li></ol><ul><li>eval方法：模型评估接口。</li><li>train方法：模型训练接口。</li><li>验证步骤：先定义验证数据集，再利用数据集，调度eval方法进行推理验证。</li></ul><ol start="2"><li>任务中断再训练或者微调场景：</li></ol><ul><li>验证步骤：先定义训练轮次和训练数据集，再利用数据集，调度train方法进行训练。可用于迁移学习。</li></ul><h3 id="导出模型："><a href="#导出模型：" class="headerlink" title="导出模型："></a>导出模型：</h3><p>通过网络和CheckPoint格式文件生成对应模型格式文件，实现在不同硬件平台上的推理。</p><ol><li><a href="https://www.mindspore.cn/docs/zh-CN/r2.7.0rc1/api_python/mindspore/mindspore.export.html#mindspore.export">mindspore.export</a>:将MindSpore网络模型导出为指定格式的文件。可导出ONNX&#x2F;AIR&#x2F;MINDIR三种格式文件。当导出文件格式为AIR、ONNX时，单个Tensor的大小不能超过2GB。</li><li>文件导出格式：</li></ol><ul><li>ONNX(Open Neural Network eXchange):一种针对机器学习所设计的开放式的文件格式，由微软提出，与环境和平台无关的标准格式，2.2 用于在不同深度学习框架共享和交换已训练好的模型。推荐的输出文件后缀是”.onnx”.</li><li>AIR(Ascend Intermediate Representation):一种Ascend模型的中间表示格式。类似ONNX，由华为提出，能更好适配昇腾AI处理器。推荐的输出文件后缀是”.air”.</li><li>MINDIR(MindSpore Native Intermediate Representation for Anf):一种MindSpore模型的中间表示格式。推荐的输出文件后缀是”.mindir”.</li></ul><ol start="3"><li>格式导出：</li></ol><ul><li><p>ONNX格式：可在第三方硬件平台上推理。导出文件名称会自动添加“.onnx”后缀。</p><p><code>export(..., file_format = &#39;ONNX&#39;)</code></p></li><li><p>AIR格式：可在昇腾AI处理器上推理。导出文件名称会自动添加“.air”后缀。<br><code>export(..., file_format = &#39;AIR&#39;)</code></p></li><li><p>MINDIR格式：可在MindSpore端侧（GPU&#x2F;CPU&#x2F;Ascend）上推理。导出文件名称会自动添加“.mindir”后缀。<br><code>export(..., file_format = &#39;MINDIR&#39;)</code></p></li></ul><h2 id="端侧推理：模型加载-植入APP-推理"><a href="#端侧推理：模型加载-植入APP-推理" class="headerlink" title="端侧推理：模型加载-植入APP-推理"></a>端侧推理：模型加载-植入APP-推理</h2><p>不同推理设备有不同的推理方法，模型可以在昇腾Ascend处理器和移动设备上进行推理，由于昇腾Ascend处理器推理配置复杂，本文主要介绍移动设备推理。</p><ol><li><a href="https://www.mindspore.cn/lite/docs/zh-CN/r2.7.0rc1/index.html">MindSpore Lite</a>:AI引擎，支持GPU&#x2F;CPU&#x2F;NPU异构调度，支持模型轻量化、全场景(IOS&#x2F;安卓&#x2F;Huawei LiteOS系统)部署，支持MindSpore、TensorFlow Lite、Caffe和ONNX 4类AI框架（不支持Pytorch）。</li><li>工作流程和步骤：</li></ol><ul><li>选择模型：可使用预置的终端模型，或者使用自己已训练好的模型。</li><li>模型转换：主要是格式转换<br>转换工具下载：按照linux和windows系统的不同，选择不同的转换工具压缩包。<br>转换工具使用：不同系统转换工具不同，执行转换命令时，–fmk参数表示输入模型的原始格式，例如MINDIR;–modeFile表示输入模型路径；–outputFile表示模型输出路径，转换后的模型会自动添加.ms后缀，转换为.ms格式。</li><li>构建环境和运行：不同系统编译和推理有差异。<br>编译构建：windows系统要比linux麻烦一点，需要下载库和模型。<br>执行推理：编译完成后，进入模型目录，调用.ms格式的模型文件</li></ul><p>基于公开来源资料mindspore教程1.3版本，详情请看<a href="https://www.mindspore.cn/tutorials/zh-CN/r1.3/custom.html#">MindSpore官网</a></p>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
            <tag> 算法 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> MindSpore </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GaussDB(DWS)数据库-巡检运维篇</title>
      <link href="/2025/08/04/GaussDB(DWS)%E6%95%B0%E6%8D%AE%E5%BA%93-%E5%B7%A1%E6%A3%80%E8%BF%90%E7%BB%B4%E7%AF%87/"/>
      <url>/2025/08/04/GaussDB(DWS)%E6%95%B0%E6%8D%AE%E5%BA%93-%E5%B7%A1%E6%A3%80%E8%BF%90%E7%BB%B4%E7%AF%87/</url>
      
        <content type="html"><![CDATA[<h3 id="基本运维动作"><a href="#基本运维动作" class="headerlink" title="基本运维动作"></a>基本运维动作</h3><ol><li><p>常用运维命令：</p><ul><li>查看集群状态或单个主机的状态：cm_ctl query -Cv；Normal:表示集群可用，主备关系正常；Degraded:表示集群可用，但是数据没有冗余备份；Unavailable:表示集群不可用；Catchup:表示集群的DN备实例正在追赶主实例的日志信息。</li><li>切换集群主备实例、实现AZ之间的相互切换：cm_ctl switchover -a</li><li>启停实例：<ul><li>注意事项<ul><li>适用场景：主机发生故障状态异常，需要停止所有实例；或单台服务器、硬盘故障，需要停止对应的实例进行检修更换等</li><li>前提条件：停止节点&#x2F;实例后，需要保证集群内至少有一个正常的CN节点、cm_server节点、gtm节点；涉及cn节点、实例后，如果没有负载均衡，需要将业务迁移至其他CN；若集群磁盘水位处于75%以上，停止节点、实例后需要重点关注磁盘水位变化；停止实例前，需要检查集群状态，保证对应实例状态正常，无catchup；停止实例前，连接集群执行checkpoint ；启停集群服务、单个主机上的所有实例或者单独启停某个实例进程</li></ul></li><li>停止模式有如下几种：<ul><li>smart: 等待用户业务结束后，集群退出</li><li>fash:不等待用户业务结束，集群退出</li><li>immediate: 不等待用户业务结束，强制集群退出。</li></ul></li><li>修复节点：<ul><li>修复前提：适用场景：DN异常、cn处于delete或者down状态</li><li>前提条件：集群安装成功，并且处于已启动状态；DN环只能损坏一个实例；集群内CMServer、CMAgent、Coordinator至少存在一个正常实例；GTM故障时，另一个GTM必须处于最高可用状态</li><li>注意实现：正常节点执行修复操作；修复涉及cn需要保障被修复的cn没有ddl业务将发生故障的主机（实例）替换为正常主机（实例）</li></ul></li></ul></li></ul></li><li><p>常用运维SQL：</p><ul><li>活跃作业语句查询，使用场景：查询此时在数据库运行的作业信息，用于确定当前作业运行的SQL、耗时、运行状态，排队状态和等待状态等信息，pgxc_stat_activity视图</li><li>作业等待查询，使用场景：查询此时在数据库运行作业的等待信息，用于确定当前作业运行过程中，在各个DN实例等待事件和阻塞状态，是在等待IO还是在等待锁等，pgxc_thread_wait_status视图</li><li>锁等待查询，使用场景：查询此时在数据库运行的作业中等锁的信息，包括等锁的语句、用户和持有锁的语句、用户，用于确定当前作业系统中调度不合理的场景，比如当一个表在进行增加表字段时，其他插入或者查询作业会阻塞。pgxc_lock_conflicts视图。</li><li>单表倾斜：通过查看表数据在各个dn的分布情况判断是否存在数据倾斜。<ul><li>倾斜表重分布处理步骤：<ul><li>创建一张新的表，并选取合适的分布列，判断一列是否可以作为分布列，可通过下面的语句查询该列的值分布情况：<code> bash select attr, cont(*) from schema.table group by atttr;</code> </li><li>将数据从旧表导入到新表：   <code> bash insert into new_table select * from old_table;</code> </li><li>删除旧表：   <code> bash drop table old_table;</code> </li><li>将新表重命名为旧表：   <code> bash alter table new_table rename to old_table;</code></li></ul></li></ul></li><li>全库查倾斜表：查询全库数据表的倾斜情况，在集群表较多时可以指定条件统计倾斜率超过10%和表大小大于100G的表倾斜信息，针对每个倾斜大表，需要按照单表的倾斜处理办法进行处理。运维建议：针对业务表建议每周例行全库运维处理倾斜表，各个节点磁盘使用率差别不超过5%。</li><li>判断需要analyze的表：识别从未做过analyze的表；识别insert、update&#x2F;delete总量超过上次统计数据量20%的表。需要固化到业务中，立即做analyze的场景：每次truncate表后执行insert数据的场景。每天插入新数据后并且业务立即只查询刚插入的数据场景。</li><li>脏页回收：<ul><li>dws用户表数据在经过频繁插入、更新、删除后，会产生脏页，脏页会占用空间。在脏页率达到一定程度时需要使用vacuum full analyze命令清理，建议每月进行一次维护</li><li>使用方法：登录需要统计的数据库，执行上面的SQL语句，找到需要进行清理的表。执行SQL命令；vacuum full analyze 业务表：</li><li>调优建议：当脏页率&gt;30%或者脏数据行数&gt;1w时，对表做脏页回收。</li></ul></li><li>内存使用：查询当前数据库节点的内存使用情况，单位MB.查询当前节点内存使用情况：   <code>bash select * from pv_total_memory_detail;  </code></li></ul></li><li><p>运维日志：</p><ul><li>数据库日志：数据库日志记录了DWS数据库服务端启动，运行或停止时出现的问题，当数据库在启动，运行或者停止的过程中出现问题时，数据库用户可以通过运行日志，快速分析问题的产生原因。</li><li>管控面日志</li><li>操作系统日志：操作系统日志可以记录系统的运行状态和异常情况，并且用于故障排除和性能分析。</li></ul></li><li><p>产品架构形态：dws数据库主要有如下部署方式：线下物理机部署ESL和云化部署HCS</p><ul><li>线下部署：<ul><li>DWS的ESL版本使用fusioninsight manager管理平台提供集群状态监控，告警管理，监控采集等功能。集群安装完成后，登录管理平台即可查看集群的状态监控指标.</li><li>数据库级别的监控指标：服务对于CPU、内存，物理读写与IO等资源的消耗趋势，反应了数据库的业务压力，需要指出的是这里的内存使用大小指的时候各个数据库实例在监控时间点消耗的内存总量。</li><li>节点级别的监控指标：提供主机级别的CPU&#x2F;内存以及磁盘使用情况的趋势图。</li><li>登录节点执行运维命令均需要在“omm”用户下执行，并且需要source环境变量。</li></ul></li><li>云化部署：<ul><li>DWS的HCS形态完成集群创建后，即可在集群管理页面看到创建的集群信息，选择集群操作选项中的监控面板功能，查看监控信息。</li><li>节点级别监控：CPU&#x2F;IO&#x2F;磁盘使用率，内存，网络等；</li><li>集群概览：集群状态，整体资源消耗利率，实例状态</li><li>实时查询：活跃会话数，活跃应用数，活跃查询数。</li></ul></li></ul></li></ol><h3 id="巡检工具及运维工具"><a href="#巡检工具及运维工具" class="headerlink" title="巡检工具及运维工具"></a>巡检工具及运维工具</h3><ol><li>巡检工具：<ul><li>不同巡检任务：</li><li>日常巡检：<ul><li>使用场景：用于集群日常维护，获取集群的健康状态，发现集群的潜在风险问题。</li><li>TOP巡检项：集群状态，负载均衡状态，CPU使用率，磁盘性能和使用率，日志空间大小，内存泄露，数据倾斜，透明大页，周期性备份等</li><li>使用规范：每单周或双周执行一次</li></ul></li><li>升级前巡检：<ul><li>使用场景：用于集群版本升级前，提前发现可能会影响集群升级的问题。</li><li>TOP巡检项：集群状态，文件系统占用率，磁盘空间空间，防火墙关闭，xid回卷，系统表是否损坏。</li><li>使用规范：升级版本前5天内执行</li></ul></li><li>扩容前巡检：<ul><li>使用场景：用于扩容操作前，提交发现可能会影响集群扩容的风险问题。</li><li>TOP巡检项:集群状态，节点间互信，磁盘使用率，磁盘的inodes使用率，数据倾斜，SCTP模块是否安装等。</li><li>使用规范：扩容操作前5天内执行</li></ul></li><li>温备前巡检（仅HCS形态支持）：<ul><li>使用场景：用于温备操作前，提交发现可能会影响温备操作的风险问题</li><li>TOP巡检项：全部11项</li><li>使用规范：温备操作前5天内执行</li></ul></li><li>深度巡检：<ul><li>使用场景：用于GaussDB集群日常维护，获取集群更深度的健康状态，发现集群的潜在风险，深度巡检必须停止业务后执行。</li><li>TOP巡检项：磁盘使用率，僵尸进程，内存泄露，残留临时表，是否有psort索引，负载均衡状态，分布键顺序，开启analyze，guc参数符合调优条件等</li><li>使用规范:每年执行一次。</li></ul></li></ul></li><li>ESL形态巡检工具：<ul><li>工具介绍：FusionInsight Tool DWS Prober是为工程师提供的一套健康检查工具，能够检查集群相关节点，服务的健康状态，提前发现集群中潜在的问题，并生成健康检查报告。由两部分组成：FusionCare和SysChecker。其中FusionCare提供对租户面节点巡检功能，SysChecker提供对管控面FusionInsight的巡检功能。</li><li>适用场景：适用于集群安装后，对集群的服务状态，节点硬件状态，操作系统配置等进行检查。</li><li>常用巡检功能：日常巡检、升级前巡检、扩容前巡检、深度巡检</li></ul></li><li>HCS形态巡检工具：<ul><li>工具介绍：Inspect插件，是为了技术支持和维护工程师提供的HCS集群界面化健康检查工具，能够检查集群相关节点，服务的健康状态，提前发现集群中的潜在问题，并生成健康检查报告。同时该插件与集群版本解耦，使用前可直接升级到最新版本。</li><li>使用场景：适合工程师在集群日常维护、升级、扩容、温备等操作前快速对集群软件、硬件、配置等进行健康检查。</li><li>日常巡检功能： 日常巡检、升级前巡检、扩容前巡检、温备前巡检、深度巡检。</li></ul></li><li>运维工具：概述：DWS提供运维工具包，针对现网高频问题和应急场景，汇总成工具包，目标是通过工具一键收集定位定界信息，用于加快问题处理和提升运维效率。<ul><li>gs_dbmonitor:<ul><li>功能描述：周期采集集群SQL级的运行状态：DDL探针，活跃语句，SQL排队，作业等待，内存使用，主备同步等信息</li><li>使用场景：实时监控系统运行状态：实时查询集群的SQL作业运行情况，实时查看异常指标，便于进一步分析集群运行情况盘点：汇总历史变化信息并转化为图表形式来分析业务和负载变化趋势，可用于系统健康度评估和业务变化分析</li></ul></li><li>gs_ccnqueue:<ul><li>功能描述：排查ccn排队作业是否有异常，输出结果包括排队的作业数，可用内存数，剩余内存数，正在执行的作业的估算内存大小，执行时间，执行用户，执行的SQL等信息</li><li>使用场景：有大量的作业在waiting in ccn queue, 查看正在运行的作业和排队作业的资源消耗情况</li></ul></li><li>gs_cpuwatcher:<ul><li>功能描述：查找集群中引起cpu高的业务SQL</li><li>使用场景：系统CPU使用率高，使用本工具抓取占用cpu高的业务SQL</li></ul></li><li>gs_memwatcher:<ul><li>功能描述：对集群内的CN&#x2F;DN的实例，进行单实例的内存监控</li><li>使用场景：系统内存&#x2F;动态内存使用率高，使用本工具抓取占用内存高的业务SQL报内存错误memory is temporarily unavailable时排查内存占用情况。监控运行过程中的内存使用率。</li></ul></li><li>gs_iowatcher:<ul><li>功能描述：监控单CN&#x2F;DN上业务SQL的IO使用情况，如果需要监控多个，可以起多个线程。</li><li>使用场景：系统IO使用率高，使用本工具抓取占用IO高的业务SQL</li></ul></li><li>gsar:<ul><li>功能描述：对指定网卡流量，重传，丢包等指标监测，以便快速定位网络问题。</li><li>使用场景：通过报错等问题，定位到可能有网络故障时，使用此工具对网络进行排查。</li></ul></li><li>gs_oscoreconfig,gs_coreanalyze<ul><li>功能描述：单节点配置os core,关闭Bbox core；解析gaussdb产生的core文件，并打印出语句，执行用户等相关信息；展示当前目录下的所有已解析的core文件结果；压缩存放解析结果的core文件夹。</li><li>使用场景：当集群内gaussdb进程产生core文件后，使用该工具分析core文件堆栈，用于分析进程异常退出的原因</li></ul></li><li>gs_diskusedcheck<ul><li>功能描述：对集群内所有磁盘的使用率进行筛选，识别超过阈值的磁盘。对单DN或单磁盘下所有DN进行磁盘使用率检查，覆盖以下场景：专有目录的大小，大文件检测</li><li>使用场景:磁盘告警或集群只读时，可使用此工具进行排查。当磁盘使用率出现倾斜时，可使用此工具进行排查。业务和负载变化，可用于系统健康度评估的参考。</li></ul></li><li>gs_tablescan:<ul><li>功能描述：快速校验集群内表文件是否有损坏或者表查询异常。</li><li>使用场景：发现存在表数据文件损坏后，使用此工具进行全库排查（磁盘故障，全局排查，数据校验）</li></ul></li></ul></li><li>TOPSQL:<ul><li>概述：TopSQL是DWS数据库内置的一款功能十分强大的性能分析工具。在生产环境中，难免会出现一些突发情况，导致查询语句出现异常中断、阻塞时间长等情况，如果当时没能记录下来，那么事后就要投入更多的人力以及时间成本，去对错位进行定位和解决，有时还往往定位不到错误的地方。为了解决这样的窘迫的情况，DWS开发了TopSQL功能，对运行中的语句记录（实时TopSQL），对运行完成的语句进行记录（历史TopSQL）</li><li>实时TopSQL：<ul><li>前提条件：<ul><li>guc参数enable_resource_track为on（默认为on）</li><li>guc参数resource_track_level为query&#x2F;perf或者operator(默认为query)</li><li>监控作业的类型为：优化估算的执行代价大于或等于resource_track_cost取值的作业。</li><li>Cgroups功能正常加载，可通过gs_cgroup -P查看控制组信息。</li><li>GUC参数enable_track_record_subsql控制是否记录存储过程、匿名块内部语句。</li><li>在上述条件中，enable_resource_track为系统级参数，用于设置是否开启资源监控功能。resource_track_level为session级参数，可以对某个session的资源监控级别进行灵活设置。</li></ul></li></ul></li><li>实时TopSQL常用视图：<ul><li>gs_session_cpu_statistics:查询实时CPU信息</li><li>gs_session_memory_statistics:查询实时memory信息</li><li>gs_wlm_session_statistics:查询当前cn的实时资源</li><li>pgxc_wlm_session_statistics：查询所有cn的实时资源</li><li>gs_wlm_operator_statistics：查询当前CN作业算子执行实时资源信息</li><li>pgxc_wlm_operator_statistics：查询所有CN作业算子执行实时资源信息</li><li>pg_session_wlmstat：查询当前用户执行作业正在运行时的负载管理信息。</li><li>pgxc_wlm_workload_records:动态负载功能开启，enable_dynamic_workload 为on时，该视图有效，查询当前用户在每个CN上，作业执行时的状态信息。</li></ul></li><li>历史TopSQL：<ul><li>前提条件：<ul><li>guc参数enable_resource_track为on（默认为on）</li><li>guc参数resource_track_level为query，perf或operator（默认为query）</li><li>guc参数enable_resource_record为on（默认为on）</li><li>guc参数resource_track_duration小于作业执行时间（默认为60s）</li><li>guc参数enable_track_record_subsql控制是否记录存储过程、匿名块内部语句（默认为on）</li><li>guc参数resource_track_subsql_duration小于存储过程中内部语句的执行时间（默认为180s）</li><li>监控作业类型为:资源监控实时视图中，记录的作业结束时的执行时间大于或等于resource_track_duration的作业</li><li>Cgroups功能正常加载，可通过gs_cgroup -P查看控制组的信息。</li></ul></li></ul></li><li>历史TopSQL常用视图：<ul><li>gs_wlm_session_history:查询当前cn最近执行作业结束后的负载记录</li><li>pgxc_wlm_session_history：查询所有cn最近执行作业结束后的负载记录</li><li>gs_wlm_session_info:数据表，查询当前cn作业执行结束后的负载记录。要查到历史记录，必须保证enable_resouce_record为on</li><li>pgxc_get_wlm_session_info_bytime:函数，对视图pgxc_wlm_session_info进行筛选查询，要查到历史记录，必须保证enable_resouce_record为on。在统计数据量很大的场景中，建议使用该函数进行查询。</li><li>gs_wlm_operator_histroy:查询当前cn作业算子最近执行资源信息。要查到记录，必须保证resource_track_level 为operator</li><li>pgxc_wlm_operator_history:查询所有cn作业算子最近执行资源信息。要查到记录，必须保证resouce_track_level为operator</li><li>gs_wlm_operator_info：数据表，查询当前cn作业算子历史执行资源信息。要查到记录，必须保证resource_track_level为operator和enable_resource_record为on</li><li>pgxc_wlm_operator_info:查询所有CN作业算子历史执行资源信息。要查到记录，必须保证resource_track_level为operator和enable_resource_record为on。</li></ul></li></ul></li></ol><h3 id="运维监控"><a href="#运维监控" class="headerlink" title="运维监控"></a>运维监控</h3><ol><li>华为云stack DWS 微服务组件：<ul><li>Controller：整个DWS的后台组件</li><li>Monitor:ECF公共组件，主要功能：集群实例的状态监控，告警&#x2F;事件上报</li><li>Event:ECF公共组件，主要功能：ECF事件&#x2F;告警管理中心，支持向SMN，OC，CTS发送事件和告警。</li><li>ECFAgent:部署在集群节点上的代理，主要功能：接收告警和事件，监控集群状态</li><li>DMSAgent:部署在集群节点上的代理，主要功能：采集数据库的资源监控信息和数据库所在节点的系统资源信息。</li></ul></li><li>告警：<ul><li>告警配置：DWS提供告警配置功能，用于提前发现集群潜在问题和故障，告警内容涵盖集群故障、资源过载、性能降级等多种故障场景，建议客户根据业务场景配置合理的告警阈值和规则，建议对紧急告警，进行短信和电话配置，便于及时关注集群告警。</li></ul></li><li>监控：<ul><li>监控上报：集群侧节点上有定时任务采集，数据仓库服务节点监控信息每隔1分钟采集一次，数据仓库整集群监控信息每隔4分钟采集一次，会在目录&#x2F;uploadtocessrc下生成*.json文件，上报成功后会将监控文件存放到uploadtocesbak进行备份，文件备份周期为2天。</li><li>异步的数据XX进程，会将数据给ces服务，OC运维监控平台从ces上获取数据进行处理展示。</li><li>监控主要用于性能问题维护，异步上报监控，监控超过阈值会上报告警，通过监控趋势提前了解集群是否需要扩容，以及潜在的性能问题风险，当前DWS已有的性能监控指标粒度比较粗，无法精确到节点上具体的性能指标监控详情，新开发的DMS功能会有比较细粒度的监控后续的监控功能会以新开发的DMS为主，会进一步完善和丰富DMS的监控功能，DWS在630就已有的性能监控会保持现状，不会有大的需求改动。</li></ul></li></ol><h3 id="业务应急"><a href="#业务应急" class="headerlink" title="业务应急"></a>业务应急</h3><ol><li>常见故障场景和应急手段：<ul><li>整体性能慢：通过应急“三板斧”，快速恢复集群性能</li><li>CPU使用率高：找到CPU占比高的语句，对相关业务进行应急查杀或者资源限制，事后进行SQL优化。</li><li>IO使用率高：找到IO占比高的语句，对相关业务进行应急查杀，事后进行SQL优化</li><li>内存报错：找到内存占比高的语句，对相关业务进行应急查杀或资源限制</li><li>锁冲突报错：找到持锁语句，应急查杀并将锁冲突业务，错峰执行。</li><li>集群只读：找到空间占比高的表或者语句，清理空间。</li></ul></li><li>整体性能慢：<ul><li>概念：数据库系统的性能管理在整个业务系统中起着很重要的作用，集群性能管理不当或在硬件、OS等故障后，容易出现集群性能降级，需要及时介入处理避免长时间对业务造成影响</li><li>问题现象：集群整体出现卡慢，业务常规查询，建表等语句劣化，性能探针出现劣化</li><li>问题影响：集群整体性能降级，造成跑批延迟，影响业务时效性</li><li>处理套路：判断性能瓶颈点（硬件&#x2F;资源&#x2F;内部等待事件等）,针对性能瓶颈点快速恢复。</li></ul></li><li>CPU使用率高：<ul><li>概念：CPU指标表示当前集群计算资源的使用情况，一般建议CPU使用率维持在60%以下，防止在主备切换后出现CPU瓶颈；当CPU使用率超过80%后，不同业务之间会有比较严重的CPU争抢，此时建议通过错峰或扩容等手段降低CPU负载。当出现CPU使用率异常突增时，会导致集群整体性能劣化，需要及时处理。</li><li>问题现象：集群CPU使用率突增，或CPU水位长期维持在80%以上，出现CPU过载</li><li>问题影响：集群整体性能降级，造成跑批延迟，影响业务时效性</li><li>处理套路：找到占用CPU高的语句或用户，针对该语句或用户处理。</li></ul></li><li>IO使用率高：<ul><li>概念：IO指标表示当前集群读写性能，对于机械硬盘应重点关注该指标，当机械盘IO使用率超过90%后，业务可能会有大量wait io出现，频繁IO等待导致集群整体性能降级。</li><li>问题现象：集群IO使用率突增，或IO使用率长期在90%以上，出现IO过载</li><li>问题影响：集群整体性能降级，造成跑批延迟，影响业务时效性</li><li>处理套路：找到占用IO高的语句或用户，同步排查硬件故障情况，针对IO占用高的语句或用户进行处理</li></ul></li><li>内存报错：<ul><li>概念：业务语句在执行过程中，大部分操作都是在动态内存中完成的，当SQL中间结果集过大或当前并发过高时，会导致集群动态可用内存不足，出现memory is temporarily unavailable报错</li><li>问题现象：集群动态内存使用率突增，出现动态内存不足告警，部分业务出现内存不足报错。</li><li>问题影响：部分业务报错</li><li>处理套路：找到占用内存占用高的语句或用户，针对内存占用高的语句或用户进行处理。</li></ul></li><li>锁冲突报错：<ul><li>概念：当对表进行查询&#x2F;DDL&#x2F;DML等任何操作时，数据库会对表进行加锁操作，在事务结束时释放。常规锁按照粒度可以分为8个等级，各个操作对应不同的锁级别，级别不同，阻塞程度不同。当互相冲突的语句执行时，后执行的语句会进入锁等待队列，表现为语句被阻塞。例如，对表进行长查询时，truncate语句会被阻塞，进入锁等待队列，表现为truncate语句执行卡住。</li><li>问题现象：表相关的业务阻塞，执行慢或出现锁等待超时报错</li><li>问题影响：部分业务报错或该表相关的业务被阻塞</li><li>处理套路：找到持锁语句，应急查杀或停用持锁业务。</li></ul></li><li>集群只读：<ul><li>概念：当集群某个磁盘完全写满，达到100%时，此时该盘对应的实例进程无法进行数据写入和xlog日志写入，并且可能导致对应的备机实例也写满，此时集群会出现不可用状态。为了避免集群不可用，当集群磁盘使用率到达90%时，会触发集群只读保护，此时只能进行查询，无法进行写入，这种情况下需要及时清理磁盘空间，将磁盘空间使用率降低到安全水位（建议80%）以下</li><li>问题现象：集群进入只读模式，写入相关的业务出现read only报错</li><li>问题影响：增删改业务报错</li><li>处理套路：找到触发只读的目录，根据对应的目录内容，找到大表或触发语句。</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> 数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GaussDB(DWS) </tag>
            
            <tag> 数据库 </tag>
            
            <tag> 数据仓库 </tag>
            
            <tag> 数据 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GaussDB(DWS)数据库-湖仓一体篇</title>
      <link href="/2025/08/04/GaussDB(DWS)%E6%95%B0%E6%8D%AE%E5%BA%93-%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93/"/>
      <url>/2025/08/04/GaussDB(DWS)%E6%95%B0%E6%8D%AE%E5%BA%93-%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93/</url>
      
        <content type="html"><![CDATA[<hr><h2 id="湖仓一体"><a href="#湖仓一体" class="headerlink" title="湖仓一体"></a>湖仓一体</h2><p>湖仓一体：lake house,其出发点是通过数据仓库和数据湖的打通和融合，让数据流动起来，减少重复建设。<br>lake house架构最重要的一点，是数据仓库和数据湖的数据&#x2F;元数据无缝打通和自由流动。湖里的“显性价值”数据可以流到仓里，甚至可以直接被数据仓库使用；而仓里是“隐性价值”数据，也可以流到湖里，低成本长久保存，供未来的数据挖掘使用。</p><h2 id="湖仓介绍"><a href="#湖仓介绍" class="headerlink" title="湖仓介绍"></a>湖仓介绍</h2><h3 id="数据湖"><a href="#数据湖" class="headerlink" title="数据湖"></a>数据湖</h3><ol><li>数据湖理解<ul><li>传统用户：以hadoop集群为主，满足支持所有结构化、半结构化、无结构化的数据存储即为数据湖</li><li>云厂商：基于对象存储，以S3、OSS、OBS等构建数据底座，进行统一存储。</li><li>大数据互联网：以数据湖三剑客为主（Iceberg、Hudi、Delta   · lake）。它们可以支持比Hive更高层的Upsert、Delete、事务操作等高级特性，能基于Hive进行升级，解决准实时性的问题。</li></ul></li><li>数据湖优势：<ul><li>更好的Table format: 通过支持ACID事务，支持Schema evolution, 能够为用户提供更好的表格式。</li><li>更好的File format: 数据湖在文件格式上支持越来越多的半结构化map、Struct、Json等，并且支持越来越多的索引，进而使文件的查询和存储效率更高，并且在基于列存存储的基础上，支持更多的复杂嵌套结构。</li><li>更低的存储成本、更高的可靠性：使用对象存储，相比于本地磁盘存储、SSD存储或者云盘存储等，可以大幅降低存储成本，并且通过编码的方式能够在降低副本数据量的同时，又能保证高可靠性，可以使用户不用担心底层数据的丢失，从而获得低成本的存储。</li><li>统一的Catalog: 通过统一的catalog，实现统一的元数据管理、权限管理、统计信息管理、入湖管理等。</li></ul></li><li>湖仓融合的价值：<ul><li> 数仓加速：基于数据湖的远程IO成本很高，而且缺少一系列数仓加速手段。早期的数据湖格式多样而且不成熟，索引支持不完善，查询性能有待提升。数据湖主要针对吞吐量的优化，关注低成本和高可靠，不适用于高性能的需求。</li><li> 实时分析：传统的数据湖实时性不够，在Iceberg或者hudi的支持下可能解决分钟级别的时效性，无法解决秒级时效性的问题。</li><li> 高并发查询：对于高并发查询，不管是点查询还是聚合类查询，数仓更加擅长。比如分桶的处理，更精细的裁剪，降低扫描的数据量，提升点查询的效率。另一方面通过物化视图或者cube等相关的预聚合手段，可以提升聚合查询的性能。</li><li> 更完善数据治理：湖仓融合的数据底座，统一主数据和元数据，基于此才有可能做上层统一的数据治理</li><li> 降本增效：简化技术架构、增强整体架构可靠性，降低运维成本。</li></ul></li><li>支持数据格式：<ul><li>文本类型：支持text、CSV，高性能导入导出，支持指定分隔符（delimiter）、换行符（eol）、编码（encoding）,以及多种容错方式处理、错误表等</li><li>列存存储格式：高性能列存存储格式，用于大数据环境中高效存储和查询数据，支持多种压缩算法、编码方式，并且兼容多种引擎。</li><li>Parquet&#x2F;ORC：融合查询，复杂类型查询，支持多种压缩算法，支持多种方式写出</li><li>湖格式：hudi是一个功能丰富的存储管理平台，支持构建具有增量数据管道的流式数据湖，针对处理引擎和常规批处理，进行优化；针对数据探索、BI场景的交互式分析能力，进行优化。支持COW、MOR的导入查询，以及增量同步导入。</li></ul></li></ol><h3 id="湖格式（hudi）"><a href="#湖格式（hudi）" class="headerlink" title="湖格式（hudi）"></a>湖格式（hudi）</h3><p>hudi是一个功能丰富的存储管理平台，支持构建具有增量数据管道的流式数据湖，针对处理引擎和常规批处理，进行优化；针对数据探索、BI场景的交互式分析能力，进行优化。<br>关键能力：变更数据、实时性、数据事务、并发性、多版本能力、存储优化、表结构变更、数据管理、生态兼容。</p><ol><li>存储结构：<ul><li>Metadata:以timeline时间线的形式维护对hudi表的各项操作。</li><li>Data:使用两种存储格式存储数据</li><li>ndex:在数据更新时提供更快的老记录查询性能。</li></ul></li><li>表类型：COW和MOR<ul><li>COW(copy on write)：写入操作时进行复制，每次写入操作都会创建新的cow表，并将原表覆盖。COW表的主要优点是可以减少内存占用和提高写入性能，适合频繁进行写入操作的场景，列如批量更新、数据批量插入等。<ul><li>优点:减少内存占用：每次操作都会创建新的cow表，而不是修改原表，可以减少内存占用，提高性能。提高可扩展性，写优化的行存格式：默认为Avro格式， 空间占用较小。</li><li>缺点：需要内存管理：内存中管理原表和cow表之间的关系，因此需要额外的内存管理能力，需要进行内存管理和回收。数据写入性能较差，写优化的行存格式：默认为Avro格式。</li></ul></li><li>MOR(merge on read):读时合并，数据在写入的时候，为了尽可能保证写入速度，不同步做数据的合并操作（可以看做是异步合并），而是以append的方式，将数据写入到avro格式的日志文件中，在我们读取数据时，再启动合并策略。<ul><li>优点：写入性能高：适用于需要高性能写入的场景，如实时数据分析、流式数据处理等。在写入新数据时会将数据写入临时文件，后通过Compaction过程将临时文件合并到基础数据文件中，更新数据文件并删除旧版本。提高可扩展性，写优化的行存格式：默认为Avro格式。</li><li>缺点：资源消耗：需要定期合并整理compact，否则碎片文件较多，数据写入性能较差。读取性能较差：需要将delta log和老数据文件合并，占用空间相对较大</li></ul></li></ul></li><li>外表查询：<ul><li>hudi外表查询：支持hudi两种表类型：COW(性能优化)、MOR(性能较差)；支持hudi两种查询视图：snapshot、incremental</li><li>增量查询：针对hudi增量查询功能，可以通过设置增量查询参数，实现增量查询。</li><li>增量设置的增量参数：通过查询视图来查看已经设置哪些参数，检查是否设置正确：select * from pg_show_custom_settings();</li><li>查询hudi外表属性：读取OBS上hudi数据的hoodie.properties</li><li>查询hudi外表最大时间线：读取OBS上hudi数据最大时间线，也就是最新的提交记录。</li></ul></li><li>自动同步任务：<ul><li>自动同步：<ul><li>单表同步任务，实现外表到内表的数据合并，记录增量同步进度。（列映射，hudi增量commit time同步点）</li><li>智能调度框架，实现定时调用存储过程任务，并进行资源管控调度，提供任务启停、告警等运维能力。</li></ul></li><li>同步任务流程：创建dws内表-&gt;创建dws外表-&gt;设置同步进度-&gt;提交hudi同步任务。</li><li>设置同步进度：select set_hudi_sync_state()</li><li>提交同步任务：select hudi_sync_task_submit()</li><li>查询同步状态：select * from hudi_show_sync_state()</li></ul></li></ol><h3 id="元数据服务"><a href="#元数据服务" class="headerlink" title="元数据服务"></a>元数据服务</h3><ol><li>元数据打通：</li></ol><ul><li>从湖仓两层架构到湖仓一体，统一元数据共享数据；统一元数据，简化数据共享。<ul><li>湖仓两层架构：存算分离，底层数据文件可对上层服务共享。湖和仓的元数据隔离，共享数据仍需要ETL</li><li>湖仓一体（data lakehouse）:在存算分离的基础上，构建统一的元数据层。上层服务通过统一的元数据层，便捷高效地共享数据。</li></ul></li><li>HiveMetaStore:<ul><li>定义：Apache Hive的一个关键组件，一个元数据存储库，用于管理Hive&#x2F;spark表的元数据信息。HiveMetaStore存储了hive表的结构信息，包括表名、列名、数据类型、分区信息和表的位置信息等。HiveMetaStore的主要作用是提供元数据服务，使得hive&#x2F;spark可以对数据进行查询和分析。它还提供了一些API，可以让开发人员通过编程方式访问表的元数据。</li><li>总之，HiveMetaStore是Hive的一个重要组件，它提供了元数据管理和查询服务。</li></ul></li><li>External schema:<ul><li>定义：External schema即外部模式，dws通过创建extrenal schema来对接hivemetastore服务，每次查询主动获取hive&#x2F;spark表对象的元数据，无需dws内核通过create foreign table获取hive&#x2F;spark表的元数据。</li><li>external schema和schema的区别：<ul><li>external schema主要用于和hivemetastore建立连接，获取表对象元数据，在创建external schema时需要指定连接的所需要的各个属性值。</li><li>普通schema在创建后会将schema的信息记录到pg_namespace中，external schema创建后和普通schema一样也会记录在pg_namespace，可以通过pg_namespace中的nsptype字段区分，是external schema还是普通schema。除了存储在pg_namespace中的相关信息外，external schema连接相关的配置信息，都会记录在pg_external_namespace中。</li><li>external schema下不支持创建表对象。对象的创建是在hive或者spark中创建的。external schema 仅用于执行DML操作。</li></ul></li></ul></li></ul><ol start="2"><li>元数据访问：</li></ol><ul><li>创建Server, external schema, sql query查询</li><li>语法解析：语法解析层主要负责解析。当读取到ex.tbl表以后，连接HMS进行元数据查询。</li><li>元数据查询：从HMS中查询元数据信息，该步骤在步骤1中完成。从HMS中读取数据，主要包括列信息、分区信息、分区键信息、分隔符信息等。</li><li>数据查询（针对select）：从DFS存储中获取统计信息文件个数和文件大小，为plan生成提供依据。</li><li>查询重写、查询优化、查询执行。</li><li>查询下发：将元数据随plan下发到DN，DN收到plan以后，会将元数据进行解码后插入到syscache中</li><li>查询执行：DN访问obs对应文件，执行查询。</li></ul><p>基于公开来源信息, 学习资源来自<a href="https://connect.huaweicloud.com/courses/learn/Learning/sp:cloudEdu_?courseNo=course-v1:HuaweiX+CBUCNXBC006+Self-paced&courseType=1">华为云GaussDB(DWS)数据库官网</a></p>]]></content>
      
      
      <categories>
          
          <category> 数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GaussDB(DWS) </tag>
            
            <tag> 数据库 </tag>
            
            <tag> 数据仓库 </tag>
            
            <tag> 数据 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GaussDB(DWS)数据库-集群管理篇</title>
      <link href="/2025/08/04/GaussDB(DWS)%E6%95%B0%E6%8D%AE%E5%BA%93-%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86%E7%AF%87/"/>
      <url>/2025/08/04/GaussDB(DWS)%E6%95%B0%E6%8D%AE%E5%BA%93-%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86%E7%AF%87/</url>
      
        <content type="html"><![CDATA[<h3 id="集群创建与删除"><a href="#集群创建与删除" class="headerlink" title="集群创建与删除"></a>集群创建与删除</h3><ol><li>集群选型<ul><li>产品类型：云数仓、标准数仓、IoT数仓、实时数仓<ul><li>云数仓： 高性价比，支持冷热数据分析，存储、计算弹性伸缩，并按需、按量计价。适用于“库、仓、市、湖”一体化的融合分析业务，适合50节点以内的中小型数据仓库。</li><li>标准数仓：高性能、高扩展、高可用、易运维的企业级数据仓库，支持2048节点、20PB级超大规模数据分析能力。适用于大型企业数仓，上云后体验不变。</li><li>IoT数仓：在标准数仓基础上，提供高效的时序计算和IoT分析能力，支持实时和历史数据关联。适用于物联网、IoT等实时分析场景。</li><li>实时数仓：在大规模数据查询和分析能力基础上，提供高并发、高性能、低时延的事务处理能力。适用于HTAP混合负载场景，“一库两用，生产即分析”，支持单机部署和集群部署两种部署方式。</li></ul></li><li>选择好产品类型后，用户可以根据数据量、业务负载以及性能需求，选择能够支撑业务应用的集群规格和节点数量，CPU数和内存越大，数量越多，存储与计算能力越强。</li><li>刚开始使用DWS服务时，用户也可以先创建一个规格较小的集群，今后随着数据量和业务负载的变化，再自由扩展而不中断业务。</li></ul></li><li>增删CN:<ul><li>当用户的集群创建后，实际需要的CN数量会随着业务需求而发生变化，因此管理CN节点功能的实现，使用户可以根据实际需求动态调整集群的CN数量</li><li>集群创建时默认的CN数量为3，用户可以根据实际发放节点数量，调整CN数量，范围为2~20</li></ul></li><li>删除集群：<ul><li>当用户不再需要使用某个集群时，可以删除该集群。删除的集群无法恢复，同时集群中的用户数据、自动快照也会自动删除，而且无法再访问。删除集群时不会删除手动快照。</li><li>如果集群绑定了弹性IP，建议用户勾选“释放与集群绑定的弹性IP”,将待删除集群的弹性IP资源释放。如果选择不释放，弹性IP将保留，用户可以将该弹性IP绑定到其他DWS集群或者云资源上使用，该弹性IP将仍然按照虚拟私有云（VPC）服务的弹性公网IP计费规则进行计费。</li></ul></li></ol><h3 id="集群监控管理"><a href="#集群监控管理" class="headerlink" title="集群监控管理"></a>集群监控管理</h3><ol><li>节点监控：提供针对当前DWS中所有节点的资源使用情况明细<ul><li>概览：包含节点资源一览图<ul><li>内容：cpu资源使用率，内存资源使用率，数据盘的平均资源使用率，磁盘IO，TCP协议重传率，网络IO</li></ul></li><li>磁盘分页：提供细粒度的磁盘使用情况，说明节点各个磁盘及对应功能（数据盘，日志盘，系统盘）<ul><li>内容：磁盘容量，读速率，写速率，磁盘IO等待时间，磁盘IO服务时间，磁盘IOPS指标。</li></ul></li><li>网络分页：提供节点网卡的详细信息<ul><li>内容：展示名称，网卡状态，接收丢包数，接收速率，发送速率</li></ul></li><li>节点所有页面都可以通过“监控”列查看过去1小时，3小时，12小时，24小时，7天，15天的各个指标变化。</li></ul></li><li>性能监控：提供集群，数据库，节点三个维度相关指标过去一个月的变化趋势，并提供了监控面板供指标集中展示。<ul><li>集群维度的监控指标，包括CPU，内存，磁盘IO，网络IO，集群状态，集群中异常CN数量，SQL堆积数量。</li><li>数据库维度提供了活跃会话数，插入行数，删除行数，修改行数。</li><li>节点维度提供了所有节点相关资源使用情况，并支持对比不同节点的变化趋势。</li><li>集群监控支持查看时间： 过去1小时、3小时、12小时、24小时，7天查看时间，支持自定义时间范围。</li><li>数据库监控支持查看时间：过去1小时，3小时，12小时，24小时。</li></ul></li><li>实时查询：提供了当前系统中的会话和SQL执行情况，并提供了针对会话和查询的查杀功能。<ul><li>实时会话支持查看会话的执行时间，对应的应用名称，接入CN，锁持有状态，锁定对象可以用来排查系统中的长会话或者锁争抢问题。</li><li>实时查询提供了细粒度的查询相关资源使用情况，比如CPU，内存，IO，资源池，查询的排队状态等</li><li>会话和查询都支持根据某一条件查杀问题会话或查询。</li><li>会话：<ul><li>实时会话可以根据多条件过滤查看，当前系统中存在的锁持有的会话，当出现锁争抢是可以根据锁定对象，快速排查相关的执行SQL</li><li>实时会话主要是根据pg_stat_activity和pg_locks信息汇聚上报获取。实时会话默认是启用状态。</li></ul></li><li>查询：<ul><li>实时查询当前仅支持8.1.2以上集群使用，默认不打开，打开需要配置guc参数：enable_resource_track 需要配置为on，resource_track_cost需要根据需求配置，如果配置为0，对所有语句进行监控。</li><li>实时查询主要的是根据pg_session_wlmstat和gs_wlm_session_statistics信息汇聚上报获取。</li></ul></li></ul></li><li>资源池监控：主要反应集群资源池信息，包括CPU使用率，磁盘使用率，内存，语句并发等，可以实时反应集群资源池运行情况。</li><li>SQL诊断：<ul><li>针对已经执行完成的查询中，存在告警信息的SQL进行集中展示。</li><li>SQL诊断对于异常的查询会同步提供SQL语句和执行计划，还有语句的资源使用情况。</li><li>SQL诊断依赖历史查询功能，默认不打开，打开需要配置GUC参数。</li><li>历史查询功能主要是根据pgxc_wlm_session_info信息采集上报获取。</li></ul></li><li>SQL探针<ul><li>SQL探针工具，支持一键执行和定时执行两种探针任务等功能，并可以针对超时的探针SQL提供告警上报信息。</li></ul></li><li>表诊断：提供了集群中数据表，关键运行状态的统计数据和诊断工具。包括：<ul><li>表倾斜率：对于集群中数据表统计信息进行监控分析，展示倾斜率高于5%并且表大小TOP 50的表信息。<ul><li>造成表倾斜率高的原因为不合理的分布列选择，将引发算子计算&#x2F;数据下盘倾斜严重，导致不同的DN的处理压力不同，影响业务性能，并容易造成单DN磁盘使用率过高。</li><li>用户可以通过查询表倾斜率，根据表的大小和倾斜率，对倾斜严重的表重新选择分布列，其中8.1.0及以上集群版本，可以直接通过alter table 语法进行调整表。</li></ul></li><li>表脏页率：对于集群中数据表统计信息进行监控分析，展示脏页率高于50%并且表大小TOP 50的表信息。<ul><li>对于数据表的DML操作将影响数据表数据，导致存在无用的脏数据，过多的脏数据将占据磁盘空间，影响集群可用容量。用户可以通过查询表的脏页率，根据表的大小和脏页率，对较大表和脏页率过高的表进行处理。</li><li>对于脏页率高的表，可以通过手动执行vacuum full操作回收表空间，或者通过“智能运维”操作时执行vacuum full操作。</li></ul></li><li>DDL审核：DDL审核是SQL审核范畴，为了避免不合理的DDL设计影响实际业务运行，该工具会对DDL元数据进行规范性检测，方便用户对潜在的表定义问题提前感知，其结果也可作为性能问题定位的参考数据之一。<ul><li>DDL审核对于审核不通过的数据表，可以通过详情页面查看问题。</li></ul></li></ul></li><li>告警管理<ul><li>包含:查看告警规则，告警规则配置，告警信息订阅功能</li><li>告警规则可以提供过去一周的告警信息统计和告警信息明细，方便用户自行查看租户下的告警。该特性除了以默认值的形式提供一套DWS告警最近实践外，还允许用户根据自己的业务特点，个性化修改告警阈值。</li><li>告警管理通过消息通知服务（Simple Message Notification，SMN）发送DWS告警通知，用户可订阅告警启用通知。</li><li>告警规则配置：<ul><li>当前支持11种告警规则的配置。告警支持启停，只对部分集群生效。当前告警规则是诊断整个租户的告警规则生效。资源类有CPU,磁盘innode,磁盘使用率，磁盘I&#x2F;O时延。业务类有语句堆积告警，语句下盘量过大告警，vacuum full 执行过长告警，资源池队列阻塞告警。工具类有SQL探针执行耗时超阈值。</li></ul></li><li>dws监控系统使用典型场景：<ul><li>磁盘使用率高：配置节点数据盘使用率告警，根据实际需要配置阈值，如果发现该告警上报，则进一步排查系统的磁盘使用情况。</li><li>磁盘只读问题：当发现数据盘使用率高，先查看“工具&#x2F;表诊断&#x2F;表脏页率”，对于脏页率较高的表数据，可以通过vacuum full做清理。如果清理之后可以解决，则可以通过配置智能运维，定位执行vacuum full。如果清理之后磁盘使用率还是较高，则需要重新评估当前系统的规格是否符合业务要求。</li></ul></li></ul></li></ol><h3 id="集群备份恢复管理"><a href="#集群备份恢复管理" class="headerlink" title="集群备份恢复管理"></a>集群备份恢复管理</h3><ol><li>快照：<ul><li>定义：快照是对DWS集群在某一时间点的一次全量数据和增量数据的备份，记录了当前数据库的数据以及集群的相关信息，其中包括节点数量、节点规格和管理员用户名称等。快照创建方式包括手动创建快照和自动创建快照。</li><li>备份：创建快照会将生成的备份文件存储到指定的备份介质中。华为云支持备份介质包括OBS(Object Storage Service)、SFS(Scalable File Service)</li><li>DWS提供免费的快照存储空间，免费容量等于集群储存空间，当快照数据存储空间超过免费空间大小时，超过部分按照OBS的计费规则进行计费。</li><li>手动快照要点：<ul><li>手动快照支持集群级全量快照和schema级快照</li><li>快照级别支持“cluster”和“schema”。schema级别快照依赖版本细粒度备份的特性开关。</li><li>集群名称可选择一个指定集群，只能选择可用状态的集群。</li><li>手动快照创建成功后会一直保存，直到从控制台中将其删除（即使集群删除，手动快照也不会删除。）</li></ul></li><li>自动快照：<ul><li>集群级自动快照采用差异增量备份，第一次创建自动快照为全量备份，以后每间隔一段时间就会做一次全量备份，全量备份作为基础版本。两次全量备份之间都是做增量备份，增量备份记录基于前一次备份所发现的更改。</li><li>集群创建时，自动快照默认处于启用状态。自动增量快照默认为每8小时一次，全量快照每周日执行一次，快照保留期可设置为1-31天，默认为3天。用户也可以根据自身需求设置自动快照策略。</li><li>在策略列表中自动快照开关默认为开启状态，保留天数默认为3天。</li><li>关闭自动快照后，自动删除历史自动快照。</li><li>快照类型设置为全量快照时，快照策略可选一次性和周期性</li><li>快照策略时间需要设置为UTC，同时需要考虑业务所在时区的时差</li></ul></li><li>快照恢复：<ul><li>使用增量快照恢复时，DWS会将最近一次的全量备份到本次快照之间的所有快照，一起用于恢复集群。</li><li>恢复快照到新集群时，恢复时长是由快照备份的数据量所决定的。</li><li>恢复快照时，参数支持重新定义。其他默认参数默认与快照中的备份信息保持一致。</li><li>规格确认无误后，便可执行恢复。待新集群状态变为“可用”，表示快照已恢复成功。</li><li>集群级恢复支持恢复到当前集群。</li><li>细粒度表级恢复：支持恢复单表和多表操作，依赖细粒度备份和细粒度恢复的特性白名单</li></ul></li></ul></li></ol><h3 id="集群容灾管理"><a href="#集群容灾管理" class="headerlink" title="集群容灾管理"></a>集群容灾管理</h3><ol><li>概述：广义上，容灾是一个系统工程，包括所有与业务连续性相关的内容。对于IT而言，容灾是提供一个能防止用户业务系统遭受各种灾难影响破坏的计算机系统。狭义的容灾是指建立两套或多套功能相同的IT系统，互相之间可以进行健康状态监视和功能切换，当主要站点因为意外（如火灾、地震、城市供电中断等）停止工作时，整个应用系统可以利用辅助站点快速恢复，并继续工作。</li><li>容灾目的：容灾的主要目的是，当自然或人为的原因，导致生产系统发生灾难时，能够尽可能地保证业务的连续性。</li><li>容灾和备份的区别 ：<ul><li>容灾主要针对火灾、地震等重大自然灾害，因此生产站点和容灾站点之间，必须保证一定的安全距离；备份主要针对人为误操作、病毒感染、逻辑错误等因素，用于业务系统的数据恢复，数据备份一般是在同一数据中心进行。</li><li>容灾系统不仅保护数据，更重要的目的在于业务的连续性；而数据备份系统只保护不同时间点版本数据的可恢复。一般首次备份为全量备份，所需的备份时间会比较长，而后续增量备份则在较短时间内就可完成。</li><li>容灾的最高等级可实现RPO&#x3D;0;备份可设置一天最多24个不同时间点的自动备份策略，后续可将数据恢复至不同的备份点。</li><li>故障情况下（例如地震、火灾），容灾系统的切换时间可降低至几分钟；而备份系统的恢复时间可能几小时到几十小时。</li></ul></li><li>RPO和RTO:<ul><li>RPO(Recovery Point Objective):即数据恢复点目标，主要指的是业务系统所能容忍的数据丢失量</li><li>RTO(Recovery Time Objective):即恢复时间目标，主要指的是所能容忍的业务停止服务的最长时间，也就是从灾难发生到业务系统恢复服务功能，所需要的最短时间周期。</li></ul></li><li>双集群容灾：<ul><li>容灾原理：<ul><li>生产集群（原集群）周期性做Roach备份，备份文件被同步scp到灾备集群。灾备集群（新集群）周期性做Roach恢复，灾备集群执行恢复操作期间，需要停止集群，其余时间可对外提供查询服务。生产集群故障后，通过switchover&#x2F;failover命令将灾备集群升主，业务由灾备集群接管。</li></ul></li><li>容灾能力：GaussDB内核已具备该能力，DWS管控面已集成该能力</li><li>方案限制：<ul><li>两套集群节点数可以不同，但实例逻辑拓扑要一致，主要指总DN个数需要相同。</li><li>当前支持集群级别的数据同步，也支持细粒度的容灾，但是细粒度容灾受限于白名单使用。</li><li>要求灾备集群具有足够的磁盘空间，存放完整的全量备份集（通常要求是集群数据量的两倍以上）</li></ul></li><li>性能说明：<ul><li>RPO和RTO主要取决于增量数据同步的性能，以及增量同步的周期间隔。对于典型的主、备集群部署场景（物理机、SAS盘、集群内万兆网卡、集群间千兆网卡），在1T&#x2F;天的数据增速下（集群节点数在30个以上时），最小可达RPO 1小时，最小可达RTO 1小时。带宽不是瓶颈的情况下，增量数据同步的性能至少在 30 MB&#x2F;S&#x2F;DN.</li></ul></li></ul></li></ol><h3 id="集群弹性伸缩管理"><a href="#集群弹性伸缩管理" class="headerlink" title="集群弹性伸缩管理"></a>集群弹性伸缩管理</h3><ol><li>节点扩容：<ul><li>集群磁盘容量使用超过70%时进行扩容。</li><li>在扩容配置中，默认配置将不使用在线扩容，并在扩容后自动进行离线重分布。</li><li>如果使用在线扩容，默认将在扩容之后进行在线重分布操作。</li><li>在线扩容以及在线重分布，相比离线模式对业务影响较小。在线重分布期间，用户可以对表执行插入、更新、删除，但重分布过程仍然会短时间阻塞用户的数据更新操作，会影响用户语句的执行性能。</li><li>扩容重分布过程会消耗大量的CPU和IO资源，因此也会对用户作业性能影响较大，用户应该尽可能在停止业务情况下或业务轻载的情况下，执行扩容重分布。</li></ul></li><li>如果用户的集群是EVS盘的云数仓类型，并且只是磁盘空间出现瓶颈，计算资源比较充足，用户可以通过磁盘扩容快速缓解存储资源不足的问题，磁盘扩容过程中无需暂停业务，并且不会造成CPU、内存等资源浪费。</li><li>节点缩容：当用户的计算或者存储资源冗余，超出业务需求时，可在控制台对已有集群进行缩容操作，以便节省成本。集群缩容时只能以安全环为单位减少集群节点的个数，比如用户的集群有9个节点，每3个节点为一个安全环，那么只能选择缩3个节点和6个节点。</li></ol><h3 id="集群资源管理"><a href="#集群资源管理" class="headerlink" title="集群资源管理"></a>集群资源管理</h3><ol><li>为解决用户资源隔离，以实现业务优先级，避免复杂业务阻塞资源，引入了资源池，每个资源池指定可以使用的CPU，内存、磁盘等大小，然后将用户与资源池关联，用户在使用时就只能使用该资源池可以使用的资源，以达到资源限制的目的。</li><li>创建资源池：<br>  用户可以对资源池进行创建、删除、修改（配置，异常规则，关联用户）等操作，队列的参数表示对该资源池的限制，其中CPU有配额和限额两个维度限制。配额：当多个资源池同时在一个CPU上执行时，各自使用时间比例。限额：限定该资源池可以运行的CPU数量。</li><li>创建资源管理计划：<br>  资源管理计划用于自动化的、周期性的对资产池中的资源进行变更，以便实现灵活的资源管理，如果有多个计划，只能生效一个。</li><li>schema空间管控:<br>  模式空间管理，用于对模式空间大小的限额。</li></ol><h3 id="智能运维"><a href="#智能运维" class="headerlink" title="智能运维"></a>智能运维</h3><ol><li>概念:<br>  智能运维是DWS的常驻运维工具，可以帮助用户智能执行运维任务。智能运维会通过集群负载情况，选择合理时间窗、并发度完成用户指定的任务，在运维任务执行过程中，智能运维将时刻关注用户业务的变化，及时调整运维任务执行策略，以减轻对用户业务的影响。智能运维支持周期型和单次型任务的创建，执行时间窗可按照不同用户业务负载定制化。智能运维具备一定的高可用性，在集群异常的情况下，智能运维将重新执行失败的运维任务，若由于集群异常导致运维任务部分步骤无法完成，智能运维将尝试跳过失败的步骤，以节省用户运维时间窗的开销。</li><li>运维计划：<br>  用户可以对运维任务进行创建、删除和修改等操作。调度模式支持自动、指定目标和优先级模式。运维任务可支持单次型和周期型。周期时间窗时间设置为默认为本地时间，请您根据业务所在时区结合时差设置该项。同一天的时间段请不要重叠。</li><li>运维状态：<br>  在运维详情部分切换至运维状态模块。可查看运维任务运行的详细信息，状态包括：Waiting、Running、Finished和Canceled</li></ol><p>基于公开来源信息, 学习资源来自<a href="https://connect.huaweicloud.com/courses/learn/Learning/sp:cloudEdu_?courseNo=course-v1:HuaweiX+CBUCNXBC006+Self-paced&courseType=1">华为云GaussDB(DWS)数据库官网</a></p>]]></content>
      
      
      <categories>
          
          <category> 数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GaussDB(DWS) </tag>
            
            <tag> 数据库 </tag>
            
            <tag> 数据仓库 </tag>
            
            <tag> 数据 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GaussDB(DWS)数据库-性能调优和开发实践篇</title>
      <link href="/2025/08/04/GaussDB(DWS)%E6%95%B0%E6%8D%AE%E5%BA%93-%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%92%8C%E5%BC%80%E5%8F%91%E5%AE%9E%E8%B7%B5%E7%AF%87/"/>
      <url>/2025/08/04/GaussDB(DWS)%E6%95%B0%E6%8D%AE%E5%BA%93-%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%92%8C%E5%BC%80%E5%8F%91%E5%AE%9E%E8%B7%B5%E7%AF%87/</url>
      
        <content type="html"><![CDATA[<h3 id="性能调优"><a href="#性能调优" class="headerlink" title="性能调优"></a>性能调优</h3><ol><li>定义：通过优化数据库系统的配置及SQL查询，以提高数据库性能和效率的过程。目的是消除性能瓶颈、减少响应时间、提高系统吞吐量和资源利用率，降低业务成本，从而提高系统稳定性，给用户带来更大的价值。</li><li>SQL执行计划解析, 执行计划命令：<ul><li>EXPLAIN VERBOSE + SQL语句(select&#x2F;update&#x2F;insert&#x2F;delete&#x2F;merge into&#x2F;create table as):获取详细执行信息，SQL语句不会真正执行 verbose</li><li>EXPLAIN PERFORMANCE+ SQL语句(select&#x2F;update&#x2F;insert&#x2F;delete&#x2F;merge into&#x2F;create table as):获取详细执行信息。performance</li></ul></li><li>verbose选项下打印详细计划信息中，plan information信息包括：<ul><li>E-rows:算子估算输出行数</li><li>E-distinct:单DN上算子distinct估计值</li><li>E-memory:DN上每个算子估算的内存使用量，只有DN上执行的算子才会显示。某些场景会在估算的内存使用量后面使用括号，表示该算子在内存资源充足下的自动扩展内存上限。</li><li>E-width:每个算子输出元祖的估算宽度</li><li>E-costs:每个算子估算的执行代价</li></ul></li><li>performance选项下打印执行信息中，和verbose相比，新增的相关信息：<ul><li>A-time：算子实际执行时间，在DN上输出由[]括起来的，由逗号分割的两个值，分别表示算子在不同DN上执行的最短时间和最长时间。</li><li>A-row：算子实际输出元祖数，是各个DN上算子输出元祖数总和。</li><li>Peak memory：算子消耗内存峰值，在DN上输出由[]括起来的，由逗号分割的两个值，分别表示算子在不同DN上执行的最小内存消耗和最大内存消耗。</li><li>A-width：算子每行元祖实际宽度，仅涉及重内存使用算子。</li></ul></li><li>performance选项打印执行中的相关信息：<ul><li>plan information:以表格形式显示整个执行过程中每个算子的执行概要信息。</li><li>SQL Diagnostic information:SQL自诊断信息<ul><li>verbose可诊断：统计信息未收集、分区不剪枝、SQL不下推</li><li>performance可诊断：统计信息未收集、分区不剪枝、SQL不下推、HashJoin中大表做内表、大表等值连接使用Nestloop、大表Broadcast、数据倾斜、索引不合理。</li></ul></li><li>predicate information:算子计算信息，如scan的filter条件，join的join条件</li><li>Datanode information:算子在每个DN上执行的详细信息，包括执行时间、CPU、Buffer的使用情况。<ul><li>执行时间（actual time）:如果这个值在各DN上存在较大差异，可初步判断存在计算倾斜（各DN上承担计算量差异过大）</li><li>输出元祖数（rows）:结合执行时间进一步佐证是否存在计算倾斜。</li><li>CPU执行cycle:在算子执行期间，执行所消耗的CPU cycle</li><li>Buffer命中率（hit）:针对Scan算子做数据扫描时。从性能角度看，buffer命中率越高越好，这需要增大集群的shared_buffers(行存)、cstore_buffers(列存)的配置参数。</li></ul></li><li>User Define information:性能profile信息，算子执行过程中的，关键动作性能打桩信息。</li><li>Memory information:算子执行过程中的内存消耗信息。包括内存信息和下盘信息。</li><li>Query Summary:query执行的概要信息。这部分打印总的执行时间和网络流量，包括各DN上初始化和结束阶段的最大最小执行时间、CN上的初始化、执行、结束阶段的时间、以及当前语句执行时系统可用内存、语句估算内存等信息。</li></ul></li><li>性能分析主要关注Plan information&#x2F;SQL diagnostic ioformation&#x2F;predicate information&#x2F;Datanode information这4部分信息。在大集群下，对复杂SQL，建议使用explain analyze 打印概要的实际执行信息，避免打印各个节点信息太多导致执行计划过长</li><li>执行计划类型：3种<ul><li>FQS计划（fast query shipping）<ul><li>CN直接将原语句下发的DN,各个DN单独执行，并将执行结果在CN上汇总。</li></ul></li><li>Stream计划：<ul><li>算子形态：GATHER&#x2F;REDISTRIBUTE&#x2F;BROADCAST</li><li>CN根据原语句先生成执行计划，再将计划下发到DN执行，各DN执行过程中使用Stream算子进行数据交互。</li></ul></li><li>Remote Query计划<ul><li>CN生成执行计划后，将部分原语句下发到DN,各DN单独执行，执行后将结果发送给CN，CN执行剩余计划。</li></ul></li><li>Explain执行计划:<ul><li>ANALYZE | ANALYSE :显示实际运行时间和其他统计数据</li><li>VERBOSE:显示有关计划的额外信息，例如输出列信息。</li><li>COST: 包括每个规划节点的估计总成本，以及估计的行数和每行的宽度。</li><li>CPU: 打印CPU的使用情况信息。</li><li>DETAIL:打印DN上的信息。</li><li>NODES:打印query执行的节点信息</li><li>NUM_NODES:打印执行中的节点个数信息</li><li>BUFFERS:包括缓冲区的使用情况信息</li><li>TIMING:包括实际的启动时间和花费在输出节点上的时间信息。</li><li>PLAN:是否将执行计划存储在plan_table中。</li><li>FORMAT:指定输出格式</li><li>GENERIC:显示将语句中的常数替换为参数后生成的generic计划</li></ul></li></ul></li><li>TopSQL：<ul><li>定义：将SQL的排队信息、运行信息（耗时、CPU、内存、IO、网络、空间）记录到一张系统表中，即作业级监控。</li><li>功能：<ul><li>确定影响数据库性能资源最密集的SQL查询</li><li>监控和跟踪SQL查询，随时间推演的性能变化</li><li>分析查询执行计划，以确定潜在的优化</li></ul></li><li>分类:实时&#x2F;历史, 当前CN&#x2F;全部CN,级别都是query<ul><li>实时当前CN:GS_WLM_SESSION_STATISTCS</li><li>实时全部CN:PGXC_WLM_SESSIOIN_STATISTICS</li><li>历史当前CN:GS_WLM_SESSION_INFO</li><li>历史全部CN:PGXC_WLM_SESSION_INFO</li></ul></li></ul></li><li>历史TopSQL：<ul><li>Topsql主要是通过视图进行承载，按照级别分为query&#x2F;perf&#x2F;operator</li><li>query:SQL语句的计划信息，类似于explain输出信息，记录到Topsql中。</li><li>perf:包含实际执行时间和执行行数的计划信息，类似于explain analyze输出信息，记录到Topsql中。</li><li>operator:不仅会把包含实际执行时间和执行行数的信息记录到TopSql中，还会把算子级别执行信息，记录到Topsql中.</li></ul></li><li>历史TopSQL视图记录了作业运行结束时的资源使用情况、运行状态信息和性能告警信息。<ul><li>分类：级别（query&#x2F;perf+operator）+当前CN&#x2F;全部CN</li><li>query&#x2F;perf级别当前CN: GS_WLM_SESSION_INFO</li><li>query&#x2F;perf级别全部CN: PGXC_WLM_SESSION_INFO</li><li>operator级别当前CN:GS_WLM_OPERATOR_INFO</li><li>operator级别全部CN:PGXC_WLM_OPERATOR_INFO</li></ul></li><li>TopSQL配置GUC参数：<ul><li>实时TopSQL参数：运行中的语句记录<ul><li>enable_resource_track(ON):资源实时监控开启，实时TopSQL总开关，关闭后实时TopSQL不再记录，不会出现在历史TopSQL中。</li><li>resource_track_cost(0):执行代价阈值，对当前会话语句进行资源监控的，最小执行代码。</li><li>resource_track_level(query):资源监控等级，当前会话的资源监控等级，默认为query级别。</li></ul></li><li>历史TopSQL参数：运行完成的语句记录<ul><li>enable_resource_record(on):资源监控记录归档，开启后，执行结束的记录会分布归档到相应INFO视图，CN和DN都需要设置上。</li><li>resource_track_duration(60s):作业运行时间阈值，实时TopSQL中记录的语句执行结束后，进行历史转存的最小执行时间，其判断包含排队时间和运行时间，当排队时间+运行时间&gt;resource_track_duration时，Topsql历史视图会记录作业信息。当执行完成的作业，其执行时间不小于此参数值时，作业信息会从实时视图（statistics为后缀的视图）转存到相应的历史视图。</li><li>topsql_retention_time(30天):历史数据老化周期，历史TopSQL当前CN视图（GS_WLM_SESSION_INFO、GS_WLM_OPERATOR_INFO）中数据保持时间，单位为天。</li></ul></li><li>数据流转过程：作业运行-&gt;运行信息记录实时Topsql-&gt;作业运行结束-&gt;执行信息记录历史Topsql-&gt;结束。</li></ul></li></ol><h3 id="SQL调优"><a href="#SQL调优" class="headerlink" title="SQL调优"></a>SQL调优</h3><ol><li>调优原则：也是唯一原则，资源利用最大化原则.其中资源包括CPU、内存、磁盘IO、网络IO,SQL语句应当尽量高效、节省资源开销，即以最优的执行方式实现功能。SQL语句应当充分利用资源，实现性能极致。</li><li>调优分类和流程：先静态调优，再动态调优<ul><li>静态调优：根据硬件资源和客户的业务特征，确定集群部署方案和表定义。集群部署方案和表定义一旦确定，后续改动的代价会比较大。</li><li>动态调优：根据SQL语句执行的实际情况，采取针对性干预SQL执行计划的方式，提升性能。采取的手段包括：SQL改写，GUC参数干预，Plan Hint</li></ul></li><li>静态调优手段(5种):表定义、存储类型、分布列、局部聚簇、分区表<ul><li>表定义的目的：<ul><li>表数据均匀分布在各个DN，选择合适分布列避免数据分布倾斜，防止单个DN数据过多导致集群有效容量下降。</li><li>表Scan压力均匀分布在各个DN,避免单DN的scan压力过大，形成scan的单节点瓶颈。避免把基表上的等值filter中的列作为分布列。</li></ul></li><li>存储类型：<ul><li>用途：客户业务属性决定表的存储类型；存储类型决定存储格式，进而影响I&#x2F;O操作行为。</li></ul></li><li>分类：<ul><li>行存：适合点查询（返回记录少，基于索引的简单查询），增删改比较多的场景</li><li>列存：统计分析类查询（group, join 多的场景），即席查询（查询条件列不确定，行存无法确定索引）</li></ul></li><li>分布列：<ul><li>分布列选择原则：列值应比较分撒，以便数据能够均匀分布都各个DN上。尽量不要选择存在常量等值过滤条件的列，避免DN剪枝后Scan集中到一个DN上。选择查询中的连接条件为分布列，以便join任务能够下推到DN中执行，而且可以减少DN间的通信数据量，建议选择join-condition或者group by 列为分布列。根据以上原则尽量根据业务特征选择hash分布方式，无法确定时可以选择roundrobin分布：</li></ul></li><li>分布方式：复制（Replication）、哈希（Hash）、轮询（RoundRobin）<ul><li>复制Replication:在集群中的每个DN实例上都有一份全量表数据。存在数据冗余。适用于小表、维表。join操作可减少重分布造成的网络开销。</li><li>哈希（Hash）：数据通过hash方式散列到集群的所有DN实例上。适用于数据量大的表。读写数据可充分利用各个节点IO资源，提升读写速度。</li><li>轮询（RoundRobin）：数据通过轮询方式发放到集群内所有DN实例上。适用于数据量大的表，而且各列都有严重倾斜的表。读写数据可充分利用各个节点IO资源，提升读写速度。</li><li>分布方式分析和调整<ul><li>判断数据是否存在存储倾斜：table_distribution()，不同DN的数据量，相差5%以上即可视为倾斜，相差10%以上，建议调整分布列。</li><li>在线判断数据列是否存在倾斜：table_skewness()，</li><li>调整分布列语法：<code> bash alter table table_name distribution by hash()/replication/roundrobin;</code></li></ul></li></ul></li><li>局部聚簇（Partial Cluster Key，简称PCK）：<ul><li>定义：列存储下的，一种通过min&#x2F;max稀疏索引，实现基表快速扫描的，一种索引技术。</li><li>优化原理：入库时进行局部排序，来换取查询性能</li><li>使用约束:列存表，一个列存表只能创建一个PCK。适用数据类型包括整型、时间类型和字符串类型。对于字符串数据类型，如果当前库的collate不为C，则只对表达式col &#x3D; Const起大加速查询的效果</li><li>使用场景：<br>  -业务特征：大表大批量数据导入，每次导入数据量远大于DN数*6W。<br>  -基表存在大量形如col op Const约束，其中col为列名，const为常量值，op为操作符&#x3D;，&lt;, &gt; ,&lt;&#x3D;, &gt;&#x3D;<br>  -选择选择度比较高的简单表达式的列，建立PCK</li><li>使用方法：在创建表的时候，指定PCK约束。在alter table语法中添加PCK约束（只对后续导入数据生效）</li></ul></li><li>分区表<ul><li>定义：把逻辑上的大表按照某种策略划分为几块物理块进行存储，逻辑上的大表成为分区表，每个物理块为一个分区。</li><li>原理：在查询时，通过分区剪枝技术来尽可能减少底层数据扫描。</li><li>适用场景：数据规模上的大表，业务特征为通过剪枝缩小查询范围。</li><li>优势：改善查询性能、增强可用性、方便维护。</li><li>分区键选择：将数据可以均匀映射到各个分区的列，常见分区键为时间列。</li><li>分类：range分区和list分区</li></ul></li></ul></li><li>执行计划：<ul><li>执行计划三要素：统计信息、优化器、配置参数<ul><li>统计信息（表的数据特征）：包括表的元祖数，字段宽度、null记录比率，distinct值，MCV值（most common value）、hb值（直方图，数据分布概览区间）</li><li>优化器（Cost-Based Optimization,CBO，基于代价的优化）：数据库根据大量的表数据特征，结合代价计算模型，通过代价估算，输出估算后的最优执行计划。其中统计信息是查询优化的核心输入，准确的统计信息可以帮助优化器选择最合适的查询计划。</li><li>配置参数：GUC参数和HINT信息。配置参数直接干预优化器的路径选择。</li><li>统计信息收集：使用analyze语法来收集整个表或者表的若干列统计信息。</li><li>操作：大批量数据导入、更新、删除之后，及时analyze.</li></ul></li><li>执行计划流程：<ul><li>词法&amp;语法解析：按照约定SQL语句规则，输入SQL语句从字符串转化为格式化结构（Stmt）</li><li>语义解析: 格式化结构转化为数据库可识别对象</li><li>查询重写：根据规则，将语义解析的输出，等价转化为执行上更为优化的结构。</li><li>查询优化：根据“查询重写”的输出和数据库内部的统计信息，规划SQL语句的具体执行方式。</li><li>查询执行：根据“查询优化”规划的执行路径，执行SQL查询语句。</li></ul></li></ul></li><li>动态调优：即执行态调优<ul><li>定义：先跑query，判断性能是否满足客户需求，如果不满足，则进一步分析性能瓶颈点，进行针对性优化，重新试跑，一直到满足性能目标为止。</li><li>步骤：<ul><li>判断查询相关表是否已收集统计信息</li><li>判断查询语句是否下推</li><li>收集perfromance信息进行性能分析，并做针对性优化</li><li>SQL改写优化</li></ul></li><li><strong>统计信息收集</strong>：对统计信息前后的执行计划，做对比分析<ul><li>E-rows：在没有收集统计信息的执行计划中，估计值E-row会比实际值小</li><li>执行计划：在没有收集统计信息的执行计划中，出现两个低效的Nest loop算子。</li></ul></li><li><strong>查询语句下推</strong>：<ul><li>执行计划类型：并行计算能力是DWS数据库的性能优势</li><li>优化器在分布式框架下有三种执行规划策略：<ul><li>下推语句计划：CN发送查询语句到DN直接执行，执行结果返回给CN.计划特征：<em>REMOTE_FQS_QUERY</em></li><li>分布式计划：CN先生成计划树，再发送计划树给DN执行，DN执行完成后，执行结果返回给CN.计划特征：Streaming(type: GATHER)</li><li>不下推计划：CN承担大量计算任务，导致性能劣化。优化器先将部分查询（多为基表扫描语句）下推的DN中执行，将中间结果返回给CN,CN再执行执行计划剩下的部分。执行计划特征：REMOTE_XXX + Coordinator quals</li></ul></li></ul></li><li><strong>不下推分析</strong>：<ul><li>常见不下推原因：含有shippable属性且为false的函数语句不下推。</li><li>问题定位手段：<ul><li>Explain performance&#x2F;Explain verbose：对正在执行的SQL，使用explain performance&#x2F;explain verbose,在输出的自诊断信息（SQL Diagostic information）中会提示具体的不下推原因。</li><li>TopSQL：历史执行信息会记录到系统表中，使用postgres库中的查询视图（历史全部DN的perf级）pgxc_wlm_session_info，获取历史SQL的执行信息，此表中的warning字段会记录对应的SQL语句不下推原因。</li></ul></li></ul></li><li><strong>performance分析</strong><ul><li>explain performance优化：收集query执行信息，分析可能的性能问题，针对性优化</li><li>重点关注信息：<ul><li>算子：耗时占整体执行时间高的算子</li><li>执行信息：DataNode information、Memory information、Targetlist information</li></ul></li><li>算子瓶颈和优化策略：<ul><li>Scan性能瓶颈：基表扫描元组数过多场景：增加索引，使用PCK， 使用分区</li></ul></li><li>性能提升策略：<ul><li>减少实际IO：针对点查询场景：增加索引，使用PCK(列存表)；针对范围查询场景：使用分区（优化IO）</li><li>数据在各个DN分布不均衡场景：调整分布列方式。把Scan压力分散到各个DN上：是指数据倾斜，IO压力分布不均衡，performance信息中各DN扫描时间存在明显差异，优化策略是修改分布列</li></ul></li></ul></li></ul></li><li>Join性能瓶颈：<ul><li>join方式选择不当场景：使用plan hint，增加索引</li><li>join内外表选择不当场景：使用plan hint，改写SQL</li><li>join类型：<ul><li>定义：表链接join，根据特定规则从两个其他表（真实表或者生成表）中派生出的结果集。</li><li>类型：在语法层，内连接（inner join）、外连接（outer join）、交叉连接（笛卡尔积， cross join）。inner是缺省的，left、right、full都是外连接，连接条件在on或using子句中指定。在内置实现支持：半连接（Semi join，in约束转化生成， 匹配上即命中）、反半连接（Anti Join, NOT IN约束转化生成，匹配上即排除）</li></ul></li><li>join性能提升策略：<ul><li>选择高效的join方式：通常情况下，hashjoin较为高效。改写SQL实现hashjoin,可以尝试将不等值join条件转化等值join条件。在部分特定场景下，nestloop+indexScan性能更好</li><li>选择合适的内外表：hashjoin：内表小，外表大，执行更高效。或者使用plan hint 调整内外表顺序。</li></ul></li></ul></li></ol><h3 id="plan-hint"><a href="#plan-hint" class="headerlink" title="plan hint"></a>plan hint</h3><ol><li>定义：可直接影响执行计划生成的手段，目的是通过对执行计划的调优，提升查询性能。</li><li>常见hint调优手段：<ul><li>指定scan方法</li><li>指定join方法、join顺序和join时的stream策略</li><li>指定估算行数</li><li>指定重分布过程中的倾斜信息</li><li>配置参数的hint</li></ul></li><li>使用要求：<ul><li>plan hint仅支持在select关键字后面通过如下形式指定。</li><li>可以同时指定多个hint，不同hint信息使用空格分隔。</li><li>配置参数之外的hint 只能hint当前层的计划，对于子查询计划中的hint，需要在子查询的select关键字后面指定hint信息。</li><li>在视图定义时指定hint， 该视图每次被调用时都会使用该hint信息。</li><li>在视图定义时指定hint， 该视图每次被调用时都会使用该hint信息。表只能用单个字符串表示，不能带schema；表如果存在别名，需要优先使用别名来表示该表。</li></ul></li><li>语法格式：<ul><li>在视图定义时指定hint， 该视图每次被调用时都会使用该hint信息。指定scan方法：[no] tablescan|indexscan|indexonlyscan(table [index]): no表示hint的scan方式不使用。table表示hint指定的表，只能指定一个表，如果表存在别名，应该优先使用别名进行hint。index表示使用indexscan或者indexonlyscan的hint时，指定的索引名称，当前只能指定一个。</li><li>在视图定义时指定hint， 该视图每次被调用时都会使用该hint信息。指定join方法：[no] nestloop|hashjoin|mergejoin(table_list):no表示hint的join方式不使用。table_list是hint表集合的字符串，中间不允许出现括号指定join的优先级。<ul><li>仅指定join顺序，不指定内外表顺序：leading(join_table_list)</li><li>同时指定join顺序和内外表顺序，内外表顺序仅在最外层生效：leading((join_table_list))</li></ul></li><li>在视图定义时指定hint， 该视图每次被调用时都会使用该hint信息。指定估算行数：rows(table_list #|+|-|* const):<ul><li>支持#，+，-，*四种操作符，#表示直接使用后面的行数，替换优化器中的估算行数，+、-、*表示对原来估算的行数进行加减乘操作。</li><li>运算后的行数最小值为1行。table_list为hint对应的单表或者多表join结果集，与join的hint中的table_list相同。</li><li>const可以是任意非负数，支持科学计数法</li><li>支持绝对值和相对值的hint，常用于多表的join时，中间结果集估算表不准的场景。</li></ul></li><li>在视图定义时指定hint， 该视图每次被调用时都会使用该hint信息。join顺序和join时的stream策略：[no] broadcast|redistribute(table_list):no表示hint的stream方式不使用。table为进行stream操作的单表或者多表join结果集。<ul><li>stream hint 和join hint配合使用，先hint明确join顺序，然后hint明确中间结果集的数据流动方式。</li></ul></li></ul></li></ol><h3 id="SQL改写"><a href="#SQL改写" class="headerlink" title="SQL改写"></a>SQL改写</h3><ol><li>相关子链接改写：<ul><li>场景：子查询和子链接性能较差。大部分场景，可提升为join进行优化；小部分场景，需要用户改写SQL进行优化。</li><li>改写策略：在语义等价前提下，将子链接和子查询的查询语句，提升到外层查询进行关联查询。</li></ul></li><li>join条件改写：等值join条件的join列增加非空过滤条件<ul><li>场景：等值join，而且join列存在大量的null</li><li>优化原理：null值和任何值比较的结果都是null，而且通过给关联列添加is not null，降低基表扫描输出的数据量，从而减少参与join运算的数据量</li></ul></li><li>not in改写：not in 转为not exists<ul><li>场景：子链接输出列上不存在null值，或者逻辑判断语义上不需要比较null值。</li><li>优化原理：只输出where条件为true的结果。null 和任何值的比较操作都是null。null和bool类型的逻辑运算。</li></ul></li></ol><p>基于公开来源信息, 学习资源来自<a href="https://connect.huaweicloud.com/courses/learn/Learning/sp:cloudEdu_?courseNo=course-v1:HuaweiX+CBUCNXBC006+Self-paced&courseType=1">华为云GaussDB(DWS)数据库官网</a></p>]]></content>
      
      
      <categories>
          
          <category> 数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GaussDB(DWS) </tag>
            
            <tag> 数据库 </tag>
            
            <tag> 数据仓库 </tag>
            
            <tag> 数据 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GaussDB(DWS)数据库-导入导出篇</title>
      <link href="/2025/08/03/GaussDB(DWS)%E6%95%B0%E6%8D%AE%E5%BA%93-%E5%AF%BC%E5%85%A5%E5%AF%BC%E5%87%BA%E7%AF%87/"/>
      <url>/2025/08/03/GaussDB(DWS)%E6%95%B0%E6%8D%AE%E5%BA%93-%E5%AF%BC%E5%85%A5%E5%AF%BC%E5%87%BA%E7%AF%87/</url>
      
        <content type="html"><![CDATA[<h2 id="DWS外表"><a href="#DWS外表" class="headerlink" title="DWS外表"></a>DWS外表</h2><p>外表定义(Foregin table)：是对外部数据源的描述，通过使用SQL接口提供访问外部数据的能力。<br>解决问题：实现数据的导入导出，访问其他DWS集群或者其他外部组件等，扩展了DWS对其他组件进行读写的能力。<br>使用原理：利用FDW(foreign data wrapper)机制。首先定义链接信息，之后创建外表，外表的创建是用于定义DWS数据库上对应其他数据源的表结构。<br>外表创建和管理，分为手动创建和自动创建:</p><ol><li>手动创建如下：在普通表基础上，额外添加server和option信息，先建服务，再建外表。<ul><li><p>server是数据库对象，通过create server创建，存储外部数据源访问和认证信息，用于外表如何找到目标数据。</p></li><li><p>语法格式如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">create server server_name </span><br><span class="line">foreign data warpper fdw_name</span><br><span class="line">option();</span><br></pre></td></tr></table></figure></li></ul></li><li>权限控制：默认只有系统管理员有权限，如果其他人使用需要对foreign data wrapper 授权才能创建，授权语法如下： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grant usage on foreign data wrapper fdw_name to username;</span><br></pre></td></tr></table></figure></li><li>options：数据源定制描述，例如编码、压缩等，不同数据源不同外表差别大。</li><li>系统查询：通过pg_foreign_server和pg_foreign_table系统表查询创建的server和外表。</li><li>自动创建如下：<ul><li>MRS&#x2F;OBS数据源管理+Lakeformation元数据管理；</li><li>MRS&#x2F;OBS数据源管理用于对接HDFS或者OBS,自动建server；</li><li>Lakeformaion元数据管理，自动建外表，使用外部元数据直接进行数据访问。</li></ul></li></ol><h2 id="外表分类"><a href="#外表分类" class="headerlink" title="外表分类"></a>外表分类</h2><p>功能分类：HDFS外表、OBS外表、GDS外表、DLI外表等。<br>server类型分类：</p><ol><li>dfs_fdw&#x2F;hdfs_fdw外表：适应用于外部文件系统（HDFS&#x2F;OBS）上的结构化数据查询。</li><li>dist_fdw外表：适用于文件导入导出。</li><li>gc_fdw外表：适用于协同分析。</li><li>log_fdw外表：适用于dws内部使用，日志查询。</li><li>file_fdw外表：访问服务器文件 。</li></ol><h2 id="GDS-Gauss-Data-Service-工具"><a href="#GDS-Gauss-Data-Service-工具" class="headerlink" title="GDS(Gauss Data Service)工具"></a>GDS(Gauss Data Service)工具</h2><p>定义：DWS提供的数据导入导出工具</p><p>适配场景：</p><ol><li>数据迁移，同构异构集群数据迁移。</li><li>以文本数据作为来源的大数据量表导入</li><li>大数据量表导出<br>  支持导入和导出的文件格式：csv&#x2F;text&#x2F;binary&#x2F;fixed（每行数据等长）</li></ol><p>工具原理：<br>数据导入过程：GDS通过网络和数据库系统相连，CN负责任务规划和下发，GDS负责数据文件切分，然后分发给各个DN，各个DN节点负责数据并行导入，各DN收到数据分片后解析数据，根据表的分布列计算hash值并确定归属哪个DN，如果是自身就缓存到本地，否则就通过网络传给相应的DN.导出过程正好相反。<br>导入要点：</p><ol><li>导入时，GDS数量&lt;&#x3D;DN数量。</li><li>GDS导入时，服务器普通文件系统数据可以导入DWS数据库，HDFS文件系统数据暂时不可以导入DWS数据库。</li></ol><p>导出要点：</p><ol><li>按照导出目的地是否是集群内的主机，分为local模式和remote模式；目的地是集群节点所在主机上为local模式，否则为remote模式。</li><li>导出支持的数据文件格式：csv&#x2F;text&#x2F;fixed，单行数据大小需要&lt;1GB</li><li>在local模式中，数据均匀切割并生成到集群指定文件夹下，需要占用集群磁盘空间。</li><li>在remote模式中，1个GDS同一时刻只为1个集群服务，多个GDS可以并发导出。和集群在同一内网的GDS，导出速度受网络带宽影响。</li></ol><p>GDS导入操作：启动GDS服务&gt;创建外表&gt;执行导入&gt;分析错误表<br>导入操作要点：</p><ol><li>GDS导入数据目录文件过多时，可以使用正则表达式指定外表的location,选择需要的导入文件</li><li>导入过程中的错误，分为数据格式和非数据格式两种错误。数据格式错误是指缺失或多出字段值、数据类型错误或者数据编码错误等。可以通过在创建外表时，设置参数“log into error_table_name”，将导入过程中的数据格式错位信息写入指定的错误信息表中。</li></ol><p>GDS导出操作：启动GDS&gt;创建外表&gt;执行导出<br>导出操作要点：导出的文本命名格式为t1_foreign_output.data.</p><h2 id="实时数仓"><a href="#实时数仓" class="headerlink" title="实时数仓"></a>实时数仓</h2><ol><li>Flink:分布式、流批一体、开源处理引擎。</li><li>用途：在无边界和有边界数据流上进行有状态计算。无边界数据流是指源源不断产生数据，数据流没有结束，类似于kafka消息流。有边界数据流是指有开始和结束的数据流，可以对所有数据做处理。有状态计算是指在流处理过程中，可以将中间状态保留，用于后续数据处理使用。</li><li>Flink内容：组件+任务+API库</li><li>Flink组件：<ul><li>JobManager:负责分配任务、协调执行任务、协助检查点，并处理失败。</li><li>TaskManager:在集群中并行执行任务，管理任务状态和缓冲区。</li><li>Client:提交Flink作业，并与JobManager通讯。</li></ul></li><li>Flink任务：任务由多算子组成，每个算子设置各自的并行度任务<ul><li>source+transformation+sink算子组成。</li><li>source:数据流起点，从外部系统读取数据并转换为Flink可处理的内部数据结构。</li><li>transformation:对数据流进行操作，转换&#x2F;聚合&#x2F;连接&#x2F;分割数据</li><li>sink:数据流终点，将处理后的数据写入外部系统。</li></ul></li><li>Flink的API库：<ul><li>DataStream API:提供转换操作符,用于构建流处理应用核心API。</li><li>Table API&amp;SQL:提供声明式API,用类SQL方式查询流和批处理数据。</li></ul></li></ol><h2 id="dws-flink-connector工具"><a href="#dws-flink-connector工具" class="headerlink" title="dws-flink-connector工具"></a>dws-flink-connector工具</h2><ol><li>用途：可以通过Flink SQL实现从DWS中读写数据（包括增量读）</li><li>功能：<ul><li>批量读：将DWS中表作为数据源供Flink用于批读</li><li>维流join：将DWS中表作为维表供Fink维流join(即用实时流和维表join)</li><li>攒批写：将DWS中表作为结果表供Flink写入数据（一定时间一定量）</li></ul></li><li>Flink catalog：通过Flink catalog，实现Flink和DWS表相互映射。</li><li>语法说明：<ul><li>Flink SQL中的表字段必须和DWS表中有对应字段</li><li>with参数设置中，connector需要指定dws, tableName需要指定为DWS对应表名。lookupAsync表示是否异步读取</li><li>在Flink catalog中，with参数type需要指定为dws,base_url中不用带数据库名称。use catalog dws 表示使用新建catalog。show catalog表示查询所有catalog。可以直接查询数据库中的表信息，不需要在Flink中建映射表。</li></ul></li></ol><h2 id="实时增量读取"><a href="#实时增量读取" class="headerlink" title="实时增量读取"></a>实时增量读取</h2><ol><li>原理：只对变化的数据进行读取，而不重新读取整个数据集。<ul><li>好处：提高处理效率，减少资源消耗</li></ul></li><li>操作：DWS通过Binlog实现增量读取。对表做DML操作时，先进行双写，对应的DML记录到辅助表中，然后通过读取该辅助表来获取增量数据，实现数据同步和增量计算。</li><li>Binlog表语法：用Binlog表作为源表供Flink实时读取。with参数中的binlog属性需要设置为true,binlogSlotName需要设置为自定义的槽位名。</li><li>注意要点：<ul><li>DWS中只有Hstore和Hstore-opt表支持Binlog功能，表需要有主键且设置为enable_binlog &#x3D; on </li><li>如果多任务消费同一个表的Binlog数据，需要保证每个任务的binlogSlotName唯一。</li><li>为达到最高读取速度，建议Flink任务并行度和DWS集群DN数设置一致。</li><li>可以使用dws-flink-connector的sink能力来写入读取到的Binlog数据，需要注意点如下：如果要保证DN内数据写入顺序，需要设置connectionSize &#x3D; 1.如果源端有更新主键操作或者Flink聚合操作，需要将ignoreUpdateBefore设置为False(默认为True).</li></ul></li></ol><h2 id="实时数仓-1"><a href="#实时数仓-1" class="headerlink" title="实时数仓"></a>实时数仓</h2><p>Flink实时处理能力+DWS的Binlog能力。</p><p>基于公开来源信息, 学习资源来自<a href="https://connect.huaweicloud.com/courses/learn/Learning/sp:cloudEdu_?courseNo=course-v1:HuaweiX+CBUCNXBC006+Self-paced&courseType=1">华为云GaussDB(DWS)数据库官网</a></p>]]></content>
      
      
      <categories>
          
          <category> 数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GaussDB(DWS) </tag>
            
            <tag> 数据库 </tag>
            
            <tag> 数据仓库 </tag>
            
            <tag> 数据 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GaussDB(DWS)数据库-开发应用篇</title>
      <link href="/2025/08/03/GaussDB(DWS)%E6%95%B0%E6%8D%AE%E5%BA%93-%E5%BC%80%E5%8F%91%E5%BA%94%E7%94%A8%E7%AF%87/"/>
      <url>/2025/08/03/GaussDB(DWS)%E6%95%B0%E6%8D%AE%E5%BA%93-%E5%BC%80%E5%8F%91%E5%BA%94%E7%94%A8%E7%AF%87/</url>
      
        <content type="html"><![CDATA[<h3 id="DWS驱动及ODBC-JDBC开发"><a href="#DWS驱动及ODBC-JDBC开发" class="headerlink" title="DWS驱动及ODBC&#x2F;JDBC开发"></a>DWS驱动及ODBC&#x2F;JDBC开发</h3><ol><li>DWS驱动：<ul><li>驱动概念：数据库驱动是应用程序和数据库存储之间的一种接口，数据库厂商为某一开发语言环境，能够实现数据库调用而开发的类似“翻译员”功能的程序，将复杂的数据库操作和通讯抽象成为当前开发语言的访问接口。</li></ul></li><li>支持驱动类型：JDBC、ODBC等，如果同时拥有不同版本的集群或者当前没有集群，单击“下载”时下载的依然是与现有集群版本相匹配的。</li><li>驱动支持平台：JDBC没有平台限制，ODBC有支持平台限制（平台：X86、鲲鹏）</li><li>JDBC应用程序开发：<ul><li>JDBC整体架构（4层）：应用程序-&gt;JDBC Driver Interface-&gt;JDBC驱动-&gt;数据库。JAVA本身具有良好的平台移植性，这也直接导致JDBC的平台移植性比ODBC强很多。</li><li>JDBC安全配置：配置JDBC包-&gt;加载驱动-&gt;连接数据库<ul><li>gsjdbc4.jar:与PostgreSQL保持兼容的驱动包，其中类名、类结构与PostgreSQL驱动完全一致，曾经运行于PostgreSQL的应用程序可以直接移植到当前系统使用。主类名为“org.postgresql.Driver”，数据库连接的URL前缀为“jdbc:postgresql”</li><li>gsjdbc200.jar:如果同一JVM进程内需要同时访问PostgreSQL及GaussDB(DWS)，请使用此驱动包。主类名为“com.huawei.gauss200.jdbc.Driver”,数据库连接的URL前缀为“jdbc:guassdb”，其余与gsjdbc4.jar相同。</li></ul></li><li>配置注意事项：<ul><li>连接参数：第三方工具通过JDBC连接DWS时，jdbc向DWS发起连接请求，会默认添加以下配置参数，详见jdbc代码ConnectionFactoryImpl类的实现。这些参数可能会导致JDBC客户端的行为与gsql客户端的行为不一致。如果实际期望和这些配置不符，建议在Java连接设置代码中显示设定这些参数。</li><li>fetchsize:在应用程序中，如果需要使用fetchsize，必须关闭autocommit。开启autocommit，会令fetchsize失效。</li><li>autocommit:在jdbc向DWS申请连接的代码中，建议显示打开autocommit开关。如果基于性能或者其他方面考虑，需要关闭autocommit时，需要应用程序自己来保证事务的提交。例如，在指定的业务SQL执行完之后做显式提交，特别是客户端退出之前务必保证所有的事务已经提交。</li><li>CopyManager:在不使用ETL工具，数据入库实时性要求又比较高的情况下，建议在开发应用程序时，使用dws的jdbc驱动的CopyManager接口进行微批导入。</li><li>释放连接：推荐使用连接池来限制应用程序的连接数。每执行一条SQL就连接一次数据库，是一种不好的SQL编写习惯。在应用程序完成作业任务之后，应当及时断开和dws的连接，释放资源。建议在任务中设置session超时时间参数。</li><li>使用jdbc连接池，在将连接释放给连接池前，需要执行以下操作，重置会话环境。否则，可能会因为历史会话信息导致的对象冲突。如果在连接中设置了GUC参数，那么在将连接归还连接池之前，必须使用“SET SESSION AUTHORIZATION DEFAULT;RESET ALL;”将连接的状态清空。如果使用了临时表，那么在将连接归还连接池之前，必须将临时表删除。（常见报错：relation “xxx_tmp” already exists）</li></ul></li></ul></li><li>ODBC应用程序开发：<ul><li>ODBC整体架构（5层）：应用程序-&gt;标准接口（ODBC API）-&gt; 驱动程序管理器（ODBC Driver Manager）-&gt;ODBC驱动-&gt;数据库</li><li>数据源配置：Linux、windows</li><li>Linux-ODBC数据源配置：<ul><li>步骤（4个）：<ul><li>安装ODBC驱动管理器：获取UnixODBC源码包，编译安装驱动管理器。备注：驱动默认安装在“&#x2F;usr&#x2F;local”目录下，生成数据源文件到“&#x2F;usr&#x2F;local&#x2F;etc”目录下，库文件生成在“&#x2F;usr&#x2F;local&#x2F;lib”目录下</li><li>配置驱动</li><li>安全组配置</li><li>测试连接：使用isql -v GaussODBC(数据源名称)</li></ul></li></ul></li><li>windows-ODBC数据源配置：<ul><li>步骤<ul><li>配置服务器：与Linux相同</li><li>配置数据源（Windows自带驱动管理器，无需额外安装）</li></ul></li></ul></li><li>应用程序调试：<ul><li>ODBC应用程序调试需要在前面配置正确可用的环境下进行。</li></ul></li></ul></li><li>客户端连接管理<ul><li>功能描述：JDBC和ODBC驱动在连接成功后会设置session级GUC参数connection_info.该参数包含连接数据库的驱动类型、驱动版本号、当前驱动的部署路径和进程属主用户，使用json格式记录。默认只显示driver_name和driver_version，driver_path和os_user的显示由用户控制，控制连接参数为ConnectionExtraInfo.connetion_info可以在pg_stat_activity和pgxc_stat_activity中查看。</li><li>连接配置示例：<ul><li>JDBC连接：在连接URL中增加connectionExtraInfo参数。</li><li>ODBC连接：在“&#x2F;usr&#x2F;local&#x2F;etc&#x2F;odbc.ini”文件中追加ConnectionExtraInfo设置。</li></ul></li></ul></li></ol><h3 id="SQL编辑器"><a href="#SQL编辑器" class="headerlink" title="SQL编辑器"></a>SQL编辑器</h3><ol><li>SQL登录：IAM用户一键登录、自定义数据源登录<ul><li>IAM用户一键登录：<ul><li>用户可以直接使用IAM账号登录集群数据库，免除填写账号密码操作</li><li>提供集群列表树展示当前用户拥有的所有集群，可以选择某一个集群直接双击打开集群。</li><li>当前连接是用户的IAM账号直接登录，一键登录集群后，用户可以对账号进行赋权。</li><li>登录后，就可以对集群数据库做一些开发运维等操作。</li><li>限制要求：<ul><li>使用IAM账号登录，首先需要有DWS Database Access角色权限，以及当前用户必须是子账号。</li><li>对于集群版本有一些要求，集群版本要高于8.3.1.330.</li></ul></li></ul></li><li>自定义数据源登录：<ul><li>自定义数据源和传递连接方式类似，用户选择集群后，需要填用户名密码登录</li><li>在创建连接之前会先提示测试连接，测试正常后可以正常保存。</li><li>限制要求：<ul><li>自定义连接对集群版本没有限制，有的只是一些语法上的兼容性，需要用户自定义根据集群版本来编写SQL</li><li>数据源名称如果不填写，会根据集群名（用户名）来创建，注意一个用户下名称不可以重复</li></ul></li></ul></li></ul></li><li>元数据管理：<ul><li>提供了库、模式、表等图形化界面管理，而且以树形方式来层级查看。</li><li>提供树形结构来展现库、模式、表、索引等元数据列表，可以层级打开查看。</li><li>每层节点也提供右键菜单做新增、修改、删除等操作。</li><li>表提供批量操作列，索引，分区，约束信息。</li><li>表，分区，视图支持直接打开数据操作，支持根据SQL条件过滤，表和分区还支持单条数据插入，修改和新增。</li></ul></li><li>SQL分析执行：<ul><li>SQL诊断军规，SQL拦截规则：<ul><li>NULL校验：NULL值的比较只能使用IS [NOT] NULL方式，其他任何形式的逻辑判断都返回NULL。例如NULL &lt;&gt; NULL,NULL &#x3D; NULL和NULL &lt;&gt; 1 返回结果都是NULL.</li><li>COUNT(col)：count(1) 会统计NULL值（真实行数），而count（col）不会统计。</li><li>LIMIT和ORDER BY : DWS的分布式操作会导致数据跨节点流动，不带ORDER BY 的LIMIT 操作的，会导致输出结果随机。因此除非不关注结果集的稳定性，否则禁止不带ORDER BY 的LIMIT操作。</li><li>不稳定函数：子查询中不能出现uuid_generate_v1(), sys_guid(),nextval等不稳定函数，会造成结果集的不稳定。</li><li>NOT IN 校验：not in 子查询逻辑执行计划，走的是nestloop嵌套循环，在数据量大的情况下，非常容易出现性能问题；通过改写not exists之后，执行计划可以使用hashjoin哈希关联，性能能够得到极大的提升。</li><li>join 代替exists: join 相比exists和in 具有更好的代码阅读性，SQL优化器相对更容易找到更精确的执行计划。</li><li>select * : 不建议使用“select * ”这种写法，请明确指定列。</li><li>ORDER BY: 子查询中禁止使用order by </li><li>RETURNING: returning会导致语句不下推</li><li>DISTINCT ON: distinct on 会导致语句不下推</li><li>表关联数量：优化器是基于代价的优化器，表数据量越多，估算的偏差就越大，产生性能差的执行计划的风险就越大，所以每条SQL语句中关联的表个数不超过16个</li><li>schema: 访问表需要加schema。</li></ul></li></ul></li><li>脚本管理<ul><li>目录：支持使用目录来管理SQL脚本，最多支持二级目录，每级目录支持创建10个文件夹，用户只能看到自己创建的目录和脚本。</li><li>脚本：脚本保存到OBS桶中，可以在基础设置中设置默认桶地址，可选择目录进行管理，目录地址也会默认带到桶地址中。</li></ul></li></ol><h3 id="数据集成工具"><a href="#数据集成工具" class="headerlink" title="数据集成工具"></a>数据集成工具</h3><ol><li>实时同步服务：<ul><li>定义： 实时同步服务是DWS 团队根据特性孵化出的，一个简便易用、高性能的、从Kafka同步数据到DWS的服务化工具。其入库时可采用DWS内部协议，以减少对DWS集群的资源消耗，同步提升入库性能。</li></ul></li><li>创建实时同步服务实例：<ul><li>创建时填写对应参数，然后点击立即购买，等待创建完成后，就会按需在后台创建好一个资源池，后续运行的作业将会从资源池中分配一定资源供作业运行；资源池统一使用CU分配资源，规格中的CPU数量即为CU数量，内存不可直接控制，他们会按照CPU内存比按照比例分配，例如创建的实例规格为4U16GB,创建时选择3节点，那么总资源 &#x3D; 4 CU * 3 &#x3D; 12CU,每个CU内存大学4GB.</li></ul></li><li>实时同步服务连接配置：<ul><li>连接配置用于配置Kafka、DWS的连接信息，一份配置所有作业均可使用，以便于后面在提交作业时可以直接使用，不用每个作业都配置一份。</li><li>当前支持Kafka和dws两种类型的连接，连接名称只用于业务区分，无实际含义，Kafka的服务地址需要是带端口的连接串，并且保证是VPC能访问的IP;dws的连接地址是一个包含协议的完整JDBC连接串，同时也需要是能在VPC内能访问的IP.</li></ul></li></ol><h3 id="数据调度工具"><a href="#数据调度工具" class="headerlink" title="数据调度工具"></a>数据调度工具</h3><ol><li>Airflow基础：<ul><li>定义：Apache Airflow是一个开源平台，用于开发、调度和监控，面向批处理的工作流程。</li><li>是可扩展Python框架，主要特点是所有工作流都用Python代码定义，有如下优点：<ul><li>动态：Airflow管道配置为Python代码，允许动态管道生成。</li><li>可扩展：Airflow框架包含可连接多种技术的运算符。所有Airflow组件都可扩展，可轻松适应运行环境。</li><li>灵活：利用Jinja模板引擎，内置工作流参数化。</li></ul></li><li>架构组件（5）：分布式架构<ul><li>Worker: 执行分配的任务</li><li>Scheduler: 负责将必要的任务添加到队列中</li><li>Web Server: HTTP服务器，提供对DAG&#x2F;任务状态等信息的访问</li><li>Database: 存储有关任务、DAG、变量、连接等状态的信息</li><li>Celery: Broker、Result backend</li><li>Broker: 存储要执行的任务。</li><li>Result backend : 存储已完成任务的状态。</li></ul></li><li>Airflow删除：当用户不需要使用某个集群时，可以删除该集群。删除的集群无法恢复，同时集群中的用户数据，已执行任务的历史记录，也会自动删除，而且无法再访问。删除集群时，不会删除集群使用的DAG文件。</li></ul></li><li>注意要点：<ul><li>访问DWS时，建议在Airflow中新建连接，通过base_hook获取连接ID，获取对应数仓的连接信息。避免在DAG文件中，硬编码数仓密码。</li></ul></li></ol><p>基于公开来源信息, 学习资源来自<a href="https://connect.huaweicloud.com/courses/learn/Learning/sp:cloudEdu_?courseNo=course-v1:HuaweiX+CBUCNXBC006+Self-paced&courseType=1">华为云GaussDB(DWS)数据库官网</a></p>]]></content>
      
      
      <categories>
          
          <category> 数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GaussDB(DWS) </tag>
            
            <tag> 数据库 </tag>
            
            <tag> 数据仓库 </tag>
            
            <tag> 数据 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GaussDB(DWS)数据库-数据库管理篇</title>
      <link href="/2025/08/03/GaussDB(DWS)%E6%95%B0%E6%8D%AE%E5%BA%93-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%AF%87/"/>
      <url>/2025/08/03/GaussDB(DWS)%E6%95%B0%E6%8D%AE%E5%BA%93-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%AF%87/</url>
      
        <content type="html"><![CDATA[<h3 id="DWS数据仓库服务："><a href="#DWS数据仓库服务：" class="headerlink" title="DWS数据仓库服务："></a>DWS数据仓库服务：</h3><ol><li>特点：在线数据分析处理、即开即用、可扩展、完全托管、分析型数据库</li><li>兼容性：兼容SQL92、SQL99、SQL2003语法、兼容PostgreSQL&#x2F;Oracle&#x2F;Teradata&#x2F;Mysql等数据库生态。</li></ol><h3 id="存储引擎"><a href="#存储引擎" class="headerlink" title="存储引擎"></a>存储引擎</h3><ol><li>用途：组织和管理数据存储</li><li>使用：SQL语句从客户端发到SQL引擎，先进行语法分析，经过SQL引擎的优化器生成执行计划，SQL引擎的执行器和存储引擎交互，存储引擎支持行存和列存（普通列存表和HStore&#x2F;HStore OPT表），并分别提供存储访问接口。</li></ol><h3 id="行存储引擎"><a href="#行存储引擎" class="headerlink" title="行存储引擎"></a>行存储引擎</h3><ol><li>行存表page页面组件：页头（page header）+空闲时间（free space）+数据（heap tuple）</li><li>页头（page header）各字段存储信息如下：<ul><li>tuple:一行数据为一个tuple</li><li>free space:行指针的末尾与最新元祖起始位置之间的空余空间。</li><li>heap tuple:存储实际数据的地方。</li></ul></li></ol><h3 id="列存储引擎"><a href="#列存储引擎" class="headerlink" title="列存储引擎"></a>列存储引擎</h3><ol><li>列存储引擎的最小存储单元是CU(Compression Unit,压缩单元)，一个CU是由表中某一列的一部分数据组成的压缩数据块，可以通过CU_ID,COL_ID标识一个CU.</li><li>列存储引擎架构：辅助表+场景</li><li>辅助表用途：行存表，辅助列存储的实现，用于记录存储的元信息，或者用于提升存储效率。</li><li>辅助表分类：<ul><li>CUDesc表：用于记录CU的事务时间戳、CU大小、存储位置、magic校验码、min&#x2F;max等信息。</li><li>delta表：由表级参数enable_delta来控制是否开启。表主要用于缓存列存表的入库数据，等攒批后再刷到CU中。</li><li>查询：可以通过查询pg_class得到列存储引擎辅助表信息。</li></ul></li><li>适用场景：<ul><li>实时场景（性能）：<ul><li>Hstore表：可用于增强实时场景下的小批量DML性能，兼容列存2.0.可以切换。</li><li>Hstore opt表：与Hstore相比，增强入库和查询能力，但是不兼容老数据。</li></ul></li><li>海量数据场景（数据）：<ul><li>冷热表：自动将冷数据放到OBS服务中存储，从而降低数据存储成本，保障热数据性能。</li><li>存算分离表：将数据完全存放到OBS存储中，并根据性能和存储可以选择相应的规格。</li></ul></li><li>兼容性：Hstore表、Hstore opt表、列存2.0都可以兼容冷热表和存算分离表。</li></ul></li></ol><h3 id="表类型（6种）"><a href="#表类型（6种）" class="headerlink" title="表类型（6种）"></a>表类型（6种）</h3><p>行存表+列存表+Hstore+Hstore opt+冷热表+存算分离表</p><ol><li>行存表：<ul><li>直接使用create table建立的表，默认为行存表，使用B-Tree索引。</li><li>B-Tree索引特点：<ul><li>索引结构：B-Tree（平衡树）是一种有序树，每个节点包含多个键，并且子节点的键值范围是确定的。</li><li>索引优势：高效支持范围查询、等值查询、排序操作。</li></ul></li></ul></li><li>列存表：<ul><li>建表时指定参数orientation &#x3D; column，建立列存表。</li><li>列存参数：<ul><li>compress_level: 指定压缩级别（low, middle, high）</li><li>max_batchrows:CU内最大行数，默认6w行。</li><li>column_version:1.0&#x2F;2.0&#x2F;3.0(存算分离)</li></ul></li><li>列索引：<ul><li>Gin索引：基于B-tree树结构的倒排索引，用于存储被索引字段的value或者value的元素，适应于数组过滤、全文检索的场景。</li><li>Gist索引：通用索引接口，用于不同类型支持不同索引方式，适用于位置索引。</li><li>PSort索引：用于对该列进行聚簇排序，目的是提升查询过滤性能。</li><li>CBTree索引：列存表的B-Tree索引，原理和行存相同。</li></ul></li></ul></li><li>Hstore表：<ul><li>建表：with参数enable_hstore指定为开启，则开启Hstore表，或者通过alter修改为普遍列存表。是实时数仓中设计的表类型，用于将insert&#x2F;update&#x2F;upsert等操作实时快速入库。</li><li>功能：<ul><li>支持异步排序：当指定Psort后，对存量未排序数据在后台排序，风险是在压力大时会造成Delta膨胀。</li><li>支持小CU合并：将小CU在后台合并为一个新CU，提升实时能力。</li><li>单条或者小批量IUD(insert&#x2F;update&#x2F;delete)操作高并发实时入库，支持大批量定期入库。</li><li>支持冷热数据管理。</li></ul></li><li>适配场景：实时入库和实时查询强诉求场景，同时拥有处理传统TP场景事务能力。版本：8.2.0.100及以上集群版本支持</li><li>与普通列存表的差异：主要的辅助表Delta表的差异：<ul><li>Hstoreb表的delta表：表结构上和主表定义不一致，功能上用于持久化存储update&#x2F;delete&#x2F;insert信息。缺点是依赖后台常驻autovacuum来执行merge操作。</li><li>列存表的delta表：表结构上和列存主表定义一致，功能上用于暂存小批量insert数据，达到阈值后统一merge到主表，避免直接insert到主表产生大量CU,缺点是如果来不及merge，会导致delta表膨胀，进而影响查询性能，同时无法解决并发update的锁冲突问题。</li></ul></li><li>注意要点：<ul><li>表级参数enable_dalta和enable_hstore不能同时开启，原因是enable_delta用于普通列存表的delta表开启，与enable_hstore冲突。</li><li>Hstore表只支持col_version 2.0版本。</li></ul></li></ul></li><li>Hstroe opt表：<ul><li>建表:前提是列存表，在with参数enable_hstore_opt指定为开启。或者和enable_hstore同时指定。当hstore_opt开启时，不能通过alter关闭。opt会默认打开turbo属性，除非手动关闭。</li><li>功能：<ul><li>支持异步排序和小CU合并：和Hstore表相同，但是没有delta表膨胀的问题。</li><li>支持Bitmap columns索引：使用bitmap_columns &#x3D; “列名1，列名2”指定。此索引只针对varchar&#x2F;text类型，并且字符长度不能大于127，只正对基数特征比较明显的列。在低基数时，内部会使用bitmap配合字典压缩存储数据，在高基数时，通过bloomfilter生成hash的bit列加速过滤。</li></ul></li><li>Hstore OPT表和Hstore表在辅助表方面的差异：<ul><li>CUDesc辅助表:</li><li>Hstore OPT表结构的cudesc和hstore不一致，支持二级分区等特性。</li><li>Hstore表结构的cudesc和列存一致，因此可以切换。</li><li>Delta辅助表：</li><li>Hstore opt表结构的delta表定义和hstore一致，cudesc和hstore不一致。</li><li>而Hstore的表结构的delta表定义和列存不一致。cudesc和列存一致。</li></ul></li></ul></li><li>冷热表：<ul><li>定义：在时间场景，数据按照时间可划分为：热数据和冷数据。</li><li>热数据Hot:被频繁查询或更新，对访问的响应时间要求高的数据。</li><li>冷数据Cold:不允许更新，偶尔查询，对访问的响应时间要求不高的数据。</li><li>通过定义冷热表，将符合规则的冷数据切换到OBS上存储，按照分区自动进行冷热数据判断和迁移。</li><li>切换策略模式：<ul><li>LMT(Last Modify Time，最后修改时间)：根据分区的最后更新时间进行切换，切换数据为切换[day]天前的分区数据为冷数据，迁移到OBS表空间，其中[day]范围：0到36500天。</li><li>HPN(Hot Partition Number，热分区数量)：保留指定数量的热分区。分区顺序根据分区的序列ID（Sequence id）确定，ID由分区边界值大小生成，切换时，将数据迁移到OBS表空间。HPN范围；0到1600。</li></ul></li><li>建表：<ul><li>创建OBS tablespace，指定OBS路径</li><li>建表，选项中指定orientation &#x3D; column, cold_tablespace &#x3D;’’, storage_policy。cold_tablespace表空间为必选项，storage_policy冷热数据切换规则，必选项。</li></ul></li></ul></li><li>存算分离表：<ul><li>背景：用于实现计算层和存储层独立增加节点并行互不打扰。</li><li>建表：<ul><li>先建立OBS tablespace 表空间，和冷热表一致。</li><li>创建逻辑集群</li><li>创建表，指定col_version &#x3D; 3.0，即可创建存算分离表。</li></ul></li></ul></li><li>不同表的优劣：<ul><li>行存表：适合少量数据，对实时性要求较高的场景。</li><li>列存表1.0&#x2F;2.0: 并发能力弱于Hstore表,不推荐</li><li>Hstore:维批copy，无更新入库场景，性能要求要的情况下使用。</li><li>Hstore opt:对列式存储有实时场景需求，当前推荐版本。</li><li>冷热表：在业务系统中，用户对不同时期数据，有不同使用需求时使用，可以和Hstore OPT同时使用。</li><li>存算分离表：云原生环境下，需要分别增减计算和储存节点的场景下使用。</li></ul></li></ol><h3 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h3><ol><li>定义：是数据库系统执行过程中的一个逻辑单位，由一组有限数据库操作序列构成，包括对数据库的读写操作。</li><li>要点：<ul><li>若事务被提交后，数据库需要确保事务中的所有操作成功完成，并且结构永久保持。</li><li>若事务中有操作没成功完成，则所有操作全部回滚，恢复事务执行前的状态。</li><li>每个事务对其他事务无影响。</li><li>并非任意对数据库操作的序列都是数据库事务，事务要满足ACID特性。</li><li>在进行多个相关更改时，一个事务内执行多个语句有助于保证一致性；在所有相关更改完成前，其他会话不能看见中间状态。</li></ul></li><li>事务分类：显性事务+自动提交事务<ul><li>显性事务：begin开始事务块，所有begin命令后的所有语句都在一个事务中执行，直到给出一个显示的commit或者rollback.</li><li>自动提交事务：默认情况下，数据自动提交模式中执行事务（没有begin块）。每个语句都在自己的事务中执行并且在语句结束时隐式执行一次提交，若失败会完成一次回滚。</li></ul></li><li>事务性质ACID:<ul><li>原子性（Atomicity）:一个事务要么全做，要么全不做。</li><li>一致性（Consistency）:事务执行前后，数据都是正确的，不存在矛盾。</li><li>隔离性（Isolation）:不同事务之间不会相互影响。</li><li>持久性（Durability）:事务提交后，对数据库的改变不会消失。</li></ul></li><li>ACID实现原理：</li><li>原则性（Atomicity）:<ul><li>通过分配的唯一标识事务号（XID）区分不同事务，是单调递增数据，用于事务提交和回滚。事务在修改（insert&#x2F;update&#x2F;delete）前先获取事务号，采用64位bit的XID；通过txid_current（）查询事务号。</li><li>事务提交日志（Commit Log,CLog）:用于记录事务执行结果的状态。事务提交，CLog中记录commit;事务回滚，CLog中记录abort.</li><li>用途：查询事务修改是否有效，只需要查询事务对应的CLog状态。</li></ul></li><li>查询函数:<ul><li>pgxc_is_committed():查询事务状态</li><li>pgxc_xacts_iscommitted():查询各节点事务状态。</li><li>注意要点：CLog日志记录了事务的提交和回滚的状态，不得随意删除或者移动。</li></ul></li><li>一致性Consistency和隔离性Isolation：任何事务都感受不到有其他事务在系统中并发地执行。<ul><li>典型读取问题<ul><li>脏读：一个事务读取另一个未提交事务写入的数据。</li><li>不可重复读：一个事务重新读取之前读取过的数据，发现该数据已经被其他已提交事务修改。</li><li>幻读：一个事务重新执行一个查询，返回符合查询结果的行，发现这些行由于其他最近提交的事务而发生改变（行的增加、减少或者更新）</li></ul></li><li>隔离级别和容易出现的问题：<ul><li>未提交读（read uncommitted）:脏读+不可重复读+幻读</li><li>已提交读（read committed）：不可重复读+幻读</li><li>可重复读（rapeatable read）:幻读</li></ul></li><li>快照：<ul><li>定义：当前时刻所有活跃事务号的集合。</li><li>特点：扫描数据时，每个事务看到的只是获取快照那一刻的数据，而不是数据的当前最新状态，从而避免一个事务看到其他并发事务的更新而导致的不一致数据。</li><li>可见性：针对某条数据对当前查询中是否可见。</li><li>可见情况如下：<ul><li>快照中活跃事务的修改不可见</li><li>事务启动前提交的事务，其修改可见</li><li>事务启动后提交的事务，其修改不可见。</li></ul></li></ul></li><li>注意要点：DWS默认隔离级别为已提交读（read committed).保证隔离级别下的数据一致性。</li></ul></li><li>持久性（Durability）:<ul><li>方法：重做日志（Redo Log）,Redo Log&#x2F;WAL日志&#x2F;xlog，记录数据修改操作，用于数据恢复和持久化。</li><li>产生方法：数据修改过程中会产生redo log，默认单文件大小16M,保存在pg_xlog目录中。主要用途：归档、节点重启恢复、备份恢复、容灾。</li><li>注意要点：xlog记录数据库发生的各种事务信息，不得随意删除或者移动日志文件，否则数据库会有无法恢复的风险。</li><li>FPW(full page writes)会产生大量xlog.带索引导入会产生大量xlog，主要因为带索引导入会使数据使用xlog进行主备复制，而不带索引导入时会使用页复制进行同步。带索引导入推荐做饭：导入前先删除索引，导入完成后重建索引。</li><li>典型函数：<ul><li>pg_current_xlog_location:获取当前重做日志写入位置。</li><li>pg_xlogfile_name:获取当前写入重做日志文件名：</li><li>pg_xlogfile_name_offset:获取当前写入重做日志文件名并返回其在文件中的字节偏移量。</li></ul></li></ul></li><li>分布式事务：<ul><li>特点：分布式事务中，事务由不同服务器不同节点共同完成，所有节点事务要么全部成功，要么全部失败。</li><li>DWS通过GTM(全局事务控制器)实现分布式事务强一致性。</li><li>DWS实施方式：两阶段提交法（2PC）<ul><li>事务协调者要求所有涉及事务的节点预提交操作，并反馈是否可以提交。</li><li>事务协调者要求每个数据库提交数据，或者回滚数据。</li></ul></li><li>2PC流程分类：按照涉及节点不同<ul><li>单节点DML：根据数据分布实际情况，在一个事务中，DML操作只涉及某一个DN节点，只需要该DN以及发起事务的CN参与事务，其他节点不参与本次事务。</li><li>跨节点DML：根据数据分布实际情况，在一个事务中，DML操作涉及多个DN节点。需要多个DN以及发起事务的CN都参与事务，其他CN节点不参与事务。</li><li>DDL:分布式DDL,更新所有实例上的元数据信息。由于元数据信息是存储在所有实例上的，所以更新元数据信息需要在所有CN和DN上都更新一遍，即所有CN和DN都参与事务。</li></ul></li></ul></li></ol><h3 id="表"><a href="#表" class="headerlink" title="表"></a>表</h3><ol><li>表要素：字段类型+存储方式+分布方式+分区方式+约束+表操作</li><li>定义：关系型数据库中二维数组集合，代码存储对象之间的关系</li><li>记录：每一行为一个记录，也称元祖，由若干字段组成。</li><li>字段：域或属性，每一列为一个字段，包含两个属性：列名和数据类型。</li><li>字段数据类型：基本数据类型：数值类型+字符类型+日期时间类型<ul><li>用户自定义类型：create type</li></ul></li><li>存储方式：<ul><li>行存：orientation &#x3D; row</li><li>列存：orientatioin &#x3D; column</li></ul></li><li>分布方式：复制+哈希+轮询<ul><li>复制（replication）：每个节点拥有完整表数据</li><li>哈希（hash）:对表中的列进行哈希，根据哈希值映射到指定数据节点</li><li>轮询（roundrobin）:默认创建方式，修改默认使用参数default_distribution_mode，轮番选择数据节点保存数据。</li></ul></li><li>分区方式：range+list<ul><li>设置：partition by range&#x2F;list(字段)</li><li>其他类型分类：非日志表+临时表</li><li>非日志表（unlogged）:不记录redo 日志，通过日志量的减少提高数据写性能，没有redo日志后，出现故障数据库重启无法恢复，适合于可靠性要求不高的非核心数据。</li><li>临时表：分为会话级和事务级临时表，用来保存会话或者事务中的、临时性的、过程性的数据。表定义和数据仅当前会话可见。</li></ul></li><li>约束：<ul><li>定义方法：列约束&#x2F;表约束</li><li>约束类型：主键约束+唯一约束+非空约束+default约束</li><li>检查约束（仅支持行存表）</li><li>partial cluster key(仅支持列存表)</li></ul></li><li>表操作：建表+修改+删除+查询<ul><li>建表方式：create table as :分区表不能采用此方式创建，可根据查询结果创建，表字段和select查询字段和数据类型相关，指定with no data时，不填充数据。create table like：自动从like指定来源表中，继承所有字段、数据类型和非空约束。使用includeing&#x2F;excluding继承或不继承来源表的某些属性。</li><li>修改方式：alter table</li><li>增加字段：add column column_name data_type</li><li>修改字段类型：modify column_name data_type</li><li>修改分布方式：distribute by repliction&#x2F;roundrobin&#x2F;hash(column_name)</li><li>删除列：drop column column_name</li><li>删除方式：drop table</li><li>可以添加cascade 进行级联删除</li><li>查询命令：<ul><li>元命令：\d</li><li>系统视图：pg_tables&#x2F;xxx_part_tables&#x2F;xxx_tab_partitions</li><li>系统表：pg_class&#x2F;pg_partition</li><li>系统函数：pg_get_tabledef</li></ul></li></ul></li></ol><h3 id="分区设计"><a href="#分区设计" class="headerlink" title="分区设计"></a>分区设计</h3><ol><li>分区策略：<ul><li>表数据量比较大：小表扫描耗时不大，分区表性能收益不明显，只建议对大表采取分区方式。在列存储下，每个列都是单独文件存储，最小存储单元CU可储存6w行数据，对列分区表，建议每个分区数据不小于DN数*6w。</li><li>数据有明显区间特征字段：需要根据有明显区间性字段做表分区，时间字段最常见。</li><li>业务查询有明显区间范围特征：查询数据可落在区间范围指定分区内，才能通过分区剪枝扫描查询需要的分区，提升数据扫描效率，降低数据扫描IO开销。</li></ul></li><li>分区类型：<ul><li>range:基于数值型范围划分数据，数据范围由建表时指定的分区键决定。间隔分区表在发现记录映射不到任何分区时，会根据间隔条件（interval）自动创建分区。 </li><li>list：基于值列表划分数据，仅8.1.3及以上版本支持。</li></ul></li><li>分区优势：改善查询性能+增强可用性+方便维护+均衡I&#x2F;O</li><li>分区要点：<ul><li>针对已存在的表进行分区，最好将数据迁移完后再建索引。</li><li>若数据表已存在，建议先建立分区表，然后使用非堵塞式迁移接口。</li><li>要充分发挥分区表查询优势，必须使用分区时的字段作为过滤字段。分区键条件查询，效率高</li><li>分区后没有全局唯一性，各个分区之间有重复uuid</li><li>分区字段必须是非空的，类似于案件的立案日期和结案日期就不能作为分区字段</li><li>vacuum 或者 analyze 只对主表有作用，要分析分区表，需要分析每个分区。</li><li>分区备份可单独备份各个分区，若要备份所有分区只能备份整个schema。</li><li>数据迁移到分区表后建议禁用主键，因为若主表没有执行vaccuum操作，则执行计划会全表扫描主表，耗时长。</li></ul></li></ol><h3 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h3><ol><li>索引分类：<ul><li>按照数据组织方式：Gin索引+Gist索引+Post索引+Btree索引<ul><li>GIN索引：倒排索引，可处理包含多个键的</li><li>Gist索引：适用于几何和地理等多维数据类型和集合数据</li><li>Psort索引：列存表的局部排序索引。</li><li>Btree索引：适用类似B+树结构来存储数据的键值。</li></ul></li><li>支持情况：<ul><li>行存表：btree(默认)+gin+gist</li><li>列存表：psort(默认)+bree+gin</li></ul></li><li>按照索引方式：唯一+多字段+部分+表达式<ul><li>唯一索引：唯一索引会在每次添加数据时检查表中是否有重复值，行存表Btree索引和列存表btree索引支持唯一索引，主键约束和唯一约束都在自动创建唯一索引</li><li>多字段索引：索引键值多于一个字段的索引，最多声明32个字段</li><li>部分索引：只包含表一部分数据的索引，常用于分布不一致的表，只索引其中频率高的key</li><li>表达式索引：基于表中一个或多个字段的表达式索引。</li></ul></li><li>按照基表类型分类：<ul><li>全局索引：非分区表创建的索引</li><li>索引分区：分区表创建的索引，不支持创建部分索引。</li></ul></li></ul></li><li>重建索引：<ul><li>重建索引条件：<ul><li>索引崩溃，并且不在包含有效数据；</li><li>索引臃肿，包含大量空页或者接近空页</li><li>为索引更改存储参数，并且要求更改生效。</li></ul></li><li>重建方式：reindex+alter index name rebuild</li><li>索引使用：哪些列可以创建索引<ul><li>经常需要搜索查询的列</li><li>经常需要根据范围进行搜索的列</li><li>经常需要排序的列</li><li>经常使用where子句的列</li><li>经常出现在关键字order by&#x2F;group by &#x2F;distinct后面的字段。</li></ul></li><li>索引优缺点：<ul><li>优点如下：点查询提速显著，直接定位到需要的位置，减少无效IO。多条件组合查询，过滤大量数据，缩小扫描范围。利用倒排索引加速全文检索。利用等值条件索引查询速度快的优势，结合nestloop提高多表join效率。提供主键和唯一性索引，满足业务需要。利用btree索引天然有序的特点，优化查询计划。</li><li>缺点如下：索引页面占用额外空间，导致磁盘膨胀。每次导入数据同时更新索引，影响导入性能。索引需要记录xlog,增加日志量。索引页面没有可见性，存在垃圾数据，需要定期清理。每个索引至少一个文件，增加备份恢复、扩容等操作代价。索引索引扫描的性能不一定比顺序扫描性能好，特别是优化器判断错误，导致查询性能劣化的情况下。</li></ul></li></ul></li></ol><h3 id="视图"><a href="#视图" class="headerlink" title="视图"></a>视图</h3><ol><li>虚表：只存放视图定义，不存放视图数据，数据仍然在基本表中，若基表数据发生变化，视图数据也变化。</li><li>视图管理：创建+修改+删除<ul><li>create view：创建视图</li><li>create or replace view: 替换同名视图或创建新视图</li><li>create temp view ：创建会话级临时视图</li><li>alter view：修改视图</li><li>alter view rebuild：在视图解耦下，可使用已保留的原始语句重建视图，恢复依赖关系。</li><li>drop view :删除视图。</li></ul></li><li>可更新视图：<ul><li>背景：在使用视图过程中，为确保权限问题，需要在表上都封装一层视图，对表中数据的IUDS(insert&#x2F;update&#x2F;delete&#x2F;select)通过对应视图操作完成。</li><li>更新机制：视图相当于子查询，子查询中的实际表作为需要更新的表，对该表做merge into&#x2F;insert&#x2F;update&#x2F;delete操作。</li><li>注意要点：可更新视图定义中包含where，则该条件会限制update和delete语句修改基础表上的行。</li><li>使用限制：<ul><li>视图定义的From语句中只能有一个普通表，不能是系统表、外表、DFS表、delta表、toast表、错误表。</li><li>视图中包含可更新的列，这些列是对基础表可更新列的简单引用。</li><li>视图定义中不能包含with、distinct、group by、order by、FOR update 、FOR share 、HAVING、tablesample、limit、offset子句。</li><li>视图定义中不能包含union、intersect、excep集合操作。</li><li>视图定义的选择列表不能包含聚集函数、窗口函数、返回集合的函数。</li><li>视图上不能有触发时机为instead of的触发器。</li><li>视图定义不能包含子链接。</li><li>视图定义不能包含属性为volatile的函数（函数值可以在一次表扫描内改变的函数）</li><li>视图定义不能对表的分布键所在列起别名，或将普通列起别名为分布键列名。</li><li>视图更新操作中包含returning子句时，视图定义中的列只能来自于基础表。</li><li>视图定义包含where条件，则该条件将会限制update和delete语句修改基础表上的行。如果update语句更新行后不再满足where条件，更新后通过视图将无法查询到。</li><li>在视图上执行插入、更新或删除的用户必须在视图和表上具有相应的插入。更新或删除权限。</li></ul></li></ul></li><li>视图解耦：<ul><li>背景：一般情况下，删除视图依赖对象，使用cascade级联将删除视图。重建视图依赖对象后，如果视图量大，使用create view重建视图工作量大。</li><li>解耦机制：删除对象时，不删除依赖对象的视图和其定义，仅删除依赖信息，实现不指定cascade也可删除对象的效果（临时表和临时视图除外）。视图依赖对象重建后，根据依赖对象重建前后差异，可分为自动重建、通过alter view rebuild重建或者drop view + create view重建</li><li>视图解耦设置：<ul><li>参数view_independent &#x3D; on，支持视图解耦和视图重建。</li></ul></li><li>视图重建：<ul><li>自动重建：视图引用的列名在重建后依赖对象中存在，则视图在查询时自动重建。</li><li>alter view rebuild：视图引用的列名在重建后依赖对象中存在，可执行命令重建。</li><li>drop view+create view:视图依赖表中的列被删除或重命名，通过该方式重建。</li></ul></li><li>视图建立原则：<ul><li>业务逻辑：经常使用的数据定义为视图，简化SQL编写，在逻辑上屏蔽真实表结构的变化带来的影响。</li><li>安全逻辑：视图封装只希望业务看到的数据。通过复杂视图，用户不能通过视图修改基表数据。</li></ul></li></ul></li></ol><h3 id="序列（sequence）"><a href="#序列（sequence）" class="headerlink" title="序列（sequence）"></a>序列（sequence）</h3><ol><li>自增整数序列：按照一定规则自增的整数，取值不重复，具有唯一标识性，常被用作主键。<br>  序列管理：</li><li>创建：create sequence</li><li>创建唯一标识自动方法：<ul><li>声明字段类型为序列整型来定义唯一标识符字段：在建表时，将唯一标识符字段类型定义为serial,数据库后台会自动创建一个对应的序列sequence。</li><li>创建自定义sequence并指定字段默认值：使用create sequence自定义序列，使用nextval(‘sequence_name’)函数读取的序列值，指定为某一字段默认值。好处是更灵活，可以为序列定义cache,一次预申请多个序列值，减少和GTM交互次数，来提高性能。</li></ul></li><li>创建注意事项：<ul><li>不建议同时定义cache和maxvalue或者minvalue.因为定义cache后不能保证sequence的连续性，可能产生空洞，造成sequence号段浪费。</li><li>建议cache值不要设置过大，否则会出现缓存序列号时耗时过长的问题；建议cache的值小于10000 0000（1亿）。实际使用时应根据业务设置合理的cache值，既保证快速访问，又不会浪费序列号。</li><li>通过owner by 创建的sequence不建议用于其他表，若希望多表共享sequence，则该sequence不应该从属于特定表。</li><li>为序列sequence指定关联列后u，该列删除时，对应的sequence也会被删除。虽然数据库并不限制序列只能为一列产生默认值，但是最好不要多列共用同一个序列。</li><li>当前版本只支持在定义表的时候指定自增列，或者指定某列的默认值为nextval(“sequence_name”),不支持在已有表中增加自增列或者增加默认值为nextval(“sequence_name”)的列。</li></ul></li><li>修改：alter sequence，alter sequence 语句能够更改现有的sequence的属性，包括修改拥有者、归属列和最大值。将序列和表的指定字段进行关联，在删除字段或者器所在表的的红时候会自动删除已关联的序列。</li><li>修改注意事项：<ul><li>使用alter sequence的用户必须是该序列的所有者</li><li>当前版本仅支持修改拥有者、归属列和最大值。若要修改其他参数，可以删除重建，并用setval函数恢复当前值。</li><li>alter sequence maxvalue 不支持在事务、函数和存储过程中使用。</li><li>修改序列的最大值后，会清空该序列在所有会话中的cache</li><li>alter sequence 会阻塞nextval、currval、lastval、setval的调用。</li></ul></li><li>删除：drop sequence<ul><li>用于从当前数据库里删除序列，只有序列的所有者或者系统管理员才能删除。</li></ul></li><li>序列函数：nextval+currval+lastval+setval<ul><li>nextval():用于递增序列并返回新值，返回类型为bight</li><li>注意事项：<ul><li>为避免从同一序列获取值的并发事务被阻塞，nextval操作不回滚。这种情况将在指定值的顺序中留下未使用的“空洞”。因此,Gauss(DWS)序列对象不能用于获得“无间隙”序列。</li><li>当nextval被下推到DN上时，各DN会自动连接GTM，请求next values值，由于GTM上有最大连接数为8192的限制，这类下推会消耗过多的GTM连接数，因此对于这类语句的并发数目限制为7000&#x2F;集群DN数目。</li></ul></li><li>currval():用于返回当前会话里，最近一次nextval返回的，指定的sequence数值。</li><li>注意事项：<ul><li>如果当前会话没调用过指定sequence的nextval,调用currval报错。</li><li>currval函数默认不支持，如果要使用，需要修改参数enable_beta_featuresw&#x3D; true,并且设置后，nextval函数将不支持下推，返回类型为bight.</li></ul></li><li>lastval():用于放回当前会话里，最近一次nextval返回的值。等效于currval.</li><li>注意事项：<ul><li>如果当前会话没有调度过nextval,调用lastval会报错。</li><li>astval函数默认不支持，如果要使用，需要修改参数enable_beta_features或者lastval_supported &#x3D; true.并且设置后，nextval函数不支持下推，返回类型为bight.</li></ul></li><li>setval():用于设置序列当前值和is_called标识，放回类型为bight</li><li>注意事项：<ul><li>setval使用后，会在当前会话和GTM上立刻生效。但是如果其他会话有缓存的序列值，需要等缓存值耗尽才能感知setval的作用。由于序列的非事务的，setval造成的改变不会由于事务的回滚而撤销。</li></ul></li></ul></li><li>序列注意事项：<ul><li>新sequence序列值产生依靠GTM维护，默认情况下，每申请一个sequence值都要向GTM发送一次申请，GTM在当前值基础上加上步长值，作为新值放回给调度者。</li><li>GTM是全局唯一节点，是性能瓶颈，对大量频繁产生序列号操作，不推荐产生默认序列值。</li><li>序列函数nextval、setval等不支持回滚。setval设置新值，会被当前会话nextval立即生效，但对于其他会话，若定义cache不会立即生效，必须在用尽所有缓存值后，其变动才能被其他会话感知。为避免产生重复值，使用setval设置的新值不能是已经产生的值或者在缓存中的值。</li><li>不要在bulkload的场景中产生默认序列值。如果必须要在bulkload场景下产生默认序列值，则一定要为newSeq1定义足够大的cache，并且不要定义maxvalue或者minvalue。</li><li>sequence创建后，在每个节点都维护一张单行表，存储序列定义和当前值，但此当前值非GTM上当前值，只是保存本节点和GTM交互后的状态。如果其他节点向GTM申请新值，或调用setval修改序列状态，则不刷新本节点的单行表，由于每次申请序列值都是向GTM申请，所以对序列正确性无影响。</li></ul></li><li>序列典型问题：<ul><li>如何确定sequence和哪个表有关联：先在pg_class查找目标sequence的oid, 然后在pg_depend根据oid查依赖该sequence的对象。</li><li>如何查询sequence的当前最新值：通过currval函数可以查询sequence的当前最新值。</li><li>如何解决sequence取值超出范围的问题：可以通过创建sequence时设置cycle字段，从而使得序列达到maxvalue或者minvalue后可循环并继续下去。但是需要注意，如果定义序列为cycle，则不能保证序列的唯一性。或者通过调用setval(regclass, bight)函数对序列取值进行重置。</li></ul></li></ol><h3 id="数据脱敏-对敏感数据进行屏蔽"><a href="#数据脱敏-对敏感数据进行屏蔽" class="headerlink" title="数据脱敏(对敏感数据进行屏蔽)"></a>数据脱敏(对敏感数据进行屏蔽)</h3><ol><li>敏感数据定义：指任何泄露后可能会给社会或个人带来严重危害的数据都属于常见的敏感数据</li><li>敏感数据举例：个人身份信息、企业不适合公开信息、设备信息、银行卡号、受保护的健康信息、知识产权等属于敏感信息。</li><li>数据脱敏原因：对敏感信息通过脱敏规则进行数据变形，实现敏感数据可靠保护。常见脱敏规则为：替换、重排、加密、截断、掩码等。用户可以根据期望的脱敏算法自定义脱敏规则。</li><li>数据脱敏原则：<ul><li>尽可能为脱敏后的应用，保留脱敏前有意义信息</li><li>最大程度防止黑客破解</li></ul></li><li>数据脱敏分类：动态脱敏+静态脱敏<ul><li>动态脱敏：在访问敏感数据时，实时脱敏。优势如下：<ul><li>策略可配置。可结合自身业务场景识别敏感数据，并对业务表的指定列灵活预置脱敏策略</li><li>策略可扩展。内置脱敏函数，可涵盖大部分常见脱敏效果，支持自定义脱敏函数</li><li>敏感数据可算不可见。原始敏感数据参与运算，仅在出库时刻，返回结果时才做脱敏处理</li><li>数据访问受控。脱敏策略生效条件的用户，均对原始敏感数据不可见。</li><li>全场景数据不泄露。底座交互，可减少敏感数据传输链路潜在的泄露风险，安全可靠，而且充分识别各种恶意套取潜在场景，有效防护。</li></ul></li><li>静态脱敏：数据的“搬迁仿真替换”，是将数据抽取并进行脱敏后，下发到下游环节，可随意取用和读写，脱敏后数据和生产数据隔离，从而满足业务需求的同时保障生产数据库安全。</li></ul></li><li>数据脱敏管理：<ul><li>创建：create redaction policy </li><li>修改：alter redaction policy</li><li>删除：drop redaction policy<ul><li>查看脱敏信息：系统视图redaction_policies和redaction_columns.</li></ul></li><li>函数：内置型+扩展型<ul><li>内置型脱敏函数：优先推荐<ul><li>mask_full():全脱敏成固定值，用于实现替代。是可覆盖任何数据类型的全脱敏函数，只关注表达式返回值类型，可保证脱敏数据不泄露，但会导致脱敏结</li><li>mask_partial():针对数值类型&#x2F;字符类型&#x2F;日期或时间类型的部分脱敏，用于实现数值变换&#x2F;截断&#x2F;遮挡</li></ul></li><li>扩展型脱敏函数：可使用pl&#x2F;pgsql语言自定义脱敏函数，遵从要求如下：<ul><li>返回值和脱敏列，类型一致</li><li>函数必须定位为可下推的</li><li>参数列表除脱敏格式外，只能包含一个脱敏列</li><li>函数仅实现针对特定数据类型的格式化改写。</li></ul></li></ul></li></ul></li><li>可算不可见：<ul><li>背景：在使用数据脱敏功能时，存在先对敏感数据加工计算，再输出的情况。</li><li>功能：在数据库内使用原始敏感数据参与加工计算，只在出库时对敏感数据进行脱敏。</li><li>使用条件：需要设置参数enable_redactcol_computable &#x3D; on</li><li>脱敏策略继承：<ul><li>对insert&#x2F;update&#x2F;merge into&#x2F;create table as 语句，当子查询对某个敏感字段投影时，会触发脱敏继承，从而实现包含脱敏信息的新表和源表使用相同的脱敏策略，进而避免敏感数据在新表中数据泄露的问题。</li><li>内置创建的脱敏策略，统一命名为“inherted_rp”</li><li>脱敏策略冲突处理原则：保护用户任何敏感数据不致泄露，优先于数据脱敏效果不具有原始特征，当遇到脱敏效果冲突，都提升为通用脱敏效果mask_full.</li></ul></li></ul></li><li>防护恶意套取：<ul><li>恶意套取定义：通过已知常量值和等值&#x2F;类等值判断表达式来进行套取用户隐私数据的行为。借助等值判断形式表达式的过滤条件或投影操作试探性匹配敏感信息。</li><li>恶意套取定义：通过已知常量值和等值&#x2F;类等值判断表达式来进行套取用户隐私数据的行为。借助等值判断形式表达式的过滤条件或投影操作试探性匹配敏感信息。应对策略：数据脱敏功能采用“悲观主义”模式，任何常量等值判断都有可能存在恶意套取的风险，都应当禁止。</li><li>恶意套取定义：通过已知常量值和等值&#x2F;类等值判断表达式来进行套取用户隐私数据的行为。借助等值判断形式表达式的过滤条件或投影操作试探性匹配敏感信息。禁止使用常量恶意套取场景总结：<ul><li>脱敏字段的常量等值判断表达式、复合表达式、等价表达式</li></ul></li></ul></li></ol><h3 id="审计日志"><a href="#审计日志" class="headerlink" title="审计日志"></a>审计日志</h3><ol><li>功能：用于监视并记录在数据库系统中用户的操作行为，将操作行为的结果记录到审计日志中。</li><li>作用：提高数据库安全级别，识别安全威胁。对用户访问数据库的行为进行记录和分析。可以对事故进行追溯，防止抵赖。支持对数据库操作细粒度的筛选</li><li>管理：支持语句类型和操作类型两种方式设置审计粒度。</li><li>审计日志前提条件：<ul><li>需要审计的审计项开关已开启</li><li>数据库正常运行，并且对数据库执行增删改查操作，保证在查询时段内有审计结果产生。</li><li>数据库各个节点审计日志单独记录，如果使用LVS负载管理机制，需要根据LVS日志追溯到具体的执行节点，并且直接连接该节点查询相关审计日志。</li><li>只有拥有auditadmin属性的用户才可以查看审计记录。</li></ul></li><li>审计日志使用：<ul><li>审计查询命令：使用数据库提供的SQL函数 pg_query_audit</li><li>查询所有CN节点审计日志：pgxc_query_audit()</li><li>查询单个CN节点，也可查询所有CN节点审计日志：pg_query_audit_details()</li></ul></li></ol><p>基于公开来源信息, 学习资源来自<a href="https://connect.huaweicloud.com/courses/learn/Learning/sp:cloudEdu_?courseNo=course-v1:HuaweiX+CBUCNXBC006+Self-paced&courseType=1">华为云GaussDB(DWS)数据库官网</a></p>]]></content>
      
      
      <categories>
          
          <category> 数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GaussDB(DWS) </tag>
            
            <tag> 数据库 </tag>
            
            <tag> 数据仓库 </tag>
            
            <tag> 数据 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GaussDB(DWS)数据库-基础篇</title>
      <link href="/2025/08/03/GaussDB(DWS)%E6%95%B0%E6%8D%AE%E5%BA%93-%E5%9F%BA%E7%A1%80%E7%AF%87/"/>
      <url>/2025/08/03/GaussDB(DWS)%E6%95%B0%E6%8D%AE%E5%BA%93-%E5%9F%BA%E7%A1%80%E7%AF%87/</url>
      
        <content type="html"><![CDATA[<h2 id="软件架构"><a href="#软件架构" class="headerlink" title="软件架构"></a>软件架构</h2><p>软件架构：分为存算分离型和存算一体型，二者的区别在于DN和存储（Local-Disk）是否绑定在一起，绑定在一起为存算一体，否则为存算分离。</p><h2 id="数据组件-7种类型"><a href="#数据组件-7种类型" class="headerlink" title="数据组件(7种类型)"></a>数据组件(7种类型)</h2><ol><li>OM(运维管理模块、主备)：提供日常运维和配置管理功能，每个节点都部署</li><li>CM(集群管理模块、主备)：自动化集群管理和监控各单元的物理资源使用情况，每个节点都部署。</li><li>GTM(全局事务控制器，主备)：主要负责生成并维护全局事务ID、事务快照、时间戳等需要全局唯一的信息。DWS集群部署2个，一主一备，分布在不同节点上。</li><li>WLM(工作负载管理)：控制资源分配，防止过载对系统冲击导致的业务拥塞和系统崩溃。内置在CN和DN实例中。</li><li>CN(Coordinator Node,协调节点，多主)：主要处理请求分解、调度、结果返回。负责SQL解析和优化。决定对外业务访问能力，默认部署2个，最大支持5个。</li><li>DN(Data Node,数据节点，主备从)：负责存储业务数据（支持行存、列存、混合存储）、执行数据查询任务以及向CN返回执行结果。决定对外业务处理能力。根据节点规格，每个节点部署2-4个，最大支持1024个。</li><li>GDS Loader(多实例)：负责批量数据加载和并行加速。</li></ol><p>物理集群由3到多个节点组成，最大支持1024个，节点为ECS&#x2F;BMS.<br>数据组件分布：以最简的ECS+EVS结构为例。ECS负责计算资源（CPU+内存+DWS实例（CN+DN等））。EVS负责存储资源，每个DN挂载EVS盘。</p><h2 id="DWS资源分配"><a href="#DWS资源分配" class="headerlink" title="DWS资源分配"></a>DWS资源分配</h2><ol><li>CPU资源：20%+60%+20%：20%CPU资源用于系统运维，20%CPU资源用于数据接入入库业务，60%CPU资源用于数据分析业务,入库业务和分析业务资源隔离，互不影响。</li><li>内存资源：默认GaussDB(DWS)使用内存占主机Linux系统可用内存的80%。GaussDB 200 默认关闭操作系统的虚拟内存。</li><li>内存参数：<ul><li>max_process_memory ：一个数据库节点（DN&#x2F;CN）可用的最大物理内存</li><li>视图pv_total_memory_detail：查看一个数据库节点总的内存分配情况。</li></ul></li></ol><h2 id="业务架构"><a href="#业务架构" class="headerlink" title="业务架构"></a>业务架构</h2><p>业务下发的SQL信息是如何在GaussDB(DWS)中的各个组件运行的。CN-&gt;DN-&gt;CN</p><ol><li>业务的查询信息先下发SQL到CN节点，其中的SQL信息可以是对数据的增删改查。</li><li>CN通过优化器生成执行计划，DN按照执行计划处理数据</li><li>在分布式存储中，数据处理的DN和数据存储DN不同，数据处理过程中需要从其他DN获取数据，通过stream流（广播流、聚合流和重分布流）降低数据在DN节点间的流动。</li><li>DN返回数据处理结果给CN，CN汇总结果。</li><li>CN将汇总结果返回给业务。</li></ol><h2 id="分布式架构优点"><a href="#分布式架构优点" class="headerlink" title="分布式架构优点"></a>分布式架构优点</h2><ol><li>支持按需扩展，支持2048节点的超大规模，100PB级的数据容量.</li><li>通过多层级的并行计算引擎，基于鲲鹏CPU的优化，软硬协同，性能相比于X86提升30%。</li><li>通过支持事务ACID,实现全场景数据的一致性数据保障，支持双集群容灾，全组件HA设计，来实现高可用。</li><li>兼容标准SQL 2003、JDBC和ODBC接口，全图形化的运维管理和开发工具，来实现高兼容性。</li></ol><h2 id="高性能"><a href="#高性能" class="headerlink" title="高性能"></a>高性能</h2><p>高斯数据库实现高性能的技术：全并行架构+分布式优化+行列混合引擎</p><ol><li>全并行架构：目的是解决如何利用x86的多核计算资源，如何解决鲲鹏众核的资源利用问题。解决方法：从大到小<ul><li>MPP(节点并行)：在集群内并行，通过使用分布式执行框架，支持1000以上的服务器，万级CPU的并行计算 </li><li>SMP(算子并行)：在查询内并行，通过多线程并行算法，从而实现在核心算子内的并行执行。众核支持，和NUMA架构优化。</li><li>SIMD(指令级并行)：操作数归并，通过SIMD和向量化引擎    ，实现一个指令执行一批数据的操作，指令可以是x86或者鲲鹏指令.</li><li>LLVM(动态编译)：指令数减少，通过将热点函数预编译成机器码，实现减少SQL执行指令数，从而提升性能。</li></ul></li><li>分布式优化：用于分布式架构下最优执行计划的生成。<ul><li>分布式查询重写:<ul><li>解决问题：单机SQL逻辑无法实现分布式执行的问题</li><li>解决方法：利用分布式查询重写技术，在分布式下消除NestLoop和子查询等查询瓶颈。</li></ul></li><li>分布式计划生成：<ul><li>解决问题：单机统计信息不能全面反应分布式数据特征</li><li>解决方案：基于Poisson估算模型，单点和全局cost估算模型，local和Global结合数据处理估算模型，实现单机+全局的自动统计信息收集。</li></ul></li><li>分布式倾斜处理：<ul><li>解决问题：数据倾斜导致的分布式执行出现木桶效应.</li><li>解决方案：针对静态模型，使用分布式倾斜估算模型；针对动态模型，使用动态倾斜处理方案RLBT（Runtime Load Balance Technology）</li></ul></li></ul></li><li>行列混合引擎：分为查询引擎和存储引擎。查询引擎分为行存+列存<ul><li>行存：适合高并发+短事务场景，例如点查询、数据更新、实时数据接入、并发增删改。</li><li>列存：适合分析AP场景，例如分析统计分组聚合、统计分析、批量加载、访问大量行少数列。</li><li>Delta列存：适合实时分析场景，例如实时分析同时进行实时插入和更新、实时插入更新进入行存Delta、实时分析基于列存+行存Delta<br>注意：Delta表是列存表附带的行存表，若创建列存表同时开启Delta表,插入列存表的数据也会以行存的形式保存。</li></ul></li></ol><h2 id="高扩展"><a href="#高扩展" class="headerlink" title="高扩展"></a>高扩展</h2><p>逻辑集群+异构扩展</p><ol><li>逻辑集群实现如下功能：通过使用CN+DN<ul><li>逻辑统一+业务隔离：用逻辑集群实现DN层的计算存储资源隔离，从而实现业务隔离。</li><li>数据共享：将不同逻辑集群的公共数据放到同一个逻辑集群中</li><li>计算弹性：可以利用空闲集群的计算资源用于其他业务的作业。</li></ul></li><li>异构扩展：用于冷数据的低成本管理<ul><li>功能：用本地盘做性能加速，用OBS做冷数据区，实现数据存储异构，自动冷热数据迁移（2年以上冷数据）。<br>结果：分层存储+成本最优：按需选择存储和计算引擎，实现冷热数据的动态切换。</li></ul></li></ol><h2 id="高可用"><a href="#高可用" class="headerlink" title="高可用"></a>高可用</h2><p>主备从HA技术+多租户资源管理+可信安全+多层次多类型备份</p><h3 id="主备从HA技术"><a href="#主备从HA技术" class="headerlink" title="主备从HA技术"></a>主备从HA技术</h3><p>功能：数据三重保护（主+备+从备）+容忍单副本故障+两副本提供HA保障。<br>主备流程：<br>正常情况：主机和备机通过日志+数据页流复制实现强同步，主机和从备仅保持连接，从备不占用额外存储资源<br>主机故障：集群管理器感知并仲裁备机升为主机，升级后的备机和从备进行主从强同步。<br>备机故障：主机自动感知，主机的未同步日志和数据发送给从备，实现主从强同步，主备同步利用内核底层实现主从同步切换，事务层不感知</p><h3 id="多租户资源管理"><a href="#多租户资源管理" class="headerlink" title="多租户资源管理"></a>多租户资源管理</h3><p>和企业组织结构匹配+管理租户资源（计算+存储）+租户资源隔离（容器技术）+租户资源监控</p><h3 id="多层级多类型备份"><a href="#多层级多类型备份" class="headerlink" title="多层级多类型备份"></a>多层级多类型备份</h3><p>多种介质：云备份推荐使用OBS备份，支持OBS&#x2F;NBU&#x2F;华为数据一体机<br>全量+增量备份：全量物理备份、差异增量、累积增量等类型备份<br>完全在线：备份期间不加锁，业务SQL无影响<br>全局一致性：备份全局一致性快照<br>细颗粒备份恢复：支持集群+schema级+表级备份恢复，支持就地集群恢复。<br>安全：加密传输。</p><h2 id="融合分析"><a href="#融合分析" class="headerlink" title="融合分析"></a>融合分析</h2><p>支持直接读写HDFS&#x2F;OBS&#x2F;PostGIS数据：<br>数据源互通：可以读取Oracle&#x2F;Spark&#x2F;Hive数据库<br>外表机制：支持HDFS&#x2F;OBS&#x2F;MPP外表，读取HDFS&#x2F;OBS数据。<br>兼容性：兼容SQL2003、JDBC&#x2F;ODBC、SQL2003访问HDFS和OBS</p><h2 id="智能运维"><a href="#智能运维" class="headerlink" title="智能运维"></a>智能运维</h2><p>适应场景：支持扩容加节点+扩容重分布+空间回收Vacuum full<br>快照策略：手动快照+自动快照<br>存储介质选择：OBS + NBU</p><p>学习资源来自<a href="https://connect.huaweicloud.com/courses/learn/Learning/sp:cloudEdu_?courseNo=course-v1:HuaweiX+CBUCNXBC006+Self-paced&courseType=1">华为云GaussDB(DWS)数据库官网</a></p>]]></content>
      
      
      <categories>
          
          <category> 数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GaussDB(DWS) </tag>
            
            <tag> 数据库 </tag>
            
            <tag> 数据仓库 </tag>
            
            <tag> 数据 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2025/04/25/hello-world/"/>
      <url>/2025/04/25/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      <categories>
          
          <category> 测试 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Typora </tag>
            
            <tag> Markdown </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
