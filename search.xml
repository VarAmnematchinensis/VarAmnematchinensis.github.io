<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>可解释人工智能及其研究-SHAP算法应用篇</title>
      <link href="/2025/09/16/%E5%8F%AF%E8%A7%A3%E9%87%8A%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%8F%8A%E5%85%B6%E7%A0%94%E7%A9%B6-SHAP%E7%AE%97%E6%B3%95%E5%BA%94%E7%94%A8%E7%AF%87/"/>
      <url>/2025/09/16/%E5%8F%AF%E8%A7%A3%E9%87%8A%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%8F%8A%E5%85%B6%E7%A0%94%E7%A9%B6-SHAP%E7%AE%97%E6%B3%95%E5%BA%94%E7%94%A8%E7%AF%87/</url>
      
        <content type="html"><![CDATA[<h3 id="SHAP算法在成人人口普查数据的应用"><a href="#SHAP算法在成人人口普查数据的应用" class="headerlink" title="SHAP算法在成人人口普查数据的应用"></a>SHAP算法在成人人口普查数据的应用</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用的是shap = 0.48.0 版本</span></span><br><span class="line"><span class="comment"># 使用的是xgboost= 3.0.4 版本</span></span><br><span class="line"><span class="comment"># 使用的是numpy = 1.26.4 版本</span></span><br><span class="line"><span class="comment"># 使用的是matplotlib = 3.10.5版本</span></span><br><span class="line"><span class="comment"># 使用的是sklearn= 1.6.1版本</span></span><br><span class="line"><span class="comment"># 使用的是lightgbm = 4.6.0版本</span></span><br><span class="line"><span class="comment"># 使用的是pandas = 2.2.3版本 </span></span><br><span class="line"><span class="comment"># 查看本地全部包和对应版本命令：pip list</span></span><br><span class="line"><span class="keyword">import</span> shap</span><br><span class="line"><span class="keyword">import</span> xgboost </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果 display 为 True，则 X 包含不包含“Education”、“Target”和“fnlwgt”目标列和冗余列的原始数据。否则，X 包含没有“Target”和“fnlwgt”列的已处理数据。</span></span><br><span class="line"><span class="comment"># X，X_display都是32561 rows x 12 columns的数据</span></span><br><span class="line"><span class="comment"># y，y_display都是32561 rows x 1 columns的数据,数组返回的“Target”列,这里可能有bug.</span></span><br><span class="line">X, y = shap.datasets.adult()</span><br><span class="line">X_display, y_display = shap.datasets.adult(display=<span class="literal">True</span>) </span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">7</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># XGBClassifier是sklearn中XGBoost分类器的实现，集成多个决策树来改善模型预测精度</span></span><br><span class="line"><span class="comment"># eval_metric确认任务类型为分类任务，使用负对数似然函数&#x27;mlogloss&#x27;</span></span><br><span class="line"><span class="comment"># 模型初始化并做模型训练</span></span><br><span class="line">model = xgboost.XGBClassifier(eval_metric=<span class="string">&#x27;mlogloss&#x27;</span>).fit(X, y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这是模型自带的特征重要性，可以查看特征重要性，plot_importance()函数基于XGBoost模型训练后计算的特征重要性分数来绘制图表，</span></span><br><span class="line"><span class="comment"># 默认使用importance_type = &#x27;weight&#x27;,特征在树中的平均权重做为重要性的度量.</span></span><br><span class="line"><span class="comment"># xgboost.plot_importance(model)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建Explainer解释器并利用训练数据X计算shap值</span></span><br><span class="line"><span class="comment"># shap_values的数据类型为 &lt;class &#x27;numpy.ndarray&#x27;&gt;</span></span><br><span class="line"><span class="comment"># shap_values2的数据类型为&lt;class &#x27;shap._explanation.Explanation&#x27;&gt;</span></span><br><span class="line">explainer = shap.Explainer(model) </span><br><span class="line">shap_values = explainer.shap_values(X) <span class="comment"># 第一个特征的shap values:shap_values[0][0]</span></span><br><span class="line">shap_values2 = explainer(X) </span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"># 全局条形图：summary plot是针对全部样本预测的解释，是取每个特征的shap values的平均绝对值来获得标准条形图，这个其实就是全局重要度</span></span><br><span class="line"><span class="string"># Summary_plot 为每一个样本绘制其每个特征的Shapley value，它说明哪些特征最重要，以及它们对数据集的影响范围。</span></span><br><span class="line"><span class="string"># 另一种是通过散点简单绘制每个样本的每个特征的shap values，通过颜色可以看到特征值大小与预测影响之间的关系，同时展示其特征值分布</span></span><br><span class="line"><span class="string"># 两个图都可以看到Relationship全局重要度是最高的，其次是Age。第一个图可以看到各个特征重要度的相对关系，虽然Capital Gain是第三，但是重要度只有Relationship的60%，</span></span><br><span class="line"><span class="string"># shap.summary_plot使用的是shap_values的数据类型为 &lt;class &#x27;numpy.ndarray&#x27;&gt;</span></span><br><span class="line"><span class="string"># shap.plots.bar使用的是shap_values2的数据类型为&lt;class &#x27;shap._explanation.Explanation&#x27;&gt;</span></span><br><span class="line"><span class="string">#shap.plots.bar(shap_values2, max_display = 12)</span></span><br><span class="line"><span class="string">shap.summary_plot(shap_values, X, plot_type=&quot;bar&quot;)</span></span><br><span class="line"><span class="string">#按照计算公式，可得其数值表格化如下</span></span><br><span class="line"><span class="string">feature_importance = pd.DataFrame()</span></span><br><span class="line"><span class="string">feature_importance[&#x27;feature&#x27;] = X.columns</span></span><br><span class="line"><span class="string">feature_importance[&#x27;importance&#x27;] = np.abs(shap_values).mean(0)</span></span><br><span class="line"><span class="string">feature_importance.sort_values(&#x27;importance&#x27;, ascending=False)</span></span><br><span class="line"><span class="string">print(feature_importance)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># y 轴上的位置由特征确定，x 轴上的位置由每 Shapley value 确定。颜色表示特征值（红色高，蓝色低），颜色使我们能够匹配特征值的变化如何影响风险的变化。</span></span><br><span class="line"><span class="comment"># 重叠点在 y 轴方向抖动，因此我们可以了解每个特征的 Shapley value分布，并且这些特征是根据它们的重要性排序的。</span></span><br><span class="line"><span class="comment"># 由颜色深浅则可以看到Relationship和Age都是值越大，个人年收入超过5万美元的可能性越大，平均而言年龄是最重要的特征，与年轻（蓝色）人相比，收入超过 5 万美元的可能性较小</span></span><br><span class="line"><span class="comment"># 也使用可以shap.plots.beeswarm绘制一样的蜂群图，在显示数据集中的TOP特征如何影响模型输出的信息密集摘要。</span></span><br><span class="line"><span class="comment"># 点的 x 位置由该特征的 SHAP 值 ( shap_values.value[instance,feature]) 确定，并且点沿每个特征行“堆积”以显示密度。</span></span><br><span class="line"><span class="comment">#shap.summary_plot(shap_values, X)</span></span><br><span class="line"><span class="comment">#shap.plots.beeswarm(shap_values2, order=np.abs(shap_values).mean(0).argsort()[::-1], max_display = 12)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 可以使用matplotlib构建自定义颜色图，color默认使用shap.plots.colors.red_blue的颜色</span></span><br><span class="line"><span class="comment">#shap.plots.beeswarm(shap_values2,  color=plt.get_cmap(&quot;cool&quot;))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 局部特征重要性条形图, 条形是每个特征的 SHAP 值。最左侧的灰色显示数值是特征值</span></span><br><span class="line"><span class="comment">#shap.plots.bar(shap_values2[1], max_display = 12)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制男性和女性特征重要性的全局摘要</span></span><br><span class="line"><span class="comment">#sex = [&quot;Women&quot; if shap_values2[i,&quot;Sex&quot;].data == 0 else &quot;Men&quot; for i in range(shap_values2.shape[0])]</span></span><br><span class="line"><span class="comment">#shap.plots.bar(shap_values2.cohorts(sex).abs.mean(0))</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用Explanation对象的自动群组功能来创建一个群组，调用Explanation.cohorts(N)将创建N个队列，</span></span><br><span class="line"><span class="comment"># 使用 sklearn DecisionTreeRegressor 最佳地分离实例的 SHAP 值，图例中的方括号显示的是每个队列中的实例数</span></span><br><span class="line"><span class="comment">#shap.plots.bar(shap_values2.cohorts(2).abs.mean(0), max_display = 12)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 拟合相对于目标变量 y 的特征 X 的分层聚类模型,可以在SHAP中通过模型损失比较来测量特征冗余</span></span><br><span class="line"><span class="comment"># 计算聚类并传递给条形图，就可以同时可视化特征冗余结构和特征重要性。默认只会显示距离 &lt; 0.5 的聚类部分</span></span><br><span class="line"><span class="comment">#clustering = shap.utils.hclust(X, y) </span></span><br><span class="line"><span class="comment">#shap.plots.bar(shap_values2, clustering=clustering, max_display = 12)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># SHAP Partial dependence plot (PDP or PD plot) 依赖图显示了一个或两个特征对机器学习模型的预测结果的边际效应</span></span><br><span class="line"><span class="comment"># PDP 的一个假设是第一个特征与第二个特征不相关。如果违反此假设，则 PDP 计算的平均值将包括极不可能甚至不可能的数据点</span></span><br><span class="line"><span class="comment"># 参数interaction_index用于设置交互项，用于验证特征之间是否存在交互效应</span></span><br><span class="line"><span class="comment"># Dependence plot 是一个散点图，显示单个特征对整个数据集的影响。每个点都是来自数据集的单个预测（行）。</span></span><br><span class="line"><span class="comment"># x 轴是数据集中的实际值。（来自 X 矩阵，存储在 中shap_values.data）。</span></span><br><span class="line"><span class="comment"># y 轴是该特征的 SHAP 值（存储在 中shap_values.values），它表示该特征值对该预测的模型输出的改变程度</span></span><br><span class="line"><span class="comment">#先看某个特征是如何影响到模型预测结果的</span></span><br><span class="line"><span class="comment">#看到Age越大，个人年收入超过5万美元的可能性越大，但是在65岁后出现波动，80岁后可能性下降</span></span><br><span class="line"><span class="comment">#shap.dependence_plot(&#x27;Age&#x27;, shap_values, X, interaction_index=None)</span></span><br><span class="line"><span class="comment">#相同的图片画法</span></span><br><span class="line"><span class="comment">#plt.figure(figsize=(7.5, 5))</span></span><br><span class="line"><span class="comment">#plt.scatter(X[&#x27;Age&#x27;], shap_values[:, 0], s=10, alpha=1)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 一个特征是如何和另一个特征交互影响到模型预测结果的，这里以Age和Capital Gain为例子</span></span><br><span class="line"><span class="comment"># 散点还是由Age绘制，但是Age的预测其实是有其他特征相互作用的，散点图垂直分散就是由相互作用效应驱动，</span></span><br><span class="line"><span class="comment"># 所以用Capital Gain进行着色以突出显示可能的相互作用</span></span><br><span class="line">shap.dependence_plot(<span class="string">&#x27;Age&#x27;</span>, shap_values, X,  display_features=X_display, interaction_index=<span class="string">&#x27;Capital Gain&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#shap values绘制归因关系是有其他特征的相互作用使图垂直分散的，可以使用shap_interaction_values消除这种相互作用</span></span><br><span class="line">shap_interaction_values = explainer.shap_interaction_values(X)</span><br><span class="line">shap.dependence_plot((<span class="string">&#x27;Age&#x27;</span>, <span class="string">&#x27;Age&#x27;</span>), shap_interaction_values, X, interaction_index=<span class="literal">None</span>)</span><br><span class="line"><span class="comment">#相同的图片画法</span></span><br><span class="line">plt.figure(figsize=(<span class="number">7.5</span>, <span class="number">5</span>))</span><br><span class="line">plt.scatter(X[<span class="string">&#x27;Age&#x27;</span>], shap_interaction_values[:, <span class="number">0</span>, <span class="number">0</span>], s=<span class="number">10</span>, alpha=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># shap.plots.scatte图底部的浅灰色区域是显示数据值分布的直方图</span></span><br><span class="line"><span class="comment"># 在交互颜色方面，散点图则需要将整个 Explanation 对象传递给 color 参数</span></span><br><span class="line"><span class="comment">#shap_values2.display_data = X_display.values</span></span><br><span class="line"><span class="comment">#shap.plots.scatter(shap_values2[:, &quot;Age&quot;], color=shap_values2[:,&quot;Workclass&quot;])</span></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"># SHAP force plot 提供了单一模型预测的可解释性，可用于误差分析，找到对特定实例预测的解释</span></span><br><span class="line"><span class="string"># 如果不想用JS,需要在shap.force_plot传入matplotlib=True的参数。否则就需要使用shap.initjs()</span></span><br><span class="line"><span class="string"># 模型输出值是-6.75，模型基值是-1.297，绘图箭头下方数字是此实例的特征值，将预测推高的特征用红色表示，将预测推低的特征用蓝色表示</span></span><br><span class="line"><span class="string"># 箭头越长，特征对输出的影响越大。explainer.expected_value是解释模型的常数</span></span><br><span class="line"><span class="string">#shap.initjs() # 初始化JavaScript库</span></span><br><span class="line"><span class="string">#shap.force_plot(explainer.expected_value, shap_values[0,:], X_display.iloc[0,:])</span></span><br><span class="line"><span class="string"># 或者</span></span><br><span class="line"><span class="string">shap.force_plot(explainer.expected_value, shap_values[0,:], X_display.iloc[0,:], matplotlib=True)</span></span><br><span class="line"><span class="string">#其数值表格化如下：</span></span><br><span class="line"><span class="string">sample_0_shap = pd.DataFrame(X.iloc[0,:])</span></span><br><span class="line"><span class="string">sample_0_shap.rename(columns=&#123;0: &#x27;feature_value&#x27;&#125;, inplace=True)</span></span><br><span class="line"><span class="string">sample_0_shap[&#x27;shap_value&#x27;] = shap_values[0]</span></span><br><span class="line"><span class="string">sample_0_shap.sort_values(&#x27;shap_value&#x27;, ascending=False)</span></span><br><span class="line"><span class="string">print(sample_0_shap)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># explainer.shap_interaction_values是实现快速两两交互计算，将为每个预测返回一个矩阵，其中主要影响在对角线上，交互影响在对角线外</span></span><br><span class="line"><span class="comment">#shap.summary_plot(explainer.shap_interaction_values(X), X) # 第一个特征的shap interaction values:explainer.shap_interaction_values(X)[0][0]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Decision plot决策图：SHAP 决策图显示复杂模型如何得出其预测（即模型如何做出决策）</span></span><br><span class="line"><span class="comment"># 决策图中间灰色垂直直线标记了模型的基础值，彩色线是预测，表示每个特征是否将输出值移动到高于或低于平均预测的值。特征值在预测线旁边以供参考。</span></span><br><span class="line"><span class="comment"># 从图的底部开始，预测线显示 SHAP value 如何从基础值累积到图顶部的模型最终分数</span></span><br><span class="line"><span class="comment">#expected_value = explainer.expected_value</span></span><br><span class="line"><span class="comment">#features = X.iloc[range(20)]# 限制20个样本</span></span><br><span class="line"><span class="comment">#shap_values = explainer.shap_values(features)[1]# 展示第一条样本</span></span><br><span class="line"><span class="comment">#features_display = X_display.loc[features.index]</span></span><br><span class="line"><span class="comment">#shap.decision_plot(expected_value, shap_values, features_display)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 决策图支持将对link=&#x27;logit&#x27;数几率转换为概率。</span></span><br><span class="line"><span class="comment"># 使用虚线样式highlight=misclassified突出显示一个错误分类的观察结果</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">shap_values = explainer.shap_values(features)</span></span><br><span class="line"><span class="string">y_pred = (shap_values.sum(1) + expected_value) &gt; 0</span></span><br><span class="line"><span class="string">misclassified = y_pred != y[:20]</span></span><br><span class="line"><span class="string">shap.decision_plot(expected_value, shap_values, </span></span><br><span class="line"><span class="string">                   features_display, </span></span><br><span class="line"><span class="string">                   link=&#x27;logit&#x27;, </span></span><br><span class="line"><span class="string">                   highlight=misclassified)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 通过单独绘制来检查错误分类的观察结果</span></span><br><span class="line"><span class="string">shap.decision_plot(expected_value, shap_values[misclassified], </span></span><br><span class="line"><span class="string">                   features_display[misclassified],</span></span><br><span class="line"><span class="string">                   link=&#x27;logit&#x27;, </span></span><br><span class="line"><span class="string">                   highlight=0)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 错误分类观察的力图</span></span><br><span class="line"><span class="string">shap.force_plot(expected_value, shap_values[misclassified], </span></span><br><span class="line"><span class="string">                features_display[misclassified],</span></span><br><span class="line"><span class="string">                link=&#x27;logit&#x27;)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 瀑布图旨在显示单个预测的解释，因此将解释对象的单行作为输入。瀑布图从底部的模型输出的预期值开始，</span></span><br><span class="line"><span class="comment"># 每一行显示每个特征的是正（红色）或负（蓝色）贡献，即如何将值从数据集上的模型预期输出值推动到模型预测的输出值</span></span><br><span class="line"><span class="comment"># waterfall绘图显示单个样本数据</span></span><br><span class="line"><span class="comment">#shap.plots.waterfall(shap_values2[5], max_display = 12)</span></span><br><span class="line"><span class="comment">#shap.plots.scatter(shap_values2[:,&quot;Relationship&quot;])</span></span><br></pre></td></tr></table></figure><h3 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h3><p>[1] <a href="https://zhuanlan.zhihu.com/p/441302127">用 SHAP 可视化解释机器学习模型的输出实用指南</a><br>[2] <a href="https://zhuanlan.zhihu.com/p/103370775">SHAP的理解与应用</a><br>[3]<a href="https://www.biaodianfu.com/shap.html">机器学习可解释性工具：SHAP </a></p><h3 id="以后的研究注意方向：使用-GPU-加速-SHAP-解释机器学习模型预测"><a href="#以后的研究注意方向：使用-GPU-加速-SHAP-解释机器学习模型预测" class="headerlink" title="以后的研究注意方向：使用 GPU 加速 SHAP 解释机器学习模型预测"></a>以后的研究注意方向：<a href="https://developer.nvidia.com/zh-cn/blog/explain-your-machine-learning-model-predictions-with-gpu-accelerated-shap/">使用 GPU 加速 SHAP 解释机器学习模型预测</a></h3>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
            <tag> 算法 </tag>
            
            <tag> 可解释 </tag>
            
            <tag> SHAP算法 </tag>
            
            <tag> 应用 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>可解释人工智能及其研究-SHAP算法说明篇</title>
      <link href="/2025/09/16/%E5%8F%AF%E8%A7%A3%E9%87%8A%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%8F%8A%E5%85%B6%E7%A0%94%E7%A9%B6-SHAP%E7%AE%97%E6%B3%95%E8%AF%B4%E6%98%8E%E7%AF%87/"/>
      <url>/2025/09/16/%E5%8F%AF%E8%A7%A3%E9%87%8A%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%8F%8A%E5%85%B6%E7%A0%94%E7%A9%B6-SHAP%E7%AE%97%E6%B3%95%E8%AF%B4%E6%98%8E%E7%AF%87/</url>
      
        <content type="html"><![CDATA[<h3 id="SHAP可解释性算法"><a href="#SHAP可解释性算法" class="headerlink" title="SHAP可解释性算法"></a>SHAP可解释性算法</h3><ol><li>算法介绍：SHAP(SHapley Additive exPlanation)，一种基于博弈论思想为载体的、模型无关(可以用于任何机器学习)的、事后机器学习可解释算法。能衡量单次预测结果中的特征贡献，也能聚合局部结果作为对模型的整体解释。其中：<ul><li>SHapley ：代表对每个样本中的每一个特征变量，都计算出它的Shapley Value；</li><li>Additive ：代表对每一个样本而言，特征变量对应的Shapley Value是可加的；</li><li>exPlanation：代表对每个样本的解释，即每个特征变量是如何影响模型的预测值。</li></ul></li></ol><h3 id="算法原理：夏普利值-shapley-value"><a href="#算法原理：夏普利值-shapley-value" class="headerlink" title="算法原理：夏普利值(shapley value)"></a>算法原理：夏普利值(shapley value)</h3><ol><li>算法历史：<ul><li>2012年诺贝尔经济学奖得主LIoyd.S.Shapley在1953年提出的分配方式（论文《A Value for n-Person Games》）。</li><li>2010年， Erik Štrumbelj 和 Igor Kononenko 发表题为《An Efficientterpretation of individual Classification using Game Theory》”的论文，首次提出使用 Shapley 值来解释机器学习模型的预测。</li><li>2017年，Scott Lundberg 和 Su-In Lee 发表题为《A unified approach to interpreting model predictions》的论文，详细介绍了SHapley Additive exPlanations (SHAP)用于机器学习可解释性。</li></ul></li><li>价值：是模型可解释性领域为数不多、理论严谨的算法，是唯一无偏地满足可加性、对称性、冗员性和有效性的指标。</li><li>解决问题：主要用于按照合作各方对合作总目标的贡献程度，按照贡献度分配，避免平均主义，来解决在合作博弈中各方的利益分配问题。</li><li>基础公理：可加性、对称性、冗员性和有效性，LIoyd.S.Shapley证明，原始Shapley值是唯一满足这四条公理的合作博弈解，而且最具合理性和公平性的分配方式也是唯一的。<ul><li>可加性(Additivity)：不同模型在相同输入单元中计算得到的重要性数值是线性可加的；表示在有多种合作时，每种合作的利益分配方式与其他合作结果无关。</li><li>对称性（Symmetry）：始终起到相同作用的两个输入单元，其得到的重要性数值也是相同的；表示合作获利的分配不随每个人在合作中的记号或者次序变化，即博弈顺序不影响博弈收益。</li><li>冗员性(Dummy)：输入样本中的冗员单元的重要性等于其独立作用于神经网络的输出，这里的冗员单元定义为不与其它任何单元相互作用的输入单元；表示如果一个成员对于任何他参与的合作联盟都没有贡献，则他不应该从全体合作中获利。</li><li>有效性（Efficiency 效率）：所有输入单元的重要性之和恰好为神经网络的输出；表示合作各方获利总和等于合作获利。</li></ul></li><li>shapley value和可解释性关系：在机器学习领域，“模型特征”可以用shapley value去刻画每个模型特征对最后模型结果的“贡献”，类似于特征重要性。</li><li>shapley value在机器学习模型解释中的难点：<ul><li>每个子集或联盟收益情况判断：一般我们知道组合最大或最大子集的情况下的收益，无法知道从单个子集到最大子集等所有组合子集的收益情况。</li><li>计算复杂度指数级计算：由于shapley value依赖子集逐个计算，导致shapley value计算复杂度随指数级增长。即$O(2^{M})$,M为子集个数</li></ul></li></ol><h3 id="shapley-value数学原理解释"><a href="#shapley-value数学原理解释" class="headerlink" title="shapley value数学原理解释"></a>shapley value数学原理解释</h3><p>模型的输入特征表示为“玩家”， 对于给定输入基于特征子集$S$进行预测表示“游戏”，特征子集$S$表示“合作”，使用子集$S$时的模型预测值和基线预测值之差被定义为“价值函数”$\upsilon(S)$, $\phi_{i}(f, x)$量化第$i$个特征对预测模型$f(x)$的平均边际贡献，它本身通过考虑所有不含特征$i$的特征子集$S$，计算特征$i$加入S时带来的预测值变化（即边际贡献），然后对所有边际贡献进行加权平均。得到数据表达式如下：<br>$$<br>\phi_{i}(f, x) &#x3D; \sum_{S \subseteq F \setminus  {i} } \frac{|S|! \cdot (|F| - |S| - 1)!}{|F|!} \cdot [\upsilon(S \cup { i}) - \upsilon(S)]<br>$$<br>其中：$F$表示所有特征集合，$|F|$表示总特征数，$S$表示$F$中不包含特征$i$的一个子集，$[\upsilon(S \cup { i})$表示当特征$i$加入特征子集$S$时的模型（或者价值函数）的输出，$\upsilon(S)$表示仅适用特征子集$S$时的模型（或者价值函数）的输出。<br>这个数学公式核心思想：一个特征的重要性取决于它在各种可能的特征组合中加入时，平均能带来多大的预测改变，进而确保按贡献分配的公平性。</p><h3 id="SHAP数学原理解释"><a href="#SHAP数学原理解释" class="headerlink" title="SHAP数学原理解释"></a>SHAP数学原理解释</h3><p>SHAP利用shapley value的原理，在 shapley value原理基础上，增加常数项$\phi_{0}$,则shapley value的含义变为在预测均值的基础上，对预测值所起到的作用。<br>对于单个样本，事后解释模型$g$的表达形式为：<br>$$<br>g(x) &#x3D; \phi_{0} + \sum_{j &#x3D; 1}^{M}\phi_{j}<br>$$<br>其中，$M$是模型中的特征数量，$\phi_{0} $是所有样本预测值的均值。<br>对于特定的预测模型$f(x)$, 其对应的解释模型$g$可以表示为各个特征归因值（SHAP值）的线性组合：</p><p>$$<br>g(z^{\prime}) &#x3D; \phi_{0} + \sum_{j &#x3D; 1}^{M}\phi_{j} z^{\prime}_{j}<br>$$</p><p>其中：$g(z^{\prime})$表示解释模型的输出，$z^{\prime}$是简化的二进制输入向量（$z^{\prime} &#x3D; 1$表示特征$j$“存在”，$z^{\prime} &#x3D; 0$表示特征$j$“缺失”），$M$表示特征总数，$\phi_{0}$表示基线值（通常表示模型在数据集上的平均预测$E[f(X)]$）, $\phi_{j}$表示是特征$j$的SHAP值。</p><p>SHAP值是Shapley值在机器学习和模型解释领域的特定应用。SHAP值不仅继承Shapley值满足四条公理的特性，还具有以下三条对模型解释至关重要的理想性质：（原始模型$f$和解释模型$g$正向相关）</p><ul><li><strong>局部准确性(Local Accuracy)</strong>：对于特定的输入$x$,解释模型$g(z^{\prime})$(当所有特征都“存在”时，即$z^{\prime}$对应于$x$的完整特征表示)的输出必须精确等于原始模型$f(x)$的输出。表示所有特征的SHAP值之和加上基准值$\phi_{0}$等于该实例的预测值$f(x)$。<br>$$<br>f(x) &#x3D; \phi_{0} + \sum_{j &#x3D; 1}^{M}\phi_{j}(当所有z_{j}^{\prime} &#x3D; 1时)<br>$$<br>这保证解释完整性，所有特征的贡献总和恰好等于预测值和基线值之差。</li><li><strong>缺失性(Missingness)</strong>：如果一个特征在简化输入$z^{\prime}$中被视为“缺失”（即$z_{j}^{\prime}&#x3D; 0$），那么其对应的SHAP值$\phi_{j}$在解释模型$g(z^{\prime})$中的贡献应为零(即$\phi_{j}\cdot z^{\prime} &#x3D; 0$)。即如果一个特征$x_{j}$对预测没有贡献，那么他的SHAP值$\phi_{j}$应该是零。</li><li><strong>一致性(Consistency)</strong>：如果一个模型被修改后，某个特征的边际贡献在任何特征组合下都增加或者保持不变，那么该特征的SHAP值也应该增加或者保持不变。该属性保证SHAP值能够可靠的反应特征重要性的真实变化，避免某些方法可能出现的反直觉行为。</li></ul><h3 id="SHAP值难点计算解决方案"><a href="#SHAP值难点计算解决方案" class="headerlink" title="SHAP值难点计算解决方案"></a>SHAP值难点计算解决方案</h3><ol><li>近似算法：<ul><li>模型无关算法：Kernel SHAP</li><li>模型相关算法TreeSHAP（适用于基于树模型的算法，Interventional TreeSHAP和Path-dependent TreeSHAP）、DeepSHAP算法（适用于深度学习模型）</li></ul></li><li>Kernel SHAP算法：在结合LIME可解释算法基础上，使用拟合加权线性模型来估算shapley value。算法五步骤如下（此部分可看参考文献[2] 第161页）：<ul><li><p>采样：采样联盟$z^{\prime}_{k} \in {0,1}^{M}, k \in {1, …, K }$(1 &#x3D; 联盟中存在的特征，0 &#x3D; 不存在的特征)</p></li><li><p>对采样值进行预测：对$z^{\prime}<em>{k}$预测，方法是首先将$z^{\prime}</em>{k}$转换为原始特征空间，然后应用模型$f:f(h_{x}( z^{\prime}_{k}))$。</p></li><li><p>使用SHAP核来计算每个$z^{\prime}_{k}$的权重。其中SHAP核如下：$M$是最大联盟大小，$|z^{\prime}|$实例$z^{\prime}$中当前特征的数量。用这个核权重的线性回归会产生Shapley值。</p></li></ul></li></ol><p>$$<br>\pi_{x}(z^{\prime}) &#x3D; \frac{(M - 1)}{\begin{pmatrix}<br>M\<br>|z^{\prime}|\<br>\end{pmatrix}|z^{\prime}|(M - z^{\prime})}<br>$$</p><ul><li>拟合加权线性模型，可以使用损失函数$L$来训练线性函数$g$:</li></ul><p>$$<br>g(z^{\prime}) &#x3D; \phi_{0} + \sum_{j &#x3D; 1}^{M}\phi_{j} z^{\prime}_{j}<br>$$</p><p>$$<br>L(f, g, \pi_{x}) &#x3D; \sum_{z^{\prime} \in Z}[f(h_{x}(z^{\prime}))-g(z^{\prime})]^{2}\pi_{x}(z^{\prime})<br>$$<br>其中$Z$是训练数据。</p><ul><li>返回shapley值$\phi_{k}$，即线性模型的系数。</li></ul><ol start="4"><li>算法优缺点:<ul><li>算法优点：模型无关性和通用性，理论上适用于任何类型的机器学习模型。</li><li>算法缺点：需要大量扰动样本进行模型评估，计算成本高。要求特征之间必须相互独立，如果特征之间存在高度相关，则可能会出现在现实中不可能出现的数据点，从而对SHAP值的估计产生误差。</li></ul></li></ol><h3 id="算法应用价值"><a href="#算法应用价值" class="headerlink" title="算法应用价值"></a>算法应用价值</h3><ol><li><p>业务领域：对异常变动敏感的业务领域，可以使用SHAP算法进行异常分析，快速定位异常原因，也可以在业务规则之外，提供新的“解释”。</p></li><li><p>模型解释和调试：可以用来解释“黑盒”是AI预测模型，既可以进行局部解释（单点数据样例），也可以实现全局可解释（数据集）。</p></li><li><p>利益分配：合作博弈的核心在于合理公平地分配合作成果，可以SHAP算法用于按照对项目的贡献分配奖金，衡量影响力大小对决策的影响。</p></li><li><p>领域应用：在金融、保险领域，SHAP可用来解释信贷评分、保险理赔反欺诈监测（中国人寿）和隐私合规的要求。分布式可解释算法已在蚂蚁集团内部反欺诈、反洗钱等场景中有落地。</p></li></ol><h3 id="算法工具：SHAP开源算法库"><a href="#算法工具：SHAP开源算法库" class="headerlink" title="算法工具：SHAP开源算法库"></a>算法工具：<a href="https://github.com/slundberg">SHAP开源算法库</a></h3><ol><li>介绍：由Scott Lundberg开发，内置Kernel SHAP&#x2F;Tree SHAP&#x2F;Deep SHAP等多种API.</li><li>安装：PyPI和Conda</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pip install shap</span><br><span class="line">or</span><br><span class="line">conda install -c conda-forge shap</span><br></pre></td></tr></table></figure><ol start="3"><li><a href="https://shap.readthedocs.io/en/latest/api.html">API方法</a></li></ol><table><thead><tr><th>命令</th><th>说明</th><th>是否和模型相关</th></tr></thead><tbody><tr><td>shap.Explainer(model[, masker, link, …])</td><td>使用 Shapley 值来解释任何机器学习模型或 python 函数。</td><td></td></tr><tr><td>shap.TreeExplainer(model[, data, …])</td><td>使用树 SHAP 算法来解释集成树模型的输出。</td><td>用于树模型</td></tr><tr><td>shap.GPUTreeExplainer(model[, data, …])</td><td>reeExplainer 的实验性 GPU 加速版本。支持与 TreeExplainer 相同的能力，同时支持基于 GPU 进行加速</td><td>用于树模型</td></tr><tr><td>shap.LinearExplainer(model, masker[, link, …])</td><td>计算线性模型的 SHAP 值，可以选择考虑特征间相关性。</td><td>用于线性模型</td></tr><tr><td>shap.PermutationExplainer(model, masker[, …])</td><td>通过迭代输入的排列来近似 Shapley 值，通过遍历输入的排列变换来估计 Shapely values，能够保证 Local accuracy 性质</td><td>模型无关</td></tr><tr><td>shap.PartitionExplainer(model, masker, *[, …])</td><td>通过特征层次结构递归计算 Shapley 值，该层次结构定义特征联盟并根据博弈论得出 Owen 值。</td><td>模型无关</td></tr><tr><td>shap.SamplingExplainer(model, data, **kwargs)</td><td>使用 Shapley 抽样值解释方法（也称为 IME）的扩展计算 SHAP 值。</td><td>模型无关</td></tr><tr><td>shap.AdditiveExplainer(model, masker[, …])</td><td>计算广义加性模型(GAM) 的 SHAP 值，并假设模型仅具有一阶交叉。</td><td>用于GAM</td></tr><tr><td>shap.DeepExplainer(model, data[, session, …])</td><td>旨在近似深度学习模型的 SHAP 值。shap实现为DeepLIFT 算法（Deep SHAP）的增强版本，与 Kernel SHAP 类似，我们使用选择的背景样本来近似 SHAP 值的条件期望。支持 tf 模型和 torch 模型</td><td>用于深度学习模型</td></tr><tr><td>shap.KernelExplainer(model, data[, …])</td><td>Kernel SHAP 是一种使用特殊的加权线性回归来计算每个特征的重要性的方法。计算的重要性值是来自博弈论的Shapley值以及来自局部线性回归的系数。</td><td>模型无关</td></tr><tr><td>shap.GradientExplainer(model, data[, …])</td><td>使用预期梯度（积分梯度的扩展）解释模型</td><td></td></tr><tr><td>shap.ExactExplainer(model, masker[, link, …])</td><td>通过优化的精确枚举计算 SHAP 值。</td><td>模型无关</td></tr><tr><td>shap.explainers.other.Coefficient(model)</td><td>只需将模型系数作为特征归因返回</td><td></td></tr><tr><td>shap.explainers.other.Random(model, masker)</td><td>仅返回随机（正态分布）特征归因</td><td></td></tr><tr><td>shap.explainers.other.LimeTabular(model, data)</td><td>简单地包裹 lime.lime_tabular。LimeTabularExplainer 到公共 shap 接口中.</td><td></td></tr><tr><td>shap.explainers.other.Maple(model, data)</td><td>只需将 MAPLE 包装到通用 SHAP 接口中即可</td><td></td></tr><tr><td>shap.explainers.other.TreeMaple(model, data)</td><td>只需将 MAPLE 树到通用 SHAP 接口中即可</td><td></td></tr><tr><td>shap.explainers.other.TreeGain(model)</td><td>仅返回树模型的全局增益&#x2F;基尼特征重要性</td><td></td></tr></tbody></table><ol start="4"><li>构建 shap解释器：</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">shap.Explainer(model,  # 要评估的方法或者模型</span><br><span class="line">   masker=None,  # 为 Explainer 提供 mask 后的背景数据</span><br><span class="line">   link=links.identity, # 指定输出结果的单位与 SHAP value 单位的关系，通常使用相同单位，也可以使用log关系</span><br><span class="line">   algorithm=&quot;auto&quot;, # 使用哪种算法来估计Shapely value，通常使用auto来自动选择</span><br><span class="line">   output_names=None, # 模型输出的名称，主要用于后续可视化</span><br><span class="line">   feature_names=None, # 输入中每一列的名称</span><br><span class="line">   linearize_link=True, # 这个代码里没解释……</span><br><span class="line">   seed=None, # 如果要复现结果，指定seed为某个int值</span><br><span class="line">   **kwargs)</span><br></pre></td></tr></table></figure><ul><li>用途：构建SHAP库的主要解释器接口类，能够根据用户传入的 model、masker 等信息，自动的选择合适的 explainer 来作为评估的实例。</li><li>常用参数：<ul><li>model：需要解释的模型对象或者函数对象，用于根据获取到样本数据集计算这些样本的模型输出；</li><li>algorithm：分为“auto”, “permutation”, “partition”, “tree”, or “linear”，表示用于估计 Shapley 值的算法。默认情况下，“auto”选项会尝试在给定传递的模型model和masker的情况下做出最佳选择；</li><li>seed： 随机数种子，用于重复测验。</li></ul></li><li>方法：<ul><li>shap.Explainer().<strong>init</strong>():传递模型构建新解释器；</li><li>shap.Explainer().explain_row()：解释单行并返回由（row_values、row_expected_values、row_mask_shapes、main_effects）构成的元组。抽象方法，需要有子类实现。返回对象是由（row_values， row_expected_values， row_mask_shapes）构成的元祖。 row_values 是每个样本归因值数组，row_expected_values 是表示每个样本模型预期值数组，row_mask_shapes 是所有输入形状的列表；</li><li>shap.Explainer().supports_model_with_masker(model, masker):确定此解释器是否可以处理给定模型，返回是False或True.抽象方法，需要有子类实现；</li><li>shap.Explainer().load(in_file)：从给定文件流in_file中加载解释器；</li><li>shap.Explainer().save(out_file)：将解释器写入给定的文件流out_file中。</li></ul></li></ul><h3 id="SHAP开源算法库可视化交互探索工具"><a href="#SHAP开源算法库可视化交互探索工具" class="headerlink" title="SHAP开源算法库可视化交互探索工具"></a><a href="https://github.com/slundberg">SHAP开源算法库</a>可视化交互探索工具</h3><ol><li><p>可视化交互探索工具按照返回值解释情况分类：</p><ul><li>局部可解释性(Local Interper)：侧重解释单个预测的生成，对单条或者多条样本预测值的解释。可以使用waterfall(瀑布图)&#x2F;decision图&#x2F;force图&#x2F;bar图（柱状图）.</li><li>全局可解释性(Global Interger):得到模型的总体结构(overall structure).</li></ul></li><li><p>瀑布图(Waterfall Plot)：</p><ul><li>命令：shap.plots.waterfall()</li><li>解释：展示了对于单个预测，各个特征的 SHAP 值如何一步步地将模型的预测输出从基线值（通常是平均预测值）推向最终的预测值。</li></ul></li><li><p>力图(Force Plot)：</p><ul><li>解释：以一种“力”的隐喻来可视化单个预测的特征贡献，针对单个样本预测解释，将shap value可视化为force，每个特征增加或减少预测的force值，预测以基线开始，基线是解释模型的常数，每个归因值为一个箭头，增加(正值)或减少(负值)预测，红色为正共享，蓝色为负贡献。红色特征（正 SHAP 值）将预测推高，蓝色特征（负 SHAP 值）将预测拉低，直观地显示了驱动预测结果的关键因素及其相对强度</li><li>命令：shap.force_plot()</li><li>可视化：基线值：图中的起点表示模型的基线值（expected_value）也就是可视化当中的base value,是传入数据集上模型预测值的均值，可以通过自己计算来验证；特征贡献：每个特征的贡献通过带颜色的条表示，条的长度表示该特征对最终预测值的影响大小，红色条表示正向贡献，即该特征使预测值增加，蓝色条表示负向贡献，即该特征使预测值减少；预测值：终点表示模型对该样本的最终预测值，这是基线值加上所有特征贡献的总和.</li></ul></li><li><p>摘要图(Summary Plot &#x2F; Beeswarm Plot):</p><ul><li>解释：这是一种非常强大的全局解释图。它通常将每个特征的 SHAP 值分布以散点图（蜂群图）的形式展示出来，其中每个点代表一个样本的一个特征的 SHAP 值。点的颜色通常表示原始特征值的高低，这有助于揭示特征值与其对预测影响之间的关系。</li><li>命令：shap.summary_plot（）</li><li>作用：摘要图是SHAP常用的一种可视化方法，用于显示特征的重要性和特征值的影响方向，摘要图结合了特征重要性和特征效应图，展示了每个特征的SHAP值的分布情况，帮助我们理解每个特征对模型预测的贡献，这张可视化结果可在众多论文当中看见，当然你也可以通过参数cmap改变配色避免审美疲劳。包括：cmap：”viridis”：从黄色到蓝绿色。”Spectral”：从红色到蓝色，适用于有正负影响的特征。”coolwarm”：从冷到暖的颜色图。”RdYlGn”：从红到绿的颜色图。”RdYlBu”：从红到蓝的颜色图。”RdBu”：红蓝双色图。”RdGy”：红灰双色图。”PuOr”：从紫色到橙色的颜色图。”BrBG”：从棕色到蓝绿色的颜色图。”PRGn”：从紫色到绿色的颜色图。”PiYG”：从粉红色到绿色的颜色图。</li><li>颜色：粉红色点:表示特征值在这个观察模型中对模型预测产生了正面影响。蓝色点:表示该特征值在这个观察中对模型预测产生负面影响。每个样本每个特征的SHAP值，并允许发现预测异常值。每一行代表一个特征，横坐标代表SHAP值。每一个单代表一个样本，颜色代表特征值（红色高，蓝色低）。红色越集中在均值左侧，而蓝色集中在右侧，则说明特征的大小和模型预测值是负相关;而红色越集中在均值右侧，而蓝色集成中均值左侧，说明特征的大小和模型预测值负相关；红蓝混合在一起，则说明特征的噪声大。</li><li>水平轴(shap值)：显示每个特征对预测结果的影响大小，点越远离中心线（零点），表示该特征对模型输出的影响越大正的shap值表示正面影响，负的shap值表示负面影响</li><li>垂直轴(特征排列)：图中垂直排列的特征按影响力从上到小进行排序，上方的特征对模型输出的总影响更大，而下方的特征影响较小</li></ul></li><li><p>特征影响力解释：</p><ul><li>最上方特征(如：MedInc)：显示了大量的正面和负面影响，表明其在不同的观察值对模型预测的结果有很大不同的影响。</li><li>中部特征(如：AveRooms)：也显示出两种颜色的点，但点的分布更集中，影响相对较小</li><li>底部特征(如：Population)：对模型的影响最小，且大部分影响较为接近于零值，表示这些特征对模型预测的贡献较小。</li></ul></li><li><p>特征重要性(Feature Importance)：</p><ul><li>通过散点简单绘制每个样本每个特征的shap值，通过颜色看到特征值大小和预测影响之间的关系，同时取每个特征的shap值的绝对值平均值作为该特征的重要性，可获得标准条形图(shap.summary_plot(plot_type &#x3D; ‘bar’)或者shap.plots.bar())。</li></ul></li><li><p>依赖图 (Dependence Plot):</p><ul><li>解释：用于探索单个特征的取值与其对应的 SHAP 值之间的关系。图中每个点代表一个样本，横轴是特征值，纵轴是该特征的 SHAP 值。通过观察点的分布模式，可以了解特征对其贡献的影响是否是线性的、单调的或其他更复杂的形式</li><li>命令：shap.dependence_plot()</li><li>含义：依赖图用于显示一个特征的SHAP值与该特征值之间的关系，并可以展示特征之间的交互作用</li><li>参数解释：’MedInc’：这是你想要研究的特征名；shap_values：这是通过SHAP计算得到的特征重要性值；X_train：这是用于生成SHAP值的训练数据；interaction_index&#x3D;’AveOccup’：这是指定与主特征（MedInc）交互的特征，SHAP会在图中显示两者的交互效果。</li></ul></li><li><p>热图（Heatmap）</p><ul><li>命令：shap.plots.heatmap()</li><li>可视化解读：左侧y轴为重要性特征排名，特征按影响力从大到小进行排序，右侧y轴为其可视化，图像中颜色深浅表示SHAP值的大小，也就是该特征下值对模型的影响，颜色越深SHAP值绝对值越大越影响模型，顶部为模型在这些数值下的预测结果可视化。</li></ul></li><li><p>使用步骤：</p><ul><li>使用SHAP工具解释，需要先选项合适的解释器(Explainer),使用shap.Explainer时,可以自动选择合适的解释器来作为评估的实例。</li><li>选择Masker合适的背景数据。Masker通常选择经过采样的样本数据(1000条以内，默认100条为主)，主要用于让解释器了解模型所使用的大致数据分布，有利于更加准确的评估每个特征的贡献。对于存在多重共线性的特征，可以先使用shap.util.hclust()方法先聚类或者分组，再分析。</li><li>最后绘图显示特征贡献情况。</li></ul></li></ol><h3 id="SHAP开源算法库使用注意事项"><a href="#SHAP开源算法库使用注意事项" class="headerlink" title="SHAP开源算法库使用注意事项"></a><a href="https://github.com/slundberg">SHAP开源算法库</a>使用注意事项</h3><ol><li>SHAP算法验证时，代码优先使用Jupyter Notebook 或 IPython 环境中运行代码，SHAP算法的图表会在运行后，自动显示。而使用PyCharm时，则不会显示，使用时，需要配合matplotlib库一起使用，配置参数show &#x3D; False, matplotlib &#x3D; True，例如shap.force_plot。</li><li>在PyCharm+matplotlib库一起使用时，单个预测和所有预测所导致的画图差别，在使用K最近邻算法时，对于所有预测，matplotlib库使用shap.force_plot（）画图无效</li><li>数据集使用，shap.datasets.adult()首次运行时会尝试从github上下载数据集并缓存，这容易导致命令在jupyter notebook中可以运行，但是在Pycharm中会报超时连接的错误。</li><li>使用代码时，导入包必须注明版本号，以防因为包的升级进化，导致存在参数和方法失效的问题。</li><li>shap.plots.initjs()是初始化交互式力图所需的javascript库，需要在仅按照IPython笔记本环境中使用。</li></ol><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p>[1] <a href="https://zh.wikipedia.org/wiki/%E5%8F%AF%E8%A7%A3%E9%87%8B%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7">可解释人工智能</a><br>[2] <a href="https://book.douban.com/subject/37102010/">可解释机器学习：黑盒模型可解释性理解指南（第2版）</a> 【德】 Christoph Molnar著，郭涛译.电子工业出版社<br>[3] <a href="https://book.douban.com/subject/35693817/">可解释机器学习(模型、方法与实践)</a> 邵平等著.机械工业出版社<br>[4] <a href="https://book.douban.com/subject/35862965/">可解释人工智能导论</a> 杨强等著.电子工业出版社<br>[5] <a href="https://book.douban.com/subject/36059612/">AI可解释性（Python语言版）</a> 列奥尼达·詹法纳(Leonida Gianfagna) &#x2F; 安东尼奥·迪·塞科(Antonio Di Cecco)著.清华大学出版社<br>[6] <a href="https://book.douban.com/subject/36818500/">可解释AI实战（PyTorch版）</a> 阿杰伊·塔姆佩（Ajay Thampi）著.清华大学出版社<br>[7] Feng, T., Zhou, Z., Tarun, J., &amp; Nair, V. N. (2022). <a href="(https://arxiv.org/pdf/2208.06096)">Comparing Baseline Shapley and Integrated Gradients for Local Explanation: Some Additional Insights</a>. arXiv preprint arXiv:2208.06096.<br>[8] <a href="https://book.douban.com/subject/36077228/">Python可解释AI（XAI）实战</a> 丹尼斯·罗斯曼(Denis Rothman)著.清华大学出版社<br>[9] Sundararajan, M., &amp; Najmi, A. (2020, November). <a href="https://proceedings.mlr.press/v119/sundararajan20b.html">The many Shapley values for model explanation</a>. In International conference on machine learning (pp. 9269-9278). PMLR.<br>[10] <a href="https://book.douban.com/subject/37092060/">面向从业者的可解释人工智能</a> Michael Munn著，陈志鸿译.东南大学出版社.<br>[11] <a href="https://zhuanlan.zhihu.com/p/473931620">夏普利值：看诺奖获得者提出的广告效果归因分析新思路</a><br>[12] <a href="https://www.zhihu.com/question/23180647">能不能形象的介绍一下 shapley 值法</a><br>[13] <a href="https://clearcode.cc/blog/game-theory-attribution/">博弈论归因：您可能从未听说过的模型</a><br>[14] <a href="https://zhuanlan.zhihu.com/p/395674023">可解释性：完善Shapley value理论体系，建模并学习基准值</a><br>[15]<a href="https://baike.baidu.com/item/Shapley%E5%80%BC%E6%B3%95/5909624?fr=aladdin">Shapley值法</a><br>[16] <a href="https://shap.readthedocs.io/en/latest/index.html">SHAP 文档</a><br>[17] <a href="https://www.infoq.cn/article/XIYtQjiIC5sPSp04aDK9">打开 AI 的黑盒子：模型可解释性的现状、应用前景与挑战</a><br>[18]  Jialin Wu and Raymond J. Mooney.<a href="http://arxiv.org/abs/1809.02805">Faithful Multimodal Explanation for Visual Question Answering</a>arXiv preprint arXiv:1809.02805<br>[19] <a href="https://www.51cto.com/aigc/5957.html">告别AI“黑箱”！SHAP全面指南，让模型解释不再难</a><br>[20] <a href="https://arxiv.org/pdf/1705.07874">A Unified Approach to Interpreting Model Predictions</a><br>[21] <a href="https://mp.weixin.qq.com/s?__biz=Mzk0NDM4OTYyOQ==&mid=2247484880&idx=1&sn=a86f37b85fe21de3e6797838d8797b15&chksm=c3242942f453a05491b5db2131973c436d3ee789d52fbc93c596eca09d2e51c2be40ba279832&scene=21#wechat_redirect">SHAP全解析：机器学习、深度学习模型解释保姆级教程</a><br>[22]<a href="https://developer.volcengine.com/articles/7418786913525760054">SHAP进阶解析：机器学习、深度学习模型解释保姆级教程</a><br>[23] <a href="https://colab.research.google.com/#scrollTo=5fCEDCU_qrC0">Colab工具</a><br>[24] <a href="https://e0hyl.github.io/BLOG-OF-E0/LIMEandSHAP/#lime-%E5%BA%93%E7%9B%B8%E5%85%B3%E6%8E%A5%E5%8F%A3">可解释方法LIME和SHAP代码实战</a></p>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
            <tag> 算法 </tag>
            
            <tag> 可解释 </tag>
            
            <tag> SHAP算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>可解释人工智能及其研究-基础篇</title>
      <link href="/2025/09/16/%E5%8F%AF%E8%A7%A3%E9%87%8A%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%8F%8A%E5%85%B6%E7%A0%94%E7%A9%B6-%E5%9F%BA%E7%A1%80%E7%AF%87/"/>
      <url>/2025/09/16/%E5%8F%AF%E8%A7%A3%E9%87%8A%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%8F%8A%E5%85%B6%E7%A0%94%E7%A9%B6-%E5%9F%BA%E7%A1%80%E7%AF%87/</url>
      
        <content type="html"><![CDATA[<p><strong>简单来说，可解释性是指一个人能够理解一个决定的原因的程度。</strong></p><h3 id="模型可解释性"><a href="#模型可解释性" class="headerlink" title="模型可解释性"></a>模型可解释性</h3><ol><li><p>也称可解释机器学习，是指对模型内部机制的解释以及对模型结果的解释。而更广泛定义认为：模型能用通俗易懂的语言进行表达，是一种被人类理解的能力，即能够将模型的预测过程转化为具备逻辑关系的规则的能力。</p></li><li><p>作为数据科学家，我们在运用模型过程中，不仅要防止模型偏见问题的发生，还要能解释模型是如何正确的产出结果的，进而正确的使用模型，越是重要严苛的应用场景，越需要说明模型是如何运作的，并且展示避免偏见和错误的证据。</p></li></ol><h3 id="可解释性人工智能分类-Explainable-AI-XAI"><a href="#可解释性人工智能分类-Explainable-AI-XAI" class="headerlink" title="可解释性人工智能分类(Explainable AI, XAI)"></a>可解释性人工智能分类(Explainable AI, XAI)</h3><ol><li><strong>建模前可解释性，也称基于数据的可解释性</strong>：<ul><li>目标是可解释的数据探索、基于统计分析的辅助决策。</li><li>特点是数据分析和可视化。</li><li>技术栈包括数据可视化技术、可解释的特征工程、聚类、降维和统计数据分析等，在sklearn开源机器学习库中，很多模型中有importance接口(<a href="https://scikit-learn.org/stable/modules/permutation_importance.html">Permutation feature importance</a>)，通过查看模型特征的重要性，来体现模型的可解释性。</li></ul></li><li><strong>内在可解释模型，也称基于模型内在的可解释性（Intrinsic Interpretability</strong>）：<ul><li>目标是使用和开发内在可解释的模型</li><li>特点使模型本身变得可解释，模型本身就可以告知为什么这么做，模型不只给答案，还要给出得到这个答案的原因。</li></ul></li></ol><p>内在可解释模型技术栈：</p><ol><li><p>包括explanation generation、prototype netwrok, explanatory graph，使用可解释性的机器学习方法。优化模型增强可解释性（如优化后的深度神经网络）、基于图的可解释性（知识图谱等）等，其中：</p></li><li><p>explanation generation典型方法VQA  explanation：在训练模型的同时也训练一个模型对应的语言解释器。这样既得到Answer，也得到了Explanation。详细方法可以看这个论文：<a href="https://arxiv.org/abs/1809.02805">Faithful Multimodal Explanation for Visual Question Answering</a></p></li><li><p>prototype netwrok典型方法：在模型设计的时候，按照仿生学的方法，让模型构造出的数据加工方式和人类自身思考方式类似，在产生结果结合工作方式，进而理解结果产生的原因。详细方法可以看这个论文：<a href="https://arxiv.org/abs/1806.10574">This Looks Like That: Deep Learning for Interpretable Image Recognition</a></p></li><li><p>广义加性可解释神经网络模型（GAMxNN模型，Explainable Neural Network based on Generalized Additive Model），该模型提供整体和局部可解释性，并用数据可视化的方式呈现。</p></li><li><p>基于具有结构化交互作用的广义加性可解释神经网络模型（GAMINET模型，An explainable neural network based on generalized additive models with structured interactions）:张军爱教授团队提出，在GAMxNN模型基础上结合特征交互项的研究，对GAMxNN模型做进一步改良和优化。其数学形式如下：<br>$$<br>g(E(y|x)) &#x3D; \mu + \sum_{j \in S_{1}} h_{j}(x_{j}) + \sum_{(j, k) \in S_{2}} f_{jk}(x_{j}, x_{k})<br>$$<br>其中$\mu$表示截距项，$S_{1}$表示主效应集合， $S_{2}$表示交互效应集合，表示式右边第二项为单个特征拟合岭函数加和，右边第三项为交互特征拟合函数加和，这里假设每个主效应和成对交互效应的平均值为零。详情请看论文：<a href="https://www.sciencedirect.com/science/article/pii/S0031320321003484#bib0009">GAMI-Net: An explainable neural network based on generalized additive models with structured interactions</a>，模型源码请看：<a href="https://github.com/ZebinYang/gaminet">https://github.com/ZebinYang/gaminet</a> 。</p></li><li><p>可解释增强机（EBM模型， Explainable Boosting Machine）：是可解释性高的广义加法模型（GAM）中的一种，其和GAMINET模型的重要差别在于，其抓取特征的函数关系，使用的boosting方法，而非神经网络。其数学形式如下：<br>$$<br>g(E[y]) &#x3D;\beta_0 +  \sum f_{j}(x_{j})<br>$$<br>其中$g$是使广义加法模型（GAM）适应不同设置（例如回归或分类）的链接函数</p></li><li><p><strong>建模后可解释性，也称基于结果或者事后的可解释性（Post-hoc Interpretability）</strong>：</p><ul><li>目标是通过假设检验，去估计、推断和验证模型决策的流程</li><li>特点是和模型无关和黑盒分析，通过观测模型的行为，去判断为什么产生这样的结果，进而建模其可解释性。</li><li>技术栈包括：Surrogate model、additive feature、attribution methods、Saliency map、局部依赖图、特征归因方法和代理模型等。其中，Surrogate model（代理模型）典型方法：在模型局部采用一种简单可解释的模型去近似原有的黑盒模型，当精度足够逼近的时候，在用代理模型来解释原黑盒模型。典型算法是VI（变量重要性，Variable Importance）、PDP（Partial Dependence Plot，部分依赖图）、ICE（Individual Conditional Expectation Plot，个体条件期望图）、<a href="https://mp.weixin.qq.com/s/fEy1A0IjwQC46JS6PBIByA">ALE</a>（累积局部效应图，Accumulated Local Effects plot）、<a href="https://arxiv.org/abs/1602.04938">LIME(Local Interpretable Model-Agnostic Explanations)</a>算法（github码源：<a href="https://github.com/marcotcr/lime%EF%BC%89%E5%92%8C[SHAP">https://github.com/marcotcr/lime）和[SHAP</a>(Shapley Additive Explanations)](<a href="https://arxiv.org/abs/1705.07874)%E7%AE%97%E6%B3%95%E3%80%82">https://arxiv.org/abs/1705.07874)算法。</a></li></ul></li></ol><p>根据是否是局部还是全局，也可以分为：</p><ol><li>局部可解释性(Local Interpretable)：当一个样本或者一组样本的输入值发生变化时，需要解释其预测结果发生的变化原因。</li><li>全局可解释性(Global Interpretable)：在基于完整数据集的整个模型从输入到输出的理解解释，可以从中得到普遍规律和统计判断，理解每个特征对模型的影响。</li></ol><p>一般认为模型可解释性和模型准确性不可兼得：简单的模型容易解释，但拟合效果不好；复杂的模型效果好，但是却不容易解释。</p><h3 id="当前模型可解释性方法的挑战和问题"><a href="#当前模型可解释性方法的挑战和问题" class="headerlink" title="当前模型可解释性方法的挑战和问题"></a>当前模型可解释性方法的挑战和问题</h3><ol><li>算法成熟度：基于模型内在的可解释性和模型、场景绑定，通用性受限。基于结果或者事后的可解释性使用的算法本身是模型的近似，存在对采样的依赖，结果不一定稳定的问题。</li><li>算力成本：基于结果或者事后的可解释性的算法，其算法复杂度太高，算力成本现对较高。其中KernelSHAP算法就比较慢，特别是涉及多实例计算Shapley值的过程中。、</li><li>数据匮乏：基于模型内在的可解释性训练出解释器的过程，是有监督的训练过程，依赖样本和标准数据，而这类数据比较稀缺。</li></ol><h3 id="AI模型在应用场景的典型使用问题"><a href="#AI模型在应用场景的典型使用问题" class="headerlink" title="AI模型在应用场景的典型使用问题"></a>AI模型在应用场景的典型使用问题</h3><ol><li>无法挖掘因果关系或者是因果关系错判：黑盒模型内部结构复杂，使用黑盒模型做预测时，我们会根据一些模型的评价指标（如AUC）去评估模型的好坏，但即使AUC很高，我们也依然不清楚黑盒模型的判断依据是否正确。如果模型无法给出合理的因果关系，那么模型的结果也将很难使人信服。</li><li>模型安全问题：模型安全问题是指人工智能模型在训练、部署和使用过程中面临的各种安全风险，包括数据泄露、模型被滥用（如用于欺诈、虚假信息生成）、输出错误（如模型幻觉）、数据投毒、以及系统漏洞等。这些风险可能导致商业机密失窃、用户隐私受损、产生偏见歧视，甚至引发社会混乱。这些问题导致模型大范围应用在敏感领域应用举步维艰。</li><li>模型偏见问题：要是指模型在生成内容或做出决策时存在的某种偏好或倾向，这些偏好或倾向往往是由于训练数据的不平衡、不完整性或社会文化背景等因素导致的。这些问题的出现也导致模型在应用过程中，对模型结果的怀疑。</li></ol><h3 id="模型可解释性价值"><a href="#模型可解释性价值" class="headerlink" title="模型可解释性价值"></a>模型可解释性价值</h3><p>根据Gartner2019企业年度调查报告《人工智能治理三基石：可信、透明和多样性》可知，人工智能系统存在三难点：选择训练数据集带来的机器学习困局（多样性问题）、决策精度差异（结果是否可解释并可信）和恰到好处的可接受结果。可解释就是回答“why”的问题</p><p>可解释性对模型应用的价值，从模型的生产周期来看，可以分为模型开发、模型运行和模型推广阶段：</p><ol><li>在模型开发阶段，模型问题定位和使用安全。由于数据和应用场景的限制和变化，模型无法做到绝对精准，因而无法保证结果的绝对安全性，而对复杂模型结构和参数调优，犹如玄学炼丹。模型可解释性有助于在新场景和新数据样本进入时，判断模型的使用条件和依据，也有助于模型发生错误时，可以及时定位问题，采取针对性的优化措施。</li><li>在模型运行阶段：建立信任，坚定信心。模型可解释性最大价值在于建立信任，使用者通常不会简单地要求模型表现好，更在于能有理有据的给出推理依据，再给出模型结论，这样说服力更强，结论更容易接受，使人类相信模型的判断，提升模型可信度，实现业务的推广。</li><li>在模型推广阶段：探索因果关系。当前模型拟合绝大多数依据误差最小化标准，模型本身更加擅长挖掘相关关系，而非因果关系，模型可解释性可以通过解读相关关系，对其中的特征重要性评估，探索出相关关系下深层次的因果规律，避免因为数据分布不均导致的“<a href="https://zhuanlan.zhihu.com/p/466660368">辛普森悖论</a>”问题，进而定位出真正的根因原因，确保模型学习到合理知识，同时给具体的业务带来指导。避免偏见和法律合规。模型的结果需要符合业务合规标准，而仅仅依靠训练样本数据得到的结果可能是存在偏见。另一方面，欧盟GDPR条例等法律法规要求，模型做出解释，让使用者知道模型的决策是如何影响他们的。模型可解释性可以辅助用户判断模型结果是否合规，是否符合预期，进而决定是否接受模型使用和模型结论，使得模型所学能反哺人类。</li></ol><h3 id="模型可解释性工具：lnterpretML"><a href="#模型可解释性工具：lnterpretML" class="headerlink" title="模型可解释性工具：lnterpretML"></a>模型可解释性工具：<a href="https://interpretml.com.cn/docs/">lnterpretML</a></h3><ol><li>介绍：开源，模型可解释Python框架</li><li>作者：微软研究院</li><li>授权协议：MIT</li><li>来源论文：<a href="https://arxiv.org/abs/1909.09223">InterpretML: A Unified Framework for Machine Learning Interpretability</a></li><li>github仓库：<a href="https://github.com/interpretml/interpret">https://github.com/interpretml/interpret</a></li><li>功能：提供机器学习可解释性算法，供研究者使用.InterpretML 能提供两种类型的可解释性：<ul><li>白盒（glassbox），这是针对可解释性设计的机器学习模型（比如线性模型、决策规则、决策树、可解释增强机、广义加性模型）。</li><li>黑箱（blackbox）可解释技术，用于解释已有的系统（比如部分依赖图、LIME解释器、SHAP解释模型、莫里斯敏感性分析）。</li></ul></li><li>优点：<ul><li>模型可解释性：帮助数据科学家等业务相关者了解机器学习模型。</li><li>易用性：提供统一API接口和丰富可视化的可解释性技术。</li><li>灵活可定制：通过解释器和交互式视觉技术来理解模型。</li><li>综合能力：可探索模型属性，在操作数据时可以查看对模型的影响，进行假设检验分析。</li></ul></li></ol><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p>[1]  <a href="https://zh.wikipedia.org/wiki/%E5%8F%AF%E8%A7%A3%E9%87%8B%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7">可解释人工智能</a><br>[2]  <a href="https://book.douban.com/subject/37102010/">可解释机器学习：黑盒模型可解释性理解指南（第2版）</a> 【德】 Christoph Molnar著，郭涛译.电子工业出版社<br>[3]  <a href="https://book.douban.com/subject/35693817/">可解释机器学习(模型、方法与实践)</a> 邵平等著.机械工业出版社<br>[4]  <a href="https://book.douban.com/subject/35862965/">可解释人工智能导论</a> 杨强等著.电子工业出版社<br>[5]  <a href="https://book.douban.com/subject/36059612/">AI可解释性（Python语言版）</a> 列奥尼达·詹法纳(Leonida Gianfagna) &#x2F; 安东尼奥·迪·塞科(Antonio Di Cecco)著.清华大学出版社<br>[6]  <a href="https://book.douban.com/subject/36818500/">可解释AI实战（PyTorch版）</a> 阿杰伊·塔姆佩（Ajay Thampi）著.清华大学出版社<br>[7]  Feng, T., Zhou, Z., Tarun, J., &amp; Nair, V. N. (2022). <a href="(https://arxiv.org/pdf/2208.06096)">Comparing Baseline Shapley and Integrated Gradients for Local Explanation: Some Additional Insights</a>. arXiv preprint arXiv:2208.06096.<br>[8]  <a href="https://book.douban.com/subject/36077228/">Python可解释AI（XAI）实战</a> 丹尼斯·罗斯曼(Denis Rothman)著.清华大学出版社<br>[9]  Sundararajan, M., &amp; Najmi, A. (2020, November). <a href="https://proceedings.mlr.press/v119/sundararajan20b.html">The many Shapley values for model explanation</a>. In International conference on machine learning (pp. 9269-9278). PMLR.<br>[10]  <a href="https://book.douban.com/subject/37092060/">面向从业者的可解释人工智能</a> Michael Munn著，陈志鸿译.东南大学出版社<br>[11]  <a href="https://zhuanlan.zhihu.com/p/473931620">夏普利值：看诺奖获得者提出的广告效果归因分析新思路</a><br>[12]  <a href="https://www.zhihu.com/question/23180647">能不能形象的介绍一下 shapley 值法</a><br>[13]  <a href="https://clearcode.cc/blog/game-theory-attribution/">博弈论归因：您可能从未听说过的模型</a><br>[14]  <a href="https://zhuanlan.zhihu.com/p/395674023">可解释性：完善Shapley value理论体系，建模并学习基准值</a><br>[15]  <a href="https://baike.baidu.com/item/Shapley%E5%80%BC%E6%B3%95/5909624?fr=aladdin">Shapley值法</a><br>[16]  <a href="https://shap.readthedocs.io/en/latest/index.html">SHAP 文档</a><br>[17]  <a href="https://www.infoq.cn/article/XIYtQjiIC5sPSp04aDK9">打开 AI 的黑盒子：模型可解释性的现状、应用前景与挑战</a><br>[18]   Jialin Wu and Raymond J. Mooney.<a href="http://arxiv.org/abs/1809.02805">Faithful Multimodal Explanation for Visual Question Answering</a>arXiv preprint arXiv:1809.02805<br>[19]  <a href="https://mp.weixin.qq.com/s/fEy1A0IjwQC46JS6PBIByA">事后模型归因解析Part 1</a><br>[20]  A, Z. Y. ,  B, A. Z. , &amp;  B, A. S. . (2021). Gami-net: an explainable neural network based on generalized additive models with structured interactions. #i{Pattern Recognition}.<br>[21]  <a href="https://interpret.ml/docs/ebm.html">Explainable Boosting Machine</a><br>[22]  Trevor Hastie and Robert Tibshirani. Generalized additive models: some applications. Journal of the American Statistical Association, 82(398):371–386, 1987.<br>[23]  <a href="https://hub.baai.ac.cn/view/30376">机器学习模型可解释性的综述</a><br>[24]  <a href="http://www.cs.hit.edu.cn/_upload/article/files/77/15/b48ec9654aaf9df9094b92e164a6/ef88ed43-925a-43d6-9375-c81a3f395136.pdf">机器学习的可解释性综述</a><br>[25]<a href="https://cloud.tencent.com/developer/article/1937611">机器学习的挑战：黑盒模型正面临这3个问题</a></p>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
            <tag> 算法 </tag>
            
            <tag> 可解释 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>统计指数理论及其应用</title>
      <link href="/2025/09/16/%E7%BB%9F%E8%AE%A1%E6%8C%87%E6%95%B0%E7%90%86%E8%AE%BA%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8/"/>
      <url>/2025/09/16/%E7%BB%9F%E8%AE%A1%E6%8C%87%E6%95%B0%E7%90%86%E8%AE%BA%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h2 id="统计指数"><a href="#统计指数" class="headerlink" title="统计指数"></a>统计指数</h2><p>含义：综合反应不能直接相加，不能直接对比多种因素组成的经济现象在不同时间和空间条件下变动的相对数，是一种经济分析方法，反应研究对象的变化趋势，可用于分析度量。<br>常见指数：70个大中城市新建商品住宅销售价格指数、<a href="https://www.stats.gov.cn/zs/tjws/zytjzbqs/jmxxggzs/202409/t20240910_1956353.html">居民消费价格指数(CPI)</a>、<a href="https://www.stats.gov.cn/zs/tjws/zytjzbqs/gyscz/202409/t20240910_1956355.html">工业生产者出厂价格指数(PPI)</a>、沪深300证券指数、<a href="https://www.spglobal.com/spdji/zh/methodology/article/sp-china-indices-methodology-chinese/">标准普尔中国PMI指数(财新PMI)</a>、<a href="https://www.sse.net.cn/indexIntro?indexName=scfi">上海出口集装箱运价指数（SCFI）</a>、摩根士丹利社会感知指数(Social Perception Index)。</p><h3 id="价格指数"><a href="#价格指数" class="headerlink" title="价格指数"></a>价格指数</h3><ol><li>含义：反应一定时期内价格水平变动趋势和变动程度的相对数，可支持基于不同颗粒度的分析管理。</li><li>作用：结合分析对象、分析视角、计算度量等因素，综合反应历史价格趋势、预判未来盈利风险、支撑综合业务决策，通过对比同行同业指数数据，评估产品或公司竞争力。</li><li>分类：<ul><li>按比较的基期不同，指数分为定基指数和环比指数。定基指数指在数列中以某一固定时期的水平作对比基准的指数。环比指数则是以其前一时期的水平作为对比基准的指数。</li><li>按计算形式的不同，指数分为综合指数和平均数指数。综合指数是指两个总量指标对比计算出来的指数。平均数指数是依据非全面统计资料编制，实质是综合指数的变形，平均数指数可分为算术平均数指数、调和平均数指数和几何平均数指数。</li><li>按所反映现象的范围不同，指数分为个体指数和综合指数。个体指数是表明某单一要素构成现象变动的相对数，如个别产品的物量指数和个别商品的价格指数等。综合指数是表明多种要素构成现象的综合变动的相对数，如社会消费品零售总额指数和居民消费价格指数等。</li><li>按所反映现象的性质不同，指数分为数量指数和质量指数。数量指数也称物量指数，是表明总体单位数量、规模等数量变动的相对数，如产品产量指数和商品销售量指数等。质量指数是表明总体单位水平、工作质量等质量变动的相对数，如各种价格指数、单位成本指数和劳动生产率指数等。</li></ul></li></ol><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><ol><li>基期：基是指统计基数，即制定一个日期作为参考标准，是一开始作为基准的时期，使用基期概念是为了将开始时间定位，作为对比基准。</li><li>报告期：就是当前研究的阶段，是当期的意思，就是把现在研究的这一期和那一期进行对比。报告期与基期是一对指标，一般报告期都是针对基期而言的。</li><li>权数及权重：权数是用来衡量总体中各构成部分对总体影响程度的数值。综合指数或者平均数的构成变量中，每个变量对综合指数或平均数的影响程度就是这个变量的权数。从表现形式上来看，权数通常可以表现为绝对数形式权数（频数）和相对数形式权数（频率）。其中，相对数是用绝对数计算出来的百分数（％）或千分数（‰）表示，又称比重或权重，通常情况下权重之和等于1。<br>中国CPI（居民消费价格指数）以前有“中国猪肉指数（China Pig&#x2F;Pork Index）”的外号，就是因为猪肉是测算CPI的一篮子商品中权重最大的单品（约占2.5%），对CPI的拉动效果极为明显。</li><li>构建综合指标体系时，各级权数选取常用到以下几种方法：<ul><li>主观经验法，根据测算对象的分项结构利用主观经验进行赋值。</li><li>专家咨询法，即邀请专家讨论修改各级指标权重意见，直到意见趋于一致得出合理的赋权方案。</li><li>层次分析法，即将一个总目标分解为多级指标，在同层级内根据各指标重要性计算每项指标的相对优先权重。</li><li>多元分析法，利用主成分分析、因子分析等统计方法计算各权数。这几种方法既可单独使用，也可配合使用。</li></ul></li><li>代表规格品：简单来说，就是价格变动趋势和变动程度有较强的足够的代表性的产品或服务。</li></ol><h3 id="典型指数计算方法"><a href="#典型指数计算方法" class="headerlink" title="典型指数计算方法"></a>典型指数计算方法</h3><p>拉式指数公式$L_{p}$, 派式指数公式$P_{p}$</p><ol><li>同度量因素：拉式为基期销量，派式为报告器销量。</li><li>权重：拉式权重固定在基期，单纯反应价格的变动；派式权重固定在报告期，即反应价格的变化，又能反应量的变化。<br>$$<br>L_{p} &#x3D; \frac{\sum p_{1}q_{0}}{\sum p_{0}q_{0}}&#x3D; \sum \frac{p_{1}}{p_{0}} \frac{p_{0}q_{0}}{\sum p_{0}q_{0}} &#x3D; \sum \frac{p_{1}}{p_{0}}w_{0}<br>$$</li></ol><p>$$<br>P_{p} &#x3D; \frac{\sum p_{1}q_{1}}{\sum p_{0}q_{1}}&#x3D; \sum \frac{p_{1}}{p_{0}} \frac{p_{0}q_{1}}{\sum p_{0}q_{1}} &#x3D; \sum \frac{p_{1}}{p_{0}}w_{1}<br>$$<br>其中：下角标0表示基期，1表示报告期。<br>3. 注意事项：<br>     - 基期不一定是某个具体日期（时点，如1月1日），基期与报告期可能是一个时点，也可能是一个时段（时期，如某年、某月等），这取决于研究对象是时期指标还是时点指标。<br>     - 计算价格指数有“拉氏”和“派氏”两种加权公式，区别在于把“一篮子”商品和服务的消费数量固定在对比期还是报告期。固定在对比期的是拉氏公式，固定在报告期的是派氏公式.世界上绝大多数国家在编制CPI时均选择了拉氏公式，一是计算价格指数时通常无法及时取得报告期的消费数量，难以编制派氏指数。二是拉氏指数是假定消费数量不变，以观察和比较消费价格的变动情况，更具经济学意义。<br>     - 对于权数变动，按照拉氏公式理论，计算定基指数时，对比期为基期年，权数即为基期年购买固定篮子内各类商品或服务所支出金额占购买整个篮子所支出总金额的比重。这个权数是固定不变的，在《消费者价格指数手册：理论与实践》里，它被称为原权数。而在计算月度环比指数时，对比期为上月，权数即为上月购买固定篮子内各类商品或服务的支出金额占总支出的比重；计算同比指数时，对比期为上年同月，权数即为上年同月购买固定篮子内各类商品或服务的支出金额占总支出的比重。很显然，环比和同比指数的权数是随着每月价格变化自动调整的，在《消费者价格指数手册：理论与实践》里，它被称为按价格调整的权数。权数虽然在变化，但权数所代表的“一篮子”商品和服务的消费数量却是相同的、固定的，也就是“固定篮子”。</p><h3 id="指数计算公式解读"><a href="#指数计算公式解读" class="headerlink" title="指数计算公式解读"></a>指数计算公式解读</h3><p>$$<br>I_{price} &#x3D; \sum^{Top N}\frac{p_{1}}{p_{0}}w_{x}<br>$$</p><ol><li>代表标准或规格品${Top N}$ : 代表标准或规格品的筛选标准可以采用统计方法筛选、业务专家意见和定期审视刷新的策略，其中数据选择标准需要有代表性，覆盖广，数据本身要连续可得，同质可比。</li><li>基期和报告期(下角标0和1)：0：代表基期单价，为指数的初始计算时间点；1，代表报告期单价，为指数报告的时间点。对于研究对象波动大的，基期时距需要相对短一些；波动相对稳定的，则基期时距应该相对长一些。其中基期和报告期的选择标准，可以从负责编制的目的，考虑波动程度，再选择数据稳定的时期。</li><li>权重$w_{x}$:针对场景选择$x$,如果$x$取基期，则是固定权重的拉式指数；如果$x$为一段时间，则为相对权重的拉式变形指数；如果$x$取报告期，则为变动权重的派式指数。权重的选择标准，可以从内容选择要服从研究目的，形式选择要满足资料可得，时期选择要考虑业务经济意义考虑。</li><li>计算公式$I_{price}$：计算公式的选择标准，需要考虑加权指数为基本形式，计算结果有业务意义，计算简明，结果敏感。</li></ol><h3 id="指数举例：-70城市房价指数"><a href="#指数举例：-70城市房价指数" class="headerlink" title="指数举例： 70城市房价指数"></a>指数举例： <a href="https://www.stats.gov.cn/sj/zxfb/202507/t20250715_1960403.html">70城市房价指数</a></h3><ol><li>发布机构：中国国家统计局。</li><li>发布时间：每月15号左右发布上月数据。</li><li>数据覆盖范围：70个大中城市，覆盖一线、二线和三线城市。</li><li>数据分类：<ul><li>新建商品住宅：反应开发商定价趋势。</li><li>二手住宅：反应真实市场交易情况，更敏感。</li></ul></li><li>数据来源：房企网签数据和房产中介上报数据。</li><li>统计方法：加权平均法，具体统计方法参见<a href="https://jszd.stats.gov.cn/TrueCMS//gjtjjjsdczd/bbzd/content/6bffa669-d9c7-4e87-a4a3-fec88e612a1b.html">《房地产价格统计报表制度》</a></li><li>数据关键指标：<ul><li>定基指数：以2015年价格为基测（100），观测累计涨幅。</li><li>环比（MoM）：本月对比上月，反应短期波动情况。</li><li>同比（YoY）：本月对应去年同期，反应长期趋势。</li></ul></li><li>场景和判断：<ul><li>二手房价涨幅大于新房时，说明市场由真实需求驱动（而非开发商业务促销），可以视为房价企稳的重要判断，或者说是进入右侧交易。</li><li>房价连续3个月环比涨幅超过1%，有可能会触发政府限购加码；而同比下跌超过5%，政府可能出台救市政策。</li><li>《逃不开的经济周期》一书中认为，房地产是经济周期之母，需要格外研究。</li></ul></li></ol><h3 id="指数计算应用经验"><a href="#指数计算应用经验" class="headerlink" title="指数计算应用经验"></a>指数计算应用经验</h3><ol><li>指数可以做为引子，借助指数我们可以计算并获取很多从其他视角的其他信息，辅助决策。例如为了计算指数，需要获得权重和均价，借此可以建立不同产品的权重图和价格图，而价格一般的是通过金额和数量计算出来的，由此可以建立不同视角下的金额热力图、占比图或者数量图、分布图等。由于计算指数需要依赖标准或规格品，在挑选标准或规格品过程中，可以按照总量或数量获取前90%等的产品清单，进而实现通过对20%产品的指数监控实现80%左右的收益(二八法则)。</li><li>如果产品之间存在组成和传递关系，可以建立产品之间的量化关系，分析产品之间的波动规律十分合理，也可以通过指数形成波动信息的传导，并将多种指数可以放置在一个图中对比分析其中的gap,分析其中的偏差原因。</li></ol><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p>[1]<a href="https://book.douban.com/subject/6061753/">统计指数理论, 方法与应用研究</a>，徐国祥等著. 上海人民出版社<br>[2] <a href="https://book.douban.com/subject/4932567/">统计指数理论及应用</a>，徐国祥著. 中国统计出版社.<br>[3] 统计指数理论与实践， 任建智著. 中国物资出版社<br>[4] <a href="https://www.douban.com/note/866626990/?_i=5827726a4yBb1W">领导干部应知应会主要统计指标诠释</a>. 本书编写组编.中国统计出版社.<br>[5] <a href="https://book.douban.com/subject/36473131/">统计预测和决策</a>.徐国祥著.上海财经大学出版社<br>[6] <a href="https://book.douban.com/subject/2329672/">国民经济核算原理与中国实践</a>.高敏学著.中国人民大学出版社<br>[7]<a href="https://www.stats.gov.cn/zs/tjws/zytjzbqs/zzxsjgzs/202411/t20241128_1957596.html">住宅销售价格指数的编制</a> .中国国家统计局<br>[8] <a href="https://www.stats.gov.cn/zs/tjws/zytjzbqs/zzxsjgzs/202501/t20250121_1958389.html">住宅销售价格数据的基础数据来源</a>.中国国家统计局<br>[9] <a href="https://www.stats.gov.cn/zs/tjws/jbtjzswd/tjbk/202507/t20250711_1960387.html">什么是统计数据的报告期和基期</a><br>[10] <a href="https://www.stats.gov.cn/zs/tjws/tjbk/202301/t20230101_1912948.html">什么是指数</a><br>[11] <a href="https://www.stats.gov.cn/zs/tjws/tjbk/202301/t20230101_1912959.html">什么是权数</a><br>[12] <a href="https://www.stats.gov.cn/zs/tjws/tjzb/202301/t20230101_1903623.html">住宅销售价格指数是如何编制的</a><br>[13] <a href="https://www.stats.gov.cn/zs/tjws/tjzb/202301/t20230101_1903972.html">什么是采购经理指数（PMI）</a><br>[14] <a href="https://www.stats.gov.cn/zs/tjws/tjzb/202301/t20230101_1903757.html">居民消费价格指数（CPI）是如何编制的</a><br>[15] <a href="https://www.stats.gov.cn/zs/tjws/zytjzbqs/cgzlzs/202501/t20250121_1958396.html">采购经理指数编制方法</a><br>[16] <a href="https://www.stats.gov.cn/zs/tjws/zytjzbqs/jmxxggzs/202411/t20241127_1957589.html">CPI 的编制方法</a><br>[17] <a href="https://tjyj.cbpt.cnki.net/portal">统计研究</a><br>[18] <a href="https://book.douban.com/subject/11516006/">消费者价格指数手册：理论与实践</a><br>[19] <a href="https://book.douban.com/subject/35587406/">宏观经济数据分析手册</a></p>]]></content>
      
      
      <categories>
          
          <category> 数学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> 数学 </tag>
            
            <tag> 统计 </tag>
            
            <tag> 指数理论 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>FastAPI使用注意事项</title>
      <link href="/2025/09/15/FastAPI%E4%BD%BF%E7%94%A8%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/"/>
      <url>/2025/09/15/FastAPI%E4%BD%BF%E7%94%A8%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/</url>
      
        <content type="html"><![CDATA[<h2 id="FastAPI"><a href="#FastAPI" class="headerlink" title="FastAPI"></a>FastAPI</h2><p>介绍：高性能、自动交互式文档生成、支持类型注解、支持异步请求和RESTful API的Web框架，兼容基于ASGI的其他框架，例如Pydantic。<br>作用：可以用于构建前后端分离和微服务的Web应用，构建RESTful API； 接收、返回和处理JSON数据。</p><p>安装：</p><ol><li>FastAPI依赖Python 3.8及以上版本</li><li>可使用pip install “fastapi[all]” 安装FastAPI和所有可选依赖。</li><li>使用注意事项<ul><li>使用时需要注意异步ASGI服务器 uvicorn 看看是否正确安装，他是支持高性能和异步编程的Web服务器，常用于开发和在生产环境运行FastAPI应用程序。</li><li>uvicorn命令样例：uvicorn main:app –reload.在FastAPI程序编写好后，可以用这个命令启动程序。<br>其中uvicorn 表示启动FastAPI应用程序，</li><li>main表示需要启动的命令程序所在的Python文件位置，需要确保当前工作目录中存在这个文件，而且这个文件内容要正确。</li><li>app表示指定文件main中需要启动的FastAPI实例对象，要确保main文件中定义了app对象。</li><li>–reload uvicorn参数，表示uvicorn在检测源代码更改时要自动重载应用程序，有利于修改代码后立即看到结果，无需手动重启服务。</li></ul></li></ol><p>４. 启动 uvicorn命令后，可以使用ctrl + c命令退出服务器<br>５. from fastapi import FastAPI:FastAPI是FastAPI的核心类，依赖它构建FastAPI应用实例，定义和管理应用组件和路由。 </p><h2 id="交互式API文档"><a href="#交互式API文档" class="headerlink" title="交互式API文档"></a>交互式API文档</h2><ol><li>用途：基于OpenAPI规范的实时反应代码的最新更改，可以直接在文档中做API测试，对输入参数类型和格式能自动验证。</li><li>风格和命令：<ul><li>Swagger UI风格：<a href="http://127.0.0.1:端口/docs">http://127.0.0.1:端口/docs</a></li><li>ReDoc 风格：<a href="http://127.0.0.1:端口/redoc">http://127.0.0.1:端口/redoc</a></li></ul></li><li>使用注意：<ul><li>修改完成代码后，要等到热重载机制生效，重新触发加载，关闭旧服务器进展，启动新服务器进程后，再ctrl + r 刷新才能看到API文档的变化。</li><li>为防止缓存影响查看API文档，可以先清楚浏览器缓存或者使用隐私模式或者无痕模式访问。</li></ul></li></ol><h2 id="路由、请求和响应配置"><a href="#路由、请求和响应配置" class="headerlink" title="路由、请求和响应配置"></a>路由、请求和响应配置</h2><ol><li>路由基本配置：FastAPI实例+@实例装饰器（配置路由路径和路径参数）+路由处理函数（可配置默认值的查询参数）<ul><li>路由路径：在路径中添加{}，可以创建动态路径。</li><li>查询参数：通过为函数参数设置默认值，可以将其作为查询参数。</li><li>请求体：使用pydantic库定义数据模型作为请求体结构，以包含多个默认值的字段。</li><li>响应模型：路由设置response_model参数，可以定义响应数据的结构。</li></ul></li><li>路由处理函数使用：路由处理函数中返回值为字典或pydantic库的实例，字典和实例会被FastAPI自动转化为JSON格式，做为响应的结果传回客户端。</li><li>请求头Header和Cookie数据：使用fastapi库中的Header和Cookie类型注解，获取请求头Header和Cookie数据</li><li>响应头JSONResponse：使用fastapi.responses中的JSONResponse，实现自定义响应头。</li><li>重定向：使用fastapi.responses中的RedirectResponse，实现重定向，将新路由路径重定向到旧的路由路径中。</li><li>异常反馈：raise HTTPException(status_code, detail)，为定位未捕获的异常导致的服务崩溃，可以在代码中添加from fastapi import HTTPException，添加异常处理来检查问题原因，返回自定义的状态码和详细信息。</li><li>注意：<ul><li>可以使用typing库中的Union类型，用于支持多种数据类型的参数注解，或者用于查询参数的多种数据类型适配。例如Union[str, None]</li></ul></li></ol><h2 id="FastAPI-Pydantic"><a href="#FastAPI-Pydantic" class="headerlink" title="FastAPI Pydantic"></a>FastAPI Pydantic</h2><ol><li>功能：数据验证和序列化的模型库，用于定义请求体、响应体和其他数据模型，实现类型检查和自动文档生成。</li><li>定义 Pydantic 模型：创建继承自 pydantic.BaseModel 的类，定义字段和数据类型，数据类型是任何有效的Python类型，字段可以设置默认值。</li><li>使用 Pydantic 模型：可以用Pydantic 模型作为请求体，可做为查询参数的数据类型，自动验证和解析客户端传入的 JSON 数据是否符合模型的定义，并将其转换为模型类型的实例。</li><li>数据转换和序列化：Pydantic 模型可以自动将数据转换为特定类型（例如 JSON）或反向序列化。</li></ol><h2 id="依赖项"><a href="#依赖项" class="headerlink" title="依赖项"></a>依赖项</h2><ol><li>定义和功能：函数，可以使用与路由处理函数相同参数的函数。用于在路由处理函数执行前或后运行的<strong>可复用</strong>的函数和逻辑，执行通用逻辑，如身份验证、数据库连接等。</li><li>类型：<br>预处理依赖项（Before）： 在路由处理函数执行前运行，用于预处理输入数据，验证请求等。<br>后处理依赖项（After）： 在路由处理函数执行后运行，用于执行一些后处理逻辑，如日志记录等。</li><li>依赖注入过程：<br>定义依赖项函数：from fastapi import Depends，依赖项函数定义和普通Python函数基本相同。<br>路由处理函数使用依赖项：(查询参数: 数据类型 &#x3D; Depends(依赖项函数名))，依赖项函数处理结果返回给路由处理函数，做为入参使用。</li><li>注意：<br>1 可以使用多个依赖项函数，依赖项函数之间可以这种依赖和继承。<br>2 异步依赖项： 依赖项函数和路由处理函数可以设置为异步，允许在它们内部执行异步操作</li></ol><h2 id="表单数据处理"><a href="#表单数据处理" class="headerlink" title="表单数据处理"></a>表单数据处理</h2><ol><li>定义：接收和处理用户通过 HTML 表单提交的数据。</li><li>声明表单数据模型： <ul><li>使用from fastapi import  Form，用Form()定义查询参数的默认类型。</li><li>使用 Pydantic 模型声明，使用from pydantic import Field， 用Field()类型声明每个表单字段，做默认类型，可以添加相应的验证规则。</li></ul></li><li>接收表单数据：在路由处理函数中，使用Form()类型接收表当数据，并和Pydantic 模型字段一一对应，实现表单数据验证和转换。</li><li>处理文件上传：使用from fastapi import File, UploadFile，如果表单包含文件上传，使用 UploadFile 类型处理，可以将文件的相关信息包装在 UploadFile 对象。</li></ol><h2 id="简单CRUD-API样例"><a href="#简单CRUD-API样例" class="headerlink" title="简单CRUD API样例"></a>简单CRUD API样例</h2><ol><li>数据模型, 首先，定义Item数据模型：</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from pydantic import BaseModel</span><br><span class="line">class Item(BaseModel):</span><br><span class="line">    name: str</span><br><span class="line">    description: str = None</span><br><span class="line">    price: float</span><br><span class="line">    tax: float = None</span><br></pre></td></tr></table></figure><ol start="2"><li>存储数据, 在这个示例中，我们将使用一个简单的字典来存储数据：</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">items = &#123;&#125;</span><br></pre></td></tr></table></figure><ol start="3"><li>创建（Create）创建一个新的item：</li></ol> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">@app.post(&quot;/items/&quot;, response_model=Item)</span><br><span class="line">def create_item(item: Item):</span><br><span class="line">    item_id = len(item) + 1</span><br><span class="line">    items[item_id] = item</span><br><span class="line">    return items</span><br></pre></td></tr></table></figure><ol start="4"><li>读取（Read）, 读取一个item：</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">@app.get(&quot;/items/&#123;item_id&#125;&quot;, response_model=Item)</span><br><span class="line">def read_item(item_id: int):</span><br><span class="line">    return items[item_id]</span><br></pre></td></tr></table></figure><ol start="5"><li>读取所有items：</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">@app.get(&quot;/items/&quot;, response_model=List[Item])</span><br><span class="line">def read_items():</span><br><span class="line">    return list(items.values())</span><br></pre></td></tr></table></figure><ol start="6"><li>更新（Update）更新一个item：</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">@app.put(&quot;/items/&#123;item_id&#125;&quot;, response_model=Item)</span><br><span class="line">def update_item(item_id: int, item: Item):</span><br><span class="line">    items[item_id] = item</span><br><span class="line">    return item</span><br></pre></td></tr></table></figure><ol start="7"><li>删除（Delete）删除一个item：</li></ol> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">@app.delete(&quot;/items/&#123;item_id&#125;&quot;, response_model=Item)</span><br><span class="line">def delete_item(item_id: int):</span><br><span class="line">    item = items.pop(item_id)</span><br><span class="line">    return item</span><br></pre></td></tr></table></figure><h2 id="使用注意"><a href="#使用注意" class="headerlink" title="使用注意"></a>使用注意</h2><ol><li><p>当使用uvicorn命令在本地（排查防火墙问题）正常启动API应用程序后发现，路径和端口调用没有反应，或者无法同时访问其他路由，或者修改完文件和重载后，交互式文件不能立即修改反应在界面上，可能是存在8000等端口占用的问题，导致后续对8000端口的请求在排队中。</p></li><li><p>排查方法：<br>使用命令检查端口占用情况：<br>Linux&#x2F;macOS: sudo lsof -i 8000，检查LISTEN的端口状态，如果端口未被占用，则不会有输出。<br>Windows：netstat -ano | findstr :8000 ,检查LISTENING的端口状态，如果端口未被占用，则不会有输出<br>或者使用不同端口调度api服务：uvicorn main:app –reload –port 8001，然后尝试访问 <a href="http://127.0.0.1:8001/%E3%80%82">http://127.0.0.1:8001/。</a><br>启动 Uvicorn，添加日志级别信息，查看日志输出：uvicorn main:app –reload –log-level debug<br>在控制台手动测试API服务端点命令：curl http:127.0.0.1:端口&#x2F;</p></li><li><p>在代码开发过程中，要注意确保服务端关闭的情况下，同时释放占用的端口。请求能快速反馈，没有长时间、执行耗时的阻塞或者耗时操作。FasfAPI内置支持使用信号来优雅关闭服务器并释放端口（signal库）</p></li><li><p>端口关闭方法：</p><table><thead><tr><th>操作系统</th><th>命令</th><th>含义</th></tr></thead><tbody><tr><td>linux&#x2F;macOS</td><td>终端窗口+kill -9 进程标识符</td><td>-9 表示强制终止进程</td></tr><tr><td>Windows</td><td>命令提示符+taskkill &#x2F;PID 占用进程号 &#x2F;F</td><td>&#x2F;PID 表示进程标识符，&#x2F;F表示强制结束进程</td></tr></tbody></table></li><li><p>TCP协议连接状态含义：</p><table><thead><tr><th>名称</th><th>含义</th><th>说明</th></tr></thead><tbody><tr><td>LISTENING</td><td>端口正在监听连接请求</td><td>服务端已启动，服务端在等待客户端发起的连接请求</td></tr><tr><td>CLOSE_WAIT</td><td>连接一方已收到关闭请求，在等待对端关闭连接</td><td>表示客户端关闭连接，服务器还没有处理完成这些连接，需要调度close()等来关闭连接</td></tr><tr><td>TIME_WAIT</td><td>连接已关闭，在等待一段时间后所有数据包都已传输完成</td><td>TIME_WAIT通常是正常的，如果有大量的TIME_WAIT状态，就需要调整系统参数来优化</td></tr></tbody></table></li></ol><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] <a href="https://fastapi.tiangolo.com/zh/tutorial/">FastAPI教程</a><br>[2] <a href="https://zhuanlan.zhihu.com/p/624779536">轻松上手Python的Web神器：FastAPI教程</a><br>[3] <a href="https://www.w3cschool.cn/fastapi/fastapi-tutorial.html">FastAPI 用户指南</a><br>[4] <a href="https://www.runoob.com/http/http-tutorial.html">HTTP 教程</a></p>]]></content>
      
      
      <categories>
          
          <category> API </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> RESful API </tag>
            
            <tag> Web框架 </tag>
            
            <tag> API </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GPU使用经验总结</title>
      <link href="/2025/09/14/GPU%E4%BD%BF%E7%94%A8%E7%BB%8F%E9%AA%8C%E6%80%BB%E7%BB%93/"/>
      <url>/2025/09/14/GPU%E4%BD%BF%E7%94%A8%E7%BB%8F%E9%AA%8C%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<p>GPU使用经验总结，主要总结在算法设计和项目开发过程中，对GPU使用过程方面，进行经验总结，为以后使用GPU等计算工具做准备。</p><h3 id="GPU使用基本流程"><a href="#GPU使用基本流程" class="headerlink" title="GPU使用基本流程"></a>GPU使用基本流程</h3><ol><li>基本流程五步骤：分析需求-评估资源-资源获取-环境准备-任务执行</li></ol><ul><li>分析需求：确定是否需要使用GPU(判断必要性)，梳理使用事情清单和实现目标，基于任务特点、任务阶段、使用环境判断任务类型是开发、训练还是推理。</li><li>评估资源：确定使用的AI平台、环境、GPU型号、使用时长和数量</li><li>资源获取：由于GPU资源受限，需要登记使用信息，进行GPU资源评审通过后，才能进行GPU资源申请和调配</li><li>环境准备：根据申请到GPU资源，在计划使用时间内，准备开发、训练、推理的生产和测试环境，并完成环境配置</li><li>任务执行：基于准备好的环境，下载加载调用模型，执行开发、训练、推理任务。</li></ul><h3 id="GPU分析需求"><a href="#GPU分析需求" class="headerlink" title="GPU分析需求"></a>GPU分析需求</h3><ol><li>根据模型的目的、开发阶段和需求，可以先从模型任务和模型选型开始。</li></ol><ul><li>模型任务类型：开发、训练、推理，涉及试算、开发和上线等IT环节。<ul><li>开发类型：主要在试算、开发、SIT阶段，主要在线上开发环境中执行，特点就要灵活快速修改代码，环境运行时需要一直占用资源，资源需要随时可支持，以获取运行结果。可以用于工具调度和代码调整过程中。</li><li>训练类型：主要在试算、开发、上线等阶段，主要用于线上训练作业，特点是代码基本固定，代码按排序依次执行，任务结束后就释放资源。可用于算法模型的微调，提升模型效果。</li><li>推理类型：主要在开发、上线等阶段，主要用于在线服务支持。特点就是代码已稳定，需要在服务器环境中执行运行供外部使用调用，资源持续占用。可用于算法模型的在线部署和服务调用，对外稳定提供服务。</li></ul></li></ul><ol start="2"><li>LLM模型的选型策略：模型配置(参数、token等)、模型评测效果</li></ol><ul><li>模型配置：<ul><li>参数：模型的权重、偏置等，是模型训练过程中的主要学习内容，影响模型的输出结果。参数越多一般效果越好，但训练消耗的资源也越多，而且模型的部署使用也会依赖更多的硬件资源支持，选择时要考虑可供使用的硬件配置。</li><li>token：模型理解和处理文本时的基本单元，使模型和语言解耦，模型的Max token就是在一次对话中基于上下文关系记忆的最大token数据量。</li></ul></li><li>模型评测效果：<ul><li>模型根据自身特点，有特定的适用领域，对模型在通用和特定任务、公开数据集下的运行结果做多维度测评，有利于在实际应用时，正确选择合适模型以达成效果。其中典型测评榜单有<a href="https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard#/">huggingface</a>和<a href="https://cevalbenchmark.com/static/leaderboard_zh.html">C-eval</a>,对于LLM评测综述可阅读<a href="https://zhuanlan.zhihu.com/p/642689101">首篇大语言模型评测的综述</a>一文。</li></ul></li></ul><h3 id="GPU评估资源"><a href="#GPU评估资源" class="headerlink" title="GPU评估资源"></a>GPU评估资源</h3><p>针对使用的模型，需要预估GPU资源数量。</p><ul><li>算力：指计算设备（GPU、CPU、NPU等）完成计算的能力大小，一般评价指标为在单位时间内完成的运算次数。GPU单卡可发挥的算力是指在理想条件下，一块GPU图形卡所能提供的最大计算性能。常用算力单位：FLOPS(每秒浮点运算次数)、TOPS(每秒万亿运算次数$10^{12}$),1T FLOPS就是每秒计算1万亿次浮点运算，等于$10^{12}$</li></ul><ol><li>基于运行时长的数据估算策略：GPU卡数影响训练时间<br>$$<br>开启激活重计算场景下的训练时间 &#x3D; \frac{8 * token数据量 * 模型参数量}{GPU卡数 * 单卡峰值运算性能FLOPS * GPU利用率}<br>$$<br>其中token数据量 * 模型参数量是模型训练所需的总计算量，GPU利用率一般在0.3−0.55之间，模型参数量中1B(1 Billion)代表10亿个参数(10^9).FLOPS每秒浮点运算次数,这个要考虑所选的数值精度，精度不同，相同GPU的单卡峰值运算性能也不同。</li><li>基于显存大小的数据估算策略：</li></ol><ul><li>工具：HuggingFace在线大模型显存消耗资源估算工具<a href="https://huggingface.co/spaces/hf-accelerate/model-memory-usage">Model Memory Calculator</a></li><li>工具使用：入参是模型对应HuggingFace地址、模型精度、library情况，输出为最大层(Largest Layer)、推理显存(Total Size)、Adam训练显存(Training using Adam)。可以先使用工具估算出不同精度下的训练和推理所需要的显存大小，再根据GPU单卡性能参数(显存大小)，估算所需单卡数量。</li></ul><ol start="3"><li>使用注意事项：</li></ol><ul><li>该估算工具可本地部署，部署方法可看链接：<a href="https://www.datalearner.com/blog/1051693562957225/https://www.wehelpwin.com/article/4255">https://www.datalearner.com/blog/1051693562957225/https://www.wehelpwin.com/article/4255</a></li><li>推理显存实际使用量应该是预估数量的1.2倍，原因来自EleutherAI的技术分析,这个是经验公式.详情请看链接：<a href="https://blog.eleuther.ai/transformer-math/">https://blog.eleuther.ai/transformer-math/</a></li><li>显存经验手工计算公式：<a href="https://blog.csdn.net/lov1993/article/details/136717491">大模型不同参数下的模型显存计算公式</a></li></ul><h3 id="GPU资源获取"><a href="#GPU资源获取" class="headerlink" title="GPU资源获取"></a>GPU资源获取</h3><ol><li>GPU资源评审考虑项：结合资源获取的公司流程，重点考虑任务类型、任务名、任务描述、资源需求、性能要求、使用时间、责任人等内容。注意点如下：</li></ol><ul><li>任务类型：模型任务是业务需求触发还是技术能力储备</li><li>任务名：可以根据任务特点简明扼要的名称做为任务名</li><li>任务描述：结合场景、目标和价值对任务做描述说明</li><li>资源需求：说明需要的资源，包括使用AI平台、任务类型、环境、GPU型号和数量</li></ul><h3 id="GPU环境准备："><a href="#GPU环境准备：" class="headerlink" title="GPU环境准备："></a>GPU环境准备：</h3><ol><li>环境准备依赖所使用的AI平台，具体使用要求需要结合平台规范进行。环境配置一般比较繁琐，但基本都一次性的。建议对环境准备过程做记录，以供其他人配置环境时，照此处理。</li></ol><h3 id="GPU任务执行"><a href="#GPU任务执行" class="headerlink" title="GPU任务执行"></a>GPU任务执行</h3><p>典型训练任务：模型微调</p><ol><li><p>目的：在特定数据集上进一步训练模型，提高模型在解决特定问题或任务时的性能。</p></li><li><p>时机：是否需要选择模型微调，主要考虑成本效益、领域专长、数据保护等方面。成本效益上看，微调预训练模型一般比从头训练大模型更经济，适应性也更好，也能更好解决Prompt Engineering限制问题。领域专长上看，可以利用企业多年积累的数据、为企业提供有针对性的定制化的模型服务，同时由于有了现成数据，利用监督学习的机制，也有利于模型在解决特定问题上性能提升。数据保护上看，由于使用的数据训练只在企业内部使用，也有利于数据保护，避免数据泄露和模型使用之间的两难困境。</p></li><li><p>方法：LoRA(新增低秩矩阵到原权限矩阵)、Prefix Tuning(前缀调整,输入增加可训练上下文前缀)、Prompt Tuning(提示调整,输入增加可训练的嵌入向量提示)、QLoRA(Quantized Low-Rank Adaptation,量化权重到4bit+LORA)、P-Tuning(使用可训练的LSTM模型生成嵌入向量用于输入)、P-TuningV2(P-Tuning结合多个N中输入)、Adapter Tuning(适配器调整,新增小神经网络).</p></li><li><p>方法适应性：</p><table><thead><tr><th>方法名</th><th>适应场景</th></tr></thead><tbody><tr><td>Adapter&#x2F;LoRA</td><td>资源有限，特别是计算和内存;中等到大型数据集上希望实现全参数微调效果;适用于分类或者问答等任务</td></tr><tr><td>Prompt Tuning&#x2F;P-Tuning</td><td>适用于自然语言生成型任务、数据量较少场景(10^3数据级);不深入模型架构，只希望用于快速原型设计、迭代调试场景。</td></tr></tbody></table></li><li><p>典型工具：</p><table><thead><tr><th>工具名</th><th>适用平台</th><th>工具用途</th></tr></thead><tbody><tr><td><a href="https://github.com/yangjianxin1/Firefly">Firefly</a></td><td>英伟达GPU</td><td>预训练和模型微调工具</td></tr><tr><td><a href="https://gitee.com/ascend/MindSpeed-LLM">MindSpeed LLM</a></td><td>华为昇腾NPU</td><td>预训练和模型微调工具</td></tr><tr><td><a href="https://hugging-face.cn/docs/peft/quicktour">Hugging Face PEFT库(Parameter-Efficient Fine-Tuning，参数高效微调)</a></td><td>英伟达GPU&#x2F;华为昇腾NPU</td><td>高效微调方法Python库,Hugging Face核心组件</td></tr></tbody></table></li><li><p>模型接口API设置: 可采用传统API格式、Openai Completions api格式(通用的自然语言生成接口)、Openai Chat api格式(专为生成对话和聊天场景而设计)</p></li></ol><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p>[1] <a href="https://cloud.tencent.com/developer/article/2393847">模型运算量、显卡算力说明</a><br>[2] <a href="https://blog.csdn.net/qq_44815135/article/details/140663123">大模型参数量和占的显存怎么换算</a><br>[3] <a href="https://blog.csdn.net/qq_44193969/article/details/132246050">大模型训练时间估算</a><br>[4] <a href="https://zhuanlan.zhihu.com/p/671786293">通俗解读大模型微调Fine-Tuning</a><br>[5] <a href="https://zhuanlan.zhihu.com/p/673789772">大模型炼丹术：大模型微调总结及实现</a><br>[6] <a href="https://aws.amazon.com/cn/blogs/china/practical-series-on-fine-tuning-large-language-models-part-two/">炼石成丹：大语言模型微调实战系列（二）模型微调篇</a><br>[7] <a href="https://openai.xiniushu.com/docs/guides/fine-tuning">微调(Fine-tuning)|OpenAI官方帮助文档中文版</a><br>[8] <a href="https://pdf.dfcfw.com/pdf/H3_AP202501221642435170_1.pdf?1737543124000.pdf">深度解析Palantir</a><br>[9] <a href="https://cookbook.langchain.com.cn/docs/langchain-agents/#%E4%BB%A3%E7%90%86-agents-%E5%92%8C%E5%B7%A5%E5%85%B7">超能力对话代理 (Agents) 的超级 LLMs</a><br>[10]<a href="https://huggingface.co/Qwen/Qwen-7B-Chat/blob/main/examples/react_prompt.md?code=true">ReAct Prompting 技术命令千问使用工具</a><br>[11] <a href="https://www.wehelpwin.com/newslist">AI魔法学院</a><br>[12] <a href="https://zhuanlan.zhihu.com/p/660721012">通俗解读大模型主流微调方法：从Prefix Tuning、P-Tuning V1&#x2F;V2到LoRA、QLoRA</a><br>[13] <a href="https://zhuanlan.zhihu.com/p/1914674647611450675">主流大语言模型API参数详解</a><br>[14] <a href="https://blog.csdn.net/ybdesire/article/details/133828010">OpenAI接口Completion和ChatCompletion的区别与使用方法</a><br>[15] <a href="https://xiniushu.com/#test_tool">犀牛书</a><br>[16] <a href="https://zhuanlan.zhihu.com/p/666655216">OpenAI API 接口实战教程 #2 Chat类和Completion 类 自然语言生成模型</a></p>]]></content>
      
      
      <categories>
          
          <category> GPU </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GPU </tag>
            
            <tag> 经验总结 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>算法文档编写要点</title>
      <link href="/2025/09/14/%E7%AE%97%E6%B3%95%E6%96%87%E6%A1%A3%E7%BC%96%E5%86%99%E8%A6%81%E7%82%B9/"/>
      <url>/2025/09/14/%E7%AE%97%E6%B3%95%E6%96%87%E6%A1%A3%E7%BC%96%E5%86%99%E8%A6%81%E7%82%B9/</url>
      
        <content type="html"><![CDATA[<p>算法文档编写要点，主要总结在算法文档编写过程中，文档内容中必须要有的关键事项，以方便日后开发人员按照文档开发。</p><ol><li><p>算法简单介绍：</p><p>编写要点：内容简明扼要，让使用人快速了解算法的用途和关键点，可以在算法中添加背景知识、历史知识和典型应用场景，方便快速理解。</p></li><li><p>算法原理详述：</p><p>介绍从算法背景知识开始，详述算法的涉及概念、核心思想、算法公式流程、算法实现方法、过程和结果等，阐明算法的工作机理，对于算法的优势劣势、性能限制局限性、适用场景等关键因素要特别关注和解释，以确保使用者快速判断算法适用情况。</p></li><li><p>算法功能说明：</p><p>3.1 功能举例：<br>3.1.1 功能说明：对功能简明扼要介绍<br>3.1.2 入参说明：表格形式说明参数名、数据类型、取值范围、默认值、备注、是否必须、数据内容样例等信息，并在备注等部分说明参数的作用。<br>3.1.3 调用示例：<br>是该算法的示例代码或伪代码，以方便使用者快速上手。示例代码要详细清晰，能重复展现算法的使用方法和功能。对于涉及多场景多应用的使用情况，需要提供每个场景下的示例，分门别类加以说明。<br>3.1.4 结果输出：<br>结果输出要给出样例，特别是涉及多场景情况下。输出要详细说明输出的内容（字段名）、类型、格式等信息，并说明其含义。<br>3.1.5 参考文献：<br>说明算法来源的文档、论文书籍等证明材料，涉及原创和专利要注意使用要求，涉及开源软件要求要参照开源协议使用。<br>3.2 其他功能近似：</p></li><li><p>使用开发指南和案例：</p><p>4.1 案例介绍：<br>重点介绍案例的使用场景<br>4.2 安装配置：<br>详细说明算法软件包的安装配置方法，包括环境准备、配置依赖、安装设置、使用检查、代码仓配置等信息，确保算法正确安装并能正常使用。<br>4.3 环境及数据准备：<br>在算法正式使用前，准备好环境配置和数据准备，特别是数据准备，数据的清洗、转换和预处理、结果可视化等动作要详细说明，确保数据符合算法入参要求，输出结果能正常呈现。涉及任务连续编排(Pipeline)功能的，最好图像化展示从头到尾的运行流程，说明Pipeline中的组件内容和运行结果。<br>4.3.1 模型训练和推理：<br>基于算法构建模型后，需要对模型先训练，后推理。文档说明中需要包括对训练数据的描述，模型训练和推理硬件软件配置、模型训练的配置等内容，对模型训练后保存的结果，是保存模型本身还是保存模型参数，保存位置等也要加以说明，模型命名和保存名要遵从模型开发和设计规范。<br>4.4 开发及使用样例：<br>代码开发要遵守开发规范，算法的样例代码和实际使用场景，要确保使用者正确理解和使用。<br>开发过程中要及时完成单元测试和质量检查，包括本地开发环境和线上测试环境代码运行通过，算法正常使用。算法设计和开发过程中涉及的需求变更，也要及时记录到文档中，用于事后可追溯。<br>4.5 备注和说明<br>针对使用过程中容易发生的典型情况和问题，给出样例、使用说明和处理方案、调试策略等，确保使用者快速解决使用过程中发现的典型问题。<br>算法设计和开发，一般要基于算法平台环境配置和操作，也需要在文档中对算法平台的行为做说明，包括环境组件配置、部署上线、权限实施、运维执行和执行监控等</p></li><li><p>版本规范说明：</p><p>按照架构设计和规范要求，说明并记录设计文档的版本号、变更说明、修改时间、变更人信息等。其中变更说明部分要详细说明变更内容和关联影响，方便使用者快速判断版本改进情况和对自身使用的影响。</p></li><li><p>评审结论：</p><p>算法设计和开发都需要经过严格评审，需要经过评审后给出评审记录(评审时间、评审人、评审结论)。</p></li></ol><h3 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h3><p>[1] <a href="https://blog.csdn.net/Linshaodan520/article/details/134759092">项目开发与算法开发基本流程</a><br>[2] <a href="https://cs.nju.edu.cn/lixuandong/guide">软件文档编写指南</a><br>[3] <a href="https://www.infoq.cn/article/o7076wcbpbkwewjbtbyz">谷歌软件工程师是怎样写设计文档的</a><br>[4] <a href="https://www.banlikanban.com/info/wiki/softwarepm/3498.html">什么是详细设计说明书？设计时需要考虑哪些关键要点</a></p>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 经验总结 </tag>
            
            <tag> 算法 </tag>
            
            <tag> 文档管理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Git使用指南</title>
      <link href="/2025/09/13/Git%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/"/>
      <url>/2025/09/13/Git%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/</url>
      
        <content type="html"><![CDATA[<p>本人之前使用的版本控制工具是SVN，最近换成了Git,总结一下Git过程的使用经验，总结教训。</p><h3 id="版本控制工具历史"><a href="#版本控制工具历史" class="headerlink" title="版本控制工具历史"></a>版本控制工具历史</h3><ol><li>版本控制工具起源：diff和patch</li><li>最早的本地版本控制工具：RCS(Revision Control System)</li><li>集中式版本控制工具：</li></ol><ul><li>SVN(Subversion)：用于取代CVS(Concurrent Versions System)的更好用的版本控制系统。不适合跨地域的协作式开发，不适合对代码高质量追求和代码门禁，其操作依赖服务器，可以用于word这类二进制文件的版本控制，适合人数不多的项目。</li></ul><ol start="4"><li>分布式版本控制工具：</li></ol><ul><li>Git, 2005年诞生。Git不适合word这类二进制文件的版本控制，由于需要整体的读授权，其不能将读授权精细到目录级别。适合分布式开发和移动办公。Git和其他版本控制工具的主要差别在于Git对待数据的方式。其他版本控制工具记录的是差异，而Git记录的是快照，即把数据看做是对文件系统的一组快照。提交和保存项目，Git会对当时的全部文件制造快照并保存快照索引。Git在实际使用中，主要用于对代码仓代码进行管理。</li><li>TortoiseGit：Windows系统下的开源Git图形化操作工具。TortoiseGit支持多种语言, TortoiseGit下载链接:<a href="https://tortoisegit.org/download/#Language_Packs">https://tortoisegit.org/download/#Language_Packs</a></li></ul><h3 id="Git安装配置"><a href="#Git安装配置" class="headerlink" title="Git安装配置"></a>Git安装配置</h3><ol><li>Linux安装:两种安装方式(包管理器安装和源代码安装)</li></ol><ul><li>包管理器安装命令如下(以Ubuntu为例)：<br>sudo aptitude install git (必装软件包)<br>sudo aptitude install git-doc git-svn git-email gitk (依赖不同，需要单独安装)</li><li>Linux可以通过bash-completion软件包实现命令补齐功能，具体设置可以看<a href="https://blog.csdn.net/m0_60534883/article/details/146981814">Git安装及使用</a></li></ul><ol start="2"><li>Windows安装：Git官方网站下载安装和安装<a href="https://zhuanlan.zhihu.com/p/419092209">GitHub Desktop</a>(包含图形化和命令行版本的Git)</li><li>macOS安装： <a href="https://git-scm.com/downloads/mac">macOS Git安装程序</a><br>Git安装后一般还需要配置，才能和代码仓配合，用于代码的版本管理，该配置比较繁琐，配置时建议和有经验的人一起弄，配置好后一般不需要再改动，为防止遗忘，建议配置过程整理文档保存。</li></ol><h3 id="配置设置"><a href="#配置设置" class="headerlink" title="配置设置"></a>配置设置</h3><ol><li>配置分类：系统配置(–system)、用户配置(–global)和仓库配置(–local)，查看配置命令：git config</li><li>配置流程：配置个人身份(用户名和邮箱)-&gt;换行符文本配置(重点在于不同系统之间的差异)-&gt;文本编码配置(使用UTF-8编码)-&gt;服务器认证配置(一般是线上代码仓，协议认证方式和公钥)，配置详情请看<a href="https://blog.csdn.net/m0_60534883/article/details/146981814">Git安装及使用</a></li></ol><h3 id="Git概念"><a href="#Git概念" class="headerlink" title="Git概念"></a>Git概念</h3><table><thead><tr><th>区域和状态</th><th>中文名称</th><th>英文名称</th><th>用途</th></tr></thead><tbody><tr><td>工程区域</td><td>工作区</td><td>Working Directory</td><td>日常使用文件所在文件夹</td></tr><tr><td>工程区域</td><td>暂存区</td><td>stage</td><td>索引，在工程根目录.git&#x2F;index文件夹中</td></tr><tr><td>工程区域</td><td>版本库</td><td>Repository</td><td>本地仓库，工作区中隐藏的目录文件夹.git,用于存放工程所有版本数据</td></tr><tr><td>文件状态</td><td>已修改</td><td>modified</td><td>修改文件，文件未提交保存</td></tr><tr><td>文件状态</td><td>已暂存</td><td>staged</td><td>已修改文件已放在将要保存的清单中</td></tr><tr><td>文件状态</td><td>已提交</td><td>committed</td><td>文件已保存在本地数据库中</td></tr></tbody></table><h3 id="Git常用命令字典"><a href="#Git常用命令字典" class="headerlink" title="Git常用命令字典"></a>Git常用命令字典</h3><table><thead><tr><th>用途</th><th>命令</th><th>解释</th></tr></thead><tbody><tr><td>工程准备</td><td><a href="https://git-scm.com/docs/git-init/zh_HANS-CN">git init</a> 项目名或工程名</td><td>在本地目录下自动生成名为.git的目录，做为项目仓库。当前项目所在目录纳入Git管理,.git目录默认不可见</td></tr><tr><td>工程准备</td><td><a href="https://git-scm.com/docs/git-clone/zh_HANS-CN">git clone</a> url链接 &#x2F; git lfs clone url链接</td><td>将远端工程或项目克隆到本地磁盘，使用前提是要有该工程或项目的查看下载权限</td></tr><tr><td>工作区查看</td><td><a href="https://git-scm.com/docs/git-diff/zh_HANS-CN">git diff</a> 文件名 文件名</td><td>比较项目中任意两个节点&#x2F;分支&#x2F;索引的差异，在diff后添加–name-status参数，可以查看文件列表</td></tr><tr><td>工作区查看</td><td>git status</td><td>查看工作目录和暂存区状态，change to be committed(已暂存)、changes not staged for commit(未暂存)、untracked file(未被跟踪)</td></tr><tr><td>新增文件到暂存区</td><td><a href="https://git-scm.com/docs/git-add/zh_HANS-CN">git add</a>文件名</td><td>如果文件未被git跟踪，则需要先执行git add后，文件添加到暂存区后，再执行提交</td></tr><tr><td>删除在暂存区的文件</td><td><a href="https://git-scm.com/docs/git-rm/zh_HANS-CN">git rm</a> 文件名</td><td>将文件从当前分支的暂存区中删除，也可理解为从当前分支的下一步提交快照中删除，删除后文件将脱离git跟踪，不受git工程管理</td></tr><tr><td>文件移动和重命名</td><td><a href="https://git-scm.com/docs/git-mv/zh_HANS-CN">git mv</a> 文件名 新目录名&#x2F;新文件名</td><td>将文件从当前目录移动到新目录，或者将当前文件重新命名为新文件名</td></tr><tr><td>提交修改文件</td><td><a href="https://git-scm.com/docs/git-commit/zh_HANS-CN">git commit</a> 文件名 -m “提交描述信息”</td><td>暂存区文件改动提交到本地版本库中，提交的是本地动作，本地版本库记录改动，远端服务器不受影响</td></tr><tr><td>提交所有文件</td><td>git commit -am “提交描述信息”</td><td>一次提交所有暂存区改动文件到本地版本库中</td></tr><tr><td>查看日志</td><td><a href="https://git-scm.com/docs/git-log/zh_HANS-CN">git log</a></td><td>查看提交历史，可配置不同参数，按提交时间由近及远列出提交历史日志，包括提交ID、作者、提交时间、提交描述等</td></tr><tr><td>推送到远端仓库分支</td><td><a href="https://git-scm.com/docs/git-push/zh_HANS-CN">git push</a> origin 本地分支名:远端分支名</td><td>在git commit命令之后，将本地分支内容推送到远端分支上</td></tr><tr><td>撤销操作</td><td><a href="https://git-scm.com/docs/git-reset/zh_HANS-CN">git reset</a> commit_id</td><td>撤销工作区中的git add&#x2F;commit操作，将工作区内容回退到历史提交的commit_id节点，可配置参数</td></tr><tr><td>回退操作</td><td><a href="https://git-scm.com/docs/git-checkout/zh_HANS-CN">git checkout</a> . &#x2F; -文件名&#x2F; commit_id</td><td>回退本地所有修改而未提交的文件内容，取消所有本地工作区修改，使用-文件名，可回退某个单一文件的未提交改动,使用commit_id回退某个提交版本</td></tr></tbody></table><h3 id="Git分支管理"><a href="#Git分支管理" class="headerlink" title="Git分支管理"></a>Git分支管理</h3><ol><li>分支类型：<table><thead><tr><th>分支类型</th><th>特征名称</th><th>功能</th></tr></thead><tbody><tr><td>主分支</td><td>master&#x2F;main</td><td>常用，存储生产代码</td></tr><tr><td>开发分支</td><td>develop</td><td>常用，存储即将发布的代码，常用于开发人员开发使用</td></tr><tr><td>发布分支</td><td>release</td><td>常用，上线分支，准备发布上线使用</td></tr><tr><td>功能分支</td><td>feature</td><td>用于开发新功能</td></tr><tr><td>热修复分支</td><td>hotfix</td><td>用于紧急修复生产问题</td></tr></tbody></table></li><li>分支管理命令：<table><thead><tr><th>用途</th><th>命令</th></tr></thead><tbody><tr><td><a href="https://git-scm.com/docs/git-branch/zh_HANS-CN">git branch</a>  &#x2F;-r&#x2F;-a</td><td>查看本地工程的所有Git分支，-r查看远端服务器上的所有分支，-a查看远端+本地工程所有分支，”*”表示当前工作区所在分支</td></tr><tr><td>git branch 新分支名</td><td>基于当前分支节点创建新分支，不会切换到新分支，而使用git checkout -b 新分支名则可以切换到新分支</td></tr><tr><td>git branch -d&#x2F;-D 分支名</td><td>删除本地分支，-D表示强制删除情况，也可搭配参数删除远程分支</td></tr><tr><td><a href="https://git-scm.com/docs/git-checkout/zh_HANS-CN">git checkout</a> 分支名</td><td>切换检出分支，-f可以强制切换分支</td></tr><tr><td><a href="https://git-scm.com/docs/git-fetch/zh_HANS-CN">git fetch</a> origin 远端分支:本地分支</td><td>分支更新，从远端服务器获取远端分支后，对本地仓库里的本地分支进行更新</td></tr><tr><td><a href="https://git-scm.com/docs/git-merge/zh_HANS-CN">git merge</a>&#x2F;rebase 分支名</td><td>分支合并，从指定分支合并到当前分支</td></tr><tr><td><a href="https://git-scm.com/docs/git-pull/zh_HANS-CN">git pull</a> origin 远端分支:本地分支</td><td>分支合并，从远端服务器获取远端分支后，和本地分支进行自动合并</td></tr></tbody></table></li></ol><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p>[1] <a href="https://git.p2hp.com/">Git中文网</a><br>[2] <a href="https://tortoisegit.org/">TortoiseGit官网</a><br>[3] <a href="https://blog.csdn.net/m0_60534883/article/details/146981814">Git安装及使用</a><br>[4] <a href="https://www.runoob.com/git/git-tutorial.html">Git教程</a></p>]]></content>
      
      
      <categories>
          
          <category> Git </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 基础 </tag>
            
            <tag> 项目管理 </tag>
            
            <tag> 版本控制 </tag>
            
            <tag> Git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python技巧-magic命令</title>
      <link href="/2025/09/13/Python%E6%8A%80%E5%B7%A7-magic%E5%91%BD%E4%BB%A4/"/>
      <url>/2025/09/13/Python%E6%8A%80%E5%B7%A7-magic%E5%91%BD%E4%BB%A4/</url>
      
        <content type="html"><![CDATA[<p>在IPython和Jupyter Notebook 高效magic命令。<br>magic命令：Jupyter Notebook中的特殊命令，使用%符号和要运行的命令一起使用。</p><h3 id="time"><a href="#time" class="headerlink" title="%%time"></a>%%time</h3><ol><li>功能：用于执行并反馈将代码运行一次后所花费的时间。输出CPU time(代码实际消耗的CPU运行时间)和Wall time(墙上挂钟时间, 代码从开始到结束所花费的，实际感受的运行时间)。</li><li>使用条件：在IPython和Jupyter Notebook中，必须放在测试单元代码的第一行，在%%time换行后，输入想要计时的一段或多段代码。</li><li>用途：</li></ol><ul><li>性能分析：提供代码运行时间信息。</li><li>代码执行时间评估：通过查看输出CPU时间和墙上时间，进而更全面的了解代码的运行时间。CPU 时间用于分析代码本身消耗的处理器资源，而墙上时间则反映了用户实际感受到的耗时。</li></ul><h3 id="time-1"><a href="#time-1" class="headerlink" title="%time"></a>%time</h3><ol><li>功能：将会给出当前行的代码运行一次后所花费的时间。输出Wall time(墙上时间, 代码从开始到结束所花费的实际时间)和代码运行结果。</li><li>使用条件：在IPython和Jupyter Notebook中，放在测试单元代码的第一行，在%time同行空格后，输入想要计时的一段或多段代码。</li><li>用途：检查代码运行时间并输出代码运行结果。</li><li>注意：也可以使用time库(import time),利用time.localtime(time.time())，返回当前时间的时间戳方法来计算时间间隔。</li></ol><h3 id="eit-r-R-n-N"><a href="#eit-r-R-n-N" class="headerlink" title="eit -r R -n N"></a>eit -r R -n N</h3><ol><li>功能：将执行代码语句运行R次，每次N遍，再对N * R 遍的运行结果取平均从而得到运行一遍代码的时间。</li><li>使用条件：在IPython和Jupyter Notebook中，必须放在测试单元代码的第一行，在%%timeit换行后，输入想要计时的一段或多段代码。如果放置在同行，则同行代码运行但不计时，从第二行才开始计时。</li><li>用途：检查代码运行时间并输出代码运行结果。</li><li>注意:%timeit的运行比%time执行时间快,在于%timeit内有额外的机制，用于防止系统调用(System calls)影响程序执行的时间结果。</li></ol><h3 id="prun"><a href="#prun" class="headerlink" title="%prun:"></a>%prun:</h3><ol><li>功能：宏观性能分析工具，用于计算函数或程序执行每个函数需要多长时间。</li><li>使用条件：在IPython和Jupyter Notebook中，放在测试单元代码的第一行，在%prun同行空格后，输入想要计时的一段或多段代码。结果返回列表，列表中是每个内部函数被调用次数、每次被调用时间、函数所有运行的累积时间。</li></ol><h3 id="lprun"><a href="#lprun" class="headerlink" title="%lprun:"></a>%lprun:</h3><ol><li>功能：微观性能分析工具，逐行计算程序性能，从而判断哪一行执行时间最长，进而优化那部分程序。</li><li>使用条件：需要安装第三方库: pip install line_profiler,在IPython中加载套件后，执行%lprun来计算函数的逐条性能。</li></ol><h3 id="mprun"><a href="#mprun" class="headerlink" title="%mprun:"></a>%mprun:</h3><ol><li>功能：使用单个语句执行的内存计算工具和代码一起执行。</li><li>使用条件：限制在独立模块上，不能应用在notebook上运行。</li></ol><h3 id="memit"><a href="#memit" class="headerlink" title="%memit:"></a>%memit:</h3><ol><li>功能：计时单个语句占用的内存空间。</li><li>使用条件：需要安装第三方库: pip install memory_profiler,在IPython中加载套件后，执行%memit来计算函数的逐条性能,从peak memory中。</li></ol><h3 id="who"><a href="#who" class="headerlink" title="%who"></a>%who</h3><ol><li>功能：在jupiter Notebook中显示所有可用变量。</li><li>使用条件：单独一行。</li></ol><h3 id="history-or-hist"><a href="#history-or-hist" class="headerlink" title="%history or %hist"></a>%history or %hist</h3><ol><li>功能：在jupiter Notebook中查看活动日志，并跟踪已经做过的内容。</li><li>使用条件：单独一行。</li></ol><h3 id="pinfo"><a href="#pinfo" class="headerlink" title="%pinfo"></a>%pinfo</h3><ol><li>功能：在jupiter Notebook中查看对象、包的详细信息（包括类型、长度、文件地址等）。</li><li>使用条件：单独一行。pinfo 包名或对象名。</li></ol><h3 id="writefile"><a href="#writefile" class="headerlink" title="%%writefile"></a>%%writefile</h3><ol><li>功能：在jupiter Notebook中用于在当前目录中，保存复用函数到Python文件中。</li><li>使用条件：单独一行,文件开头。%%writefile 文件名.py。</li></ol><h3 id="pycat"><a href="#pycat" class="headerlink" title="%pycat"></a>%pycat</h3><ol><li>功能：用于在当前目录中，读取Python文件中的复用函数到jupiter Notebook中，在新弹出窗口中显示文件中的所有代码。</li><li>使用条件：%pycat 文件名.py</li></ol><h3 id="quickref"><a href="#quickref" class="headerlink" title="%quickref"></a>%quickref</h3><ol><li>功能：在jupiter Notebook中，详细解释所有jupiter Notebook中存在的所有magic命令。</li><li>使用条件：单独一行 %quickref。</li></ol><h3 id="Jupiter-Notebook和Pycharm使用差异"><a href="#Jupiter-Notebook和Pycharm使用差异" class="headerlink" title="Jupiter Notebook和Pycharm使用差异:"></a>Jupiter Notebook和Pycharm使用差异:</h3><ol><li>命令中的数据集是否需要从网络中下载，还是直接运行本地数据集：</li></ol><ul><li>Jupiter Notebook：在本地浏览器环境中使用，网络(例如Github)数据集和本地数据集都可以正常使用。</li><li>Pycharm：除非设置好代理和打开防火墙，否则只能使用本地数据集，使用网络数据集会因为连接超时报错。</li></ul><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献:"></a>参考文献:</h3><p>[1] <a href="https://towardsdatascience.com/9-magic-command-to-enhance-your-jupyter-notebook-experience-101fb5f3a84/">9个可以提高Jupyter Notebook开发效率的魔术命令</a></p>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> magic </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>专利基础知识整理</title>
      <link href="/2025/09/12/%E4%B8%93%E5%88%A9%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/"/>
      <url>/2025/09/12/%E4%B8%93%E5%88%A9%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h3 id="知识产权"><a href="#知识产权" class="headerlink" title="知识产权"></a>知识产权</h3><ol><li>概念：人对其智力劳动成果依法享有的占有、处分和收益的权利。</li><li>专利权概念：申请人就一项发明创造，即发明、实用新型或外观设计向国务院专利行政部门<strong>提出专利申请</strong>，经<strong>依法审查合格</strong>后，向专利申请人授予的<strong>在规定的时间内</strong>对该项发明创造享有的专有权利。</li></ol><h3 id="知识产权类型"><a href="#知识产权类型" class="headerlink" title="知识产权类型"></a>知识产权类型</h3><table><thead><tr><th>知识产权类型</th><th>保护期限</th></tr></thead><tbody><tr><td>专利权-发明</td><td>从申请日开始，保护期限20年</td></tr><tr><td>专利权-新型实用&#x2F;外观设计</td><td>从申请日开始，保护期限10年</td></tr><tr><td>著作权(版权)</td><td>自然人软件著作权保护器为自然人终生及其死后50年，法人或组织软件著作权保护期为首次发表后的50年</td></tr><tr><td>商标权</td><td>每次10年，可以不断续注</td></tr><tr><td>商业秘密</td><td>永久</td></tr></tbody></table><h3 id="专利权特点"><a href="#专利权特点" class="headerlink" title="专利权特点"></a>专利权特点</h3><table><thead><tr><th>特点</th><th>解释</th></tr></thead><tbody><tr><td>时间性</td><td>专利保护有时间限制，例如发明的保护期限是20年</td></tr><tr><td>地域性</td><td>专利只在申请的国家或地区有效，可以借助PCT专利合作公约申请多国保护</td></tr><tr><td>排他性</td><td>赋予专利人一定时间内的垄断权利</td></tr></tbody></table><h3 id="授予专利的条件-《专利法》第二十二条"><a href="#授予专利的条件-《专利法》第二十二条" class="headerlink" title="授予专利的条件(《专利法》第二十二条)"></a>授予专利的条件(《专利法》第二十二条)</h3><table><thead><tr><th>条件</th><th>解释</th></tr></thead><tbody><tr><td>新颖性</td><td>是指该发明或者实用新型不属于现有技术；也没有任何单位或者个人就<strong>同样的</strong>发明或者实用新型在申请日以前向国务院专利行政部门提出过申请，并记载在申请日以后公布的专利申请文件或者公告的专利文件中</td></tr><tr><td>实用性</td><td>可以<strong>复现</strong>，是指该发明或者实用新型能够制造或者使用，并且能够产生<strong>积极</strong>效果</td></tr><tr><td>创造性</td><td>是指与现有技术相比，该发明具有<strong>突出的实质性特点和显著</strong>的进步，该实用新型具有实质性特点和进步</td></tr></tbody></table><h3 id="好想法提炼条件"><a href="#好想法提炼条件" class="headerlink" title="好想法提炼条件"></a>好想法提炼条件</h3><p>掌握现有技术，发现现有技术缺陷并能转换为能解决的技术问题，找到解决问题的技术方案。</p><h3 id="挖掘专利技巧"><a href="#挖掘专利技巧" class="headerlink" title="挖掘专利技巧"></a>挖掘专利技巧</h3><ol><li>切记完美主义，申请专利的技术方案不需要现在就实现，或者已经实现产品落地成形，只需要能看到有后续的市场价值即可。要克服低估自身技术成果的错误思想。</li><li>针对现有技术，找到和现有技术特征的差别、改进现有技术方案的问题或者提升现有技术方案性能。</li><li>针对现实需求，找到解决问题全部的解决方案，并以方案的每个步骤的具体可操作性为方向。<br>对特定场景进行挖掘，从中换位思考。</li><li>看技术方案：可以是实现新功能的架构和方法、解决技术问题的新方法或者改造已有方法中的某个步骤。</li></ol><h3 id="专利价值判断依据"><a href="#专利价值判断依据" class="headerlink" title="专利价值判断依据"></a>专利价值判断依据</h3><ol><li>创造性：看专利是否是原创性、重大改进还现有技术的极小改进。</li><li>市场应用前景：看专利对应的市场空间是否明确或规模比较大。</li><li>侵权证据可获得性：看专利是否<strong>很容易</strong>判断对方是否侵权，侵权证据获取成本是否比较高。</li><li>专利可规避程度：看专利是否可以采用其他技术方案达成相同的目的，或者付出较小的代码或性能也能实现相同的目标。</li><li>标准相关性：看专利是否已纳入正式国家、国际、行业等技术标准，纳入技术标准的专利一般是基本专利，否则为商用特性专利。基本专利一般受标准组织政策约束。</li></ol><h3 id="侵权判断标准-等同原则四要素："><a href="#侵权判断标准-等同原则四要素：" class="headerlink" title="侵权判断标准-等同原则四要素："></a>侵权判断标准-等同原则四要素：</h3><p>以基本相同的手段，实现基本相同的功能，产生基本相同的效果，而且本领域普通技术人员在被诉侵权行为发生时无需经过创造性劳动就能够联想到的特征。<br>其中：<br>     - 基本相同的手段，是指被诉侵权技术方案中的技术特征与权利要求对应技术特征在技术内容上并无实质性差异。<br>     - 基本相同的功能，是指被诉侵权技术方案中的技术特征与权利要求对应技术特征在各自技术方案中所起的作用基本相同。被诉侵权技术方案中的技术特征与权利要求对应技术特征相比还有其他作用的，不予考虑。<br>     - 基本相同的效果，是指被诉侵权技术方案中的技术特征与权利要求对应技术特征在各自技术方案中所达到的技术效果基本相当。被诉侵权技术方案中的技术特征与权利要求对应技术特征相比还有其他技术效果的，不予考虑。<br>     - 无需经过创造性劳动就能够想到，是指对于本领域普通技术人员而言，被诉侵权技术方案中的技术特征与权利要求对应技术特征相互替换是容易想到的。<br>等同原则构建的初衷是为了避免被诉侵权人通过改变一些细微的、非实质性的技术特征来逃避专利侵权的法律责任，从而给予专利权人以有效的救济。等同原则的实质是扩展权利要求文字表达的保护范围，使专利的保护范围不仅涵盖与专利相同的东西，也涵盖与专利相似的东西。    </p><h3 id="编写专利经验"><a href="#编写专利经验" class="headerlink" title="编写专利经验"></a>编写专利经验</h3><ol><li>纯算法类不适合写专利，但是算法类和工具能够外化呈现的可以写专利。能解决需求、提升性能、方案创新和缺陷改进的适合写专利。</li><li>评审创造性时，技术问题、解决方案和实施效果是作为评价创造性的整理来考虑的。而新方案和新问题是保证创造性的关键。</li></ol><h3 id="常用专利检索网站："><a href="#常用专利检索网站：" class="headerlink" title="常用专利检索网站："></a>常用专利检索网站：</h3><table><thead><tr><th>专利网站</th><th>是否付费</th></tr></thead><tbody><tr><td><a href="http://www.innojoy.com/search/index.shtml">innojoy系统</a></td><td>付费</td></tr><tr><td><a href="https://www.baiten.cn/">佰腾网</a></td><td>付费</td></tr><tr><td><a href="http://www.uspto.gov/patft/index.html">美国专利商标局</a></td><td>免费</td></tr><tr><td><a href="https://www.cnipa.gov.cn/">中国国家知识产权局</a></td><td>免费</td></tr><tr><td><a href="https://www.drugfuture.com/cnpat/cn_patent.asp">中国专利全文打包下载</a></td><td>免费</td></tr><tr><td><a href="https://www.drugfuture.com/uspat/us_patent.asp">美国专利全文打包下载</a></td><td>免费</td></tr><tr><td><a href="https://www.patent9.com/">专利在线Patent.com</a></td><td>免费</td></tr><tr><td><a href="https://ipc.incopat.com/index">IPC分类查询</a></td><td>免费</td></tr><tr><td><a href="https://patents.google.com/">谷歌Patents</a></td><td>免费</td></tr><tr><td><a href="https://www.incopat.com/">incoPat</a></td><td>免费</td></tr></tbody></table><p>专利检索有技巧，需要单独学习并掌握。</p><h3 id="参考文献："><a href="#参考文献：" class="headerlink" title="参考文献："></a>参考文献：</h3><p>[1]  <a href="https://book.douban.com/subject/36746756/">专利审查指南</a><br>[2]  <a href="https://book.douban.com/subject/6082864/">中国专利法详解</a><br>[3]  <a href="https://book.douban.com/subject/26796545/">专利分析</a><br>[4]  <a href="https://www.cnipa.gov.cn/art/2020/11/23/art_97_155167.html">专利法</a><br>[5]  <a href="https://book.douban.com/subject/30682427/">以案说法——专利复审、无效典型案例汇编</a><br>[6]  <a href="https://ggfw-dlsks.cnipa.gov.cn/">专利代理师考试</a><br>[7]  <a href="https://blog.csdn.net/aiyanzielf/article/details/124519315?ops_request_misc=%257B%2522request%255Fid%2522%253A%25222f5aea95e35e65d31d08a1a7411972af%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=2f5aea95e35e65d31d08a1a7411972af&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-124519315-null-null.142%5Ev102%5Epc_search_result_base8&utm_term=%E4%B8%93%E5%88%A9&spm=1018.2226.3001.4187">从零开始写专利</a><br>[8]  <a href="https://www.bjcourt.gov.cn/article/newsDetail.htm?NId=150002896&channel=100014003">专利侵权判定指南(2017)</a>,北京市高级人民法院著<br>[9]<a href="https://www.cnipa.gov.cn/art/2024/12/31/art_66_196988.html">《人工智能相关发明专利申请指引（试行）》</a></p>]]></content>
      
      
      <categories>
          
          <category> 专利 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 基础 </tag>
            
            <tag> 知识产权 </tag>
            
            <tag> 专利 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>项目管理十大要点</title>
      <link href="/2025/09/11/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E5%8D%81%E5%A4%A7%E8%A6%81%E7%82%B9/"/>
      <url>/2025/09/11/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E5%8D%81%E5%A4%A7%E8%A6%81%E7%82%B9/</url>
      
        <content type="html"><![CDATA[<p>懂得项目管理，你其实当“军长”都够用了，华为的项目经理就是CEO,我就是华为最大的项目经理。–老板</p><p>项目管理的要点有哪些？即：一个使命、两个概念、三重约束、四类方法、五个过程组、六字方针、七计成败、八个绩效域、九方关系、十大知识领域。</p><h3 id="一个使命"><a href="#一个使命" class="headerlink" title="一个使命"></a>一个使命</h3><ul><li>一个使命：Make Ideas A Reality</li><li>“Make Ideas A Reality”指出了项目最本质的使命就是：把一个个想法最终变为现实。项目管理首先把产生的idea变成可行的方案，然后再把可行的方案变成现实。这不仅明确了项目的核心使命，更是对项目管理过程中每一个环节的精准概括。</li></ul><h3 id="二个概念"><a href="#二个概念" class="headerlink" title="二个概念"></a>二个概念</h3><ul><li>二个概念：项目和项目管理</li><li>项目管理中涉及到两个核心概念：项目和项目管理。<ul><li>项目：为创造独特的产品、服务或成果而进行的临时性的工作。项目的成功往往取决于有效的规划、执行和监控。</li><li>项目管理：将知识、技能、工具与技术应用于项目活动，以满足项目的要求。项目管理不仅要求项目经理具备扎实的管理知识和技能，还需要他们拥有出色的领导能力、沟通能力和团队合作精神。通过项目管理，可以确保项目的资源得到合理分配，风险得到有效控制，团队的工作高效协同，最终实现项目的预期目标。</li></ul></li></ul><h3 id="三重约束"><a href="#三重约束" class="headerlink" title="三重约束"></a>三重约束</h3><ul><li>三重约束：范围、时间、成本<ul><li>任何一个项目都会受到范围、时间、成本的约束，项目管理就是要做好这三者之间的平衡。</li><li>项目的三重约束可以互动，如范围不变的前提下，要缩短时间，就需要增加成本，或者范围不变，要减少成本，就需要延长时间。在平衡范围、时间和成本的过程中，项目经理需要考虑如何在有限的时间内，有限的预算下，完成规定范围内的任务并达成项目目标，还要使得客户满意。</li></ul></li></ul><h3 id="四类方法"><a href="#四类方法" class="headerlink" title="四类方法"></a>四类方法</h3><ul><li>四类方法：预测型方法、迭代型方法、增量型方法、敏捷型方法</li><li>如果把项目的技术和需求两个要素分别作为横轴和纵轴，就会构成四个象限，从左到右代表技术从确定到不确定，从下往上代表需求的确定到不确定，则每个象限代表了不同类别的项目，对于不同类别的项目需要使用对应的项目管理方法，方能正确解锁项目。<ul><li>第一象限项目：技术确定，需求不确定。这类项目往往已经具备成熟的技术基础，但面临的需求却较为模糊或易变。在这种情况下，使用增量型方法是非常合适的。通过分阶段交付成果，逐步明确和细化需求，同时保持技术的稳定性，可以确保项目在满足不断变化的需求的同时，也能保证技术的有效实施。</li><li>第二象限项目：技术不太确定，需求也不太确定。这是极具挑战性的项目类型，既需要面对技术上的未知，又要应对需求的不确定性。对于这类项目，我们需要采用敏捷的项目管理方法，强调快速迭代和适应性调整。通过频繁的反馈和协作，及时发现问题并进行调整，确保项目能够在不断变化的环境中保持灵活性和创新性。</li><li>第三象限项目：技术确定，需求确定。这类项目通常处于较为稳定的状态，技术基础坚实，需求也清晰明确。针对这样的项目，使用预测型方法将是一个高效的选择。预测型方法强调计划的重要性和执行的精确性，通过详细的项目计划和时间线，确保项目按照既定的路径稳步推进。</li><li>第四象限项目：技术不确定，但需求确定。面对这种情况，使用迭代型方法是非常明智的选择。迭代型方法强调在不确定的技术环境下，通过多次的迭代和反馈，逐步逼近和满足确定的需求。</li></ul></li></ul><h3 id="五个过程组"><a href="#五个过程组" class="headerlink" title="五个过程组"></a>五个过程组</h3><ul><li>五个过程组：启动、规划、执行、监控、收尾</li><li>项目管理一共五个过程组：启动、规划、执行、监控、收尾。这五个过程组相互衔接，共同确保项目的顺利进行和成功完成。<ul><li>启动：定义一个新项目或现有项目的一个新阶段，授权开始该项目或阶段的一组过程。</li><li>规划：明确项目范围，完善目标，为实现目标制定行动方案的一组过程。</li><li>执行：完成项目管理计划中确定的工作，以满足项目需求的一组过程。</li><li>监控：跟踪、审查和调整项目进展与绩效的一组过程，该过程识别任何计划需要变更的领域，并启动相应变更。</li><li>收尾：正式完成或结束项目、阶段或合同时所执行的过程。</li></ul></li></ul><h3 id="六字方针"><a href="#六字方针" class="headerlink" title="六字方针"></a>六字方针</h3><ul><li>六字方针：目标、价值、客户、团队、计划、控制</li><li>项目管理一共有6字方针，分别是：以目标为导向、以价值为牵引、以客户为中心、以团队为核心、以计划为龙头、以控制为手段。<ul><li>以目标为导向：任何项目都需要设定清晰的目标，目标应该是Smart化的产品、服务或成果；</li><li>以价值为牵引：项目还需要实现项目目标所对应的价值；</li><li>以客户为中心：要时刻关注客户以及客户的关注点；</li><li>以团队为核心：要紧密团结项目团队成员（包括客户以及伙伴等），形成一个核心团队；</li><li>以计划为龙头：没有计划就是打乱仗，有了计划才能协调好人财物，高效搞定项目；</li><li>以控制为手段：监控项目目标、价值、计划执行等，一旦有所偏离，要及时采取纠偏措施。</li></ul></li></ul><h3 id="七计成败"><a href="#七计成败" class="headerlink" title="七计成败"></a>七计成败</h3><ul><li>七计成败：主、将、天地、法令、兵众、士卒、赏罚</li><li>交付项目的过程中，要以孙子兵法的“七计”来判断项目成败的概率，一旦发现薄弱环节需要及时补救。<ul><li>主孰有道：指项目的价值&#x2F;目标是否科学合理，是否获得各方干系人的认同？</li><li>将孰有能：指项目经理是否具备足够的资质和能力，能否胜任？</li><li>天地孰得：指是否主孰有道能获得项目关键干系人如投资方和使用方的支持？</li><li>法令孰行：指项目组是否有清晰的项目管理规章制度？</li><li>兵众孰强：指项目团队成员是否胜任，尤其各核心团队成员？</li><li>士卒孰练：指项目团队成员是否经过同类场景的训战，是否具备足够的经验？</li><li>赏罚孰明：指项目组是否有清晰的奖惩制度，能否严格按制度执行？</li></ul></li></ul><h3 id="八个绩效域"><a href="#八个绩效域" class="headerlink" title="八个绩效域"></a>八个绩效域</h3><ul><li>项目管理一共有八个绩效域：干系人、团队、开发方法与生命周期、规划、项目工作、交付、测量、不确定性。<ul><li>干系人：与干系人相关的活动和功能；</li><li>团队：与负责生成项目可交付物以实现商业成果相关的人员活动和功能；</li><li>开发方法与生命周期: 与项目的开发方法、节奏和生命周期阶段相关的活动和功能；</li><li>规划：为交付项目可交付物和项目成果所需的与初始、持续进行和演变的组织和协调相关的活动和功能；</li><li>项目工作：与建立项目过程、管理实物资源和营造学习环境相关的活动和功能；</li><li>交付：与交付项目要实现的范围和质量相关的活动和功能；</li><li>测量：与评估项目绩效和采取适当行动维持可接受绩效相关的活动和功能；</li><li>不确定性: 与风险和不确定性相关的活动和功能。</li></ul></li></ul><h3 id="九方关系"><a href="#九方关系" class="headerlink" title="九方关系"></a>九方关系</h3><ul><li>九方关系：三方 X 三层 &#x3D; 九方关系<ul><li>三方：投资方、建设方和使用方</li><li>三层：指导层、管理层和执行层</li></ul></li><li>项目管理的九方关系是一个复杂而精细的体系，它涵盖了项目涉及的各个层面和利益相关方。这一体系的核心在于三方与三层的交织，共同构建了一个包含九个关键干系方的九宫格。当三方与三层相结合时，就构成了九方关系。这九个关键干系方在项目中各自扮演着重要的角色，他们的支持和配合对于项目的成功至关重要。因此，作为项目经理，需要对这九个关键干系方进行有效管理。这包括了解他们的需求和期望，建立有效的沟通机制，协调他们之间的利益关系，以获得他们的支持和合作。</li></ul><h3 id="十大知识领域"><a href="#十大知识领域" class="headerlink" title="十大知识领域"></a>十大知识领域</h3><ul><li>项目管理涉及十大知识领域：干系人管理、范围管理、进度管理、成本管理、质量管理、资源管理、采购管理、沟通管理、风险管理、整合管理，这也对应了“项目管理十问”。<ul><li>第一问是：为谁做？也就是“干系人管理”，因而要知晓为什么要做此项目；</li><li>第二问是：做什么？也就是“范围管理”，是基于干系人的需求，以决定要做什么；</li><li>第三问是：花多长时间做？也就是“进度管理”，要考虑计划花多长时间，过程中是否有偏差，如何矫正偏差；</li><li>第四问是：用多少成本做？也就是“成本管理”，要考虑计划花多少钱，是否有超支等；</li><li>第五问是：按什么标准做？也就是“质量管理”，要考虑质量过程是否可控；</li><li>第六问是：内部谁来做？也就是“人力资源管理”，要考虑如何构建团队、角色和职责的分配，以及激励和领导团队等内容；</li><li>第七问是：外部谁来做？也就是“采购管理”，包括采购规划、供应商选择、合同管理以及采购收尾；</li><li>第八问是：人员如何协作？也就是“沟通管理”，为了确保及时、准确和适当地收集、整理、发布、存储和使用项目信息；</li><li>第九问是：有哪些风险导致无法达成目标？也就是“风险管理”，包括风险识别、风险评估、风险应对计划和风险监控；</li><li>第十问是：如何实现整体最优？也就是“整合管理”，包括项目起始、项目计划制定、项目执行以及项目结束。</li></ul></li></ul><h3 id="参考文献："><a href="#参考文献：" class="headerlink" title="参考文献："></a>参考文献：</h3><p>[1] <a href="https://news.qq.com/rain/a/20240904A06FMA00?uid%5B0%5D=&uid%5B1%5D=&suid=&media_id=">华为项目管理十大要点，太有用了，必须收藏！</a><br>[2] <a href="https://zhuanlan.zhihu.com/p/662502101">大厂项目管理’43210’法：人人都需要的项目管理课</a></p>]]></content>
      
      
      <categories>
          
          <category> 项目管理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 项目管理 </tag>
            
            <tag> 管理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorch基础教程及注意事项-基础篇</title>
      <link href="/2025/08/25/PyTorch%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B%E5%8F%8A%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9-%E5%9F%BA%E7%A1%80%E7%AF%87/"/>
      <url>/2025/08/25/PyTorch%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B%E5%8F%8A%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9-%E5%9F%BA%E7%A1%80%E7%AF%87/</url>
      
        <content type="html"><![CDATA[<h2 id="PyTorch安装和环境准备"><a href="#PyTorch安装和环境准备" class="headerlink" title="PyTorch安装和环境准备"></a>PyTorch安装和环境准备</h2><p>PyTorch下载地址：<a href="https://pytorch.org/">https://PyTorch.org/</a></p><ol><li>PyTorch可以同时安装GPU（CUDA）和CPU版本，使用时需要注意，不同版本PyTorch不能安装在同一个Python解释器下，否则会报错。可以尝试一个安装在本地Python解释器下，另一个使用Anaconda Prompt安装在Anaconda环境中。</li><li>如果发现安装的cuda版本在PyTorch中不存在预构建二进制文件，可以手动先安装低版本，例如电脑安装的是12.2版本cuda，PyTorch可以先安装11.8版本，最后使用PyTorch命令检查按照按照的PyTorch版本和cuda版本。</li></ol><h2 id="Anaconda专门环境配置"><a href="#Anaconda专门环境配置" class="headerlink" title="Anaconda专门环境配置"></a><a href="https://anaconda.org.cn/">Anaconda</a>专门环境配置</h2><p>介绍：数据科学和机器学习软件套装<br>环境管理功能：使用cnnda包管理器，在管理软件包的同时，可以创建管理不同的Python环境<br><a href="https://docs.conda.org.cn/projects/conda/en/stable/user-guide/tasks/manage-environments.html">常用环境管理命令</a>：</p><table><thead><tr><th>方法</th><th>conda命令</th></tr></thead><tbody><tr><td>创建新环境</td><td>conda create –name 环境名称</td></tr><tr><td>创建指定版本环境</td><td>conda create –name 环境名称 Python &#x3D; 版本号</td></tr><tr><td>激活环境</td><td>conda activate 环境名称</td></tr><tr><td>退出当前环境</td><td>deactivate</td></tr><tr><td>查看所有已创建环境</td><td>conda env list</td></tr><tr><td>复制环境</td><td>conda create –name 复制后环境新名 –clone 环境名</td></tr><tr><td>删除环境</td><td>conda env remove –name 环境名</td></tr><tr><td>查看帮助</td><td>conda –help</td></tr></tbody></table><p><a href="https://docs.conda.org.cn/projects/conda/en/stable/user-guide/tasks/manage-pkgs.html">常用包管理命令</a>：</p><table><thead><tr><th>方法</th><th>conda命令</th></tr></thead><tbody><tr><td>安装包</td><td>conda install 包名</td></tr><tr><td>安装指定版本包</td><td>conda install 包名 &#x3D; 版本号</td></tr><tr><td>更新包</td><td>conda update 包名</td></tr><tr><td>卸载包</td><td>conda remove 包名</td></tr><tr><td>查看已安装包</td><td>conda list</td></tr><tr><td>搜索包</td><td>conda search 包名</td></tr><tr><td>清理conda缓存，删除不需要使用的包</td><td>conda clean –all</td></tr><tr><td>查看conda版本</td><td>conda –version</td></tr></tbody></table><h2 id="PyTorch"><a href="#PyTorch" class="headerlink" title="PyTorch"></a>PyTorch</h2><p>介绍：动态计算图、可自动微分、张量计算、多语言多设备支持的开源Python深度学习框架，基于torch库，底层由C++实现<br>结构（从上到下）：  </p><ol><li>PyTorch生态系统（专业库）：  <ul><li><a href="https://docs.pytorch.org/vision/stable/index.html">torchvision</a>:用于计算机视觉的数据集和模型  </li><li><a href="https://docs.pytorch.org/text/stable/index.html">torchtext</a>:用于自然语言处理的数据集和模型  </li><li><a href="https://docs.pytorch.org/audio/stable/index.html">torchaudio</a>:用于音频处理的数据集和模型</li></ul></li><li>PyTorch核心：  <ul><li><a href="https://docs.pytorch.org/docs/stable/PyTorch-api.html">PyTorch API</a>(顶层):开发者直接调用接口<br> torch: 张量核心计算<br> torch.nn:构建神经网络<br> torch.autograd: 自动微分，反向传播  </li><li><a href="https://docs.pytorch.org/cppdocs/">C++核心</a>（中层）：高性能计算，沟通Python代码和底层硬件<br> ATen: 基础张量和数学运算核心库<br> JIT: 即时编译优化模型，编译器和解释器的接口<br> Autograd引擎：自动微分计算引擎，增强ATen库  </li><li>基础层（底层）：直接操作硬件，实现高速优化<br> TN&#x2F;THNN: C&#x2F;C++实现的基础张量和神经网络操作库，非常底层<br> THC&#x2F;THCUNN: 对应模块的CUDA实现</li></ul></li><li>PyTorch运算流程：python代码-&gt;Python API接口-&gt;C++核心计算-&gt;底层CUDA&#x2F;C库加速计算-&gt;返回结果。</li></ol><h2 id="张量（Tensor）"><a href="#张量（Tensor）" class="headerlink" title="张量（Tensor）"></a>张量（Tensor）</h2><p>定义：数据核心表示形式，类似于NumPy多维数组，数据可存储在CPU&#x2F;GPU等计算设备<br>组成：  </p><ul><li>维度(Dimensionality)：定义张量的多维数组结构  </li><li>形状(shape)：定义张量每个维度的大小  </li><li>数据类型(Dtype)：定义张量上每个元素存储所需的内存大小和解释方式，包括整理、浮点型和布尔型。<br>张量属性&#x2F;方法工具如下：</li></ul><table><thead><tr><th>方法属性</th><th>说明</th></tr></thead><tbody><tr><td>.shape&#x2F;.size()</td><td>获取张量形状</td></tr><tr><td>.dtype</td><td>获取张量数据类型</td></tr><tr><td>.device</td><td>查看张量所在计算设备(CPU&#x2F;GPU)</td></tr><tr><td>.dim()</td><td>获取张量的维度数</td></tr><tr><td>.requires_grad</td><td>判断张量是否使用梯度计算</td></tr><tr><td>.numel()</td><td>获取张量元素总数</td></tr><tr><td>.is_cuda</td><td>判断张量是否在GPU上</td></tr><tr><td>.T</td><td>获取张量转置（二维及以下张量）</td></tr><tr><td>.item()</td><td>获取单元素张量值</td></tr><tr><td>.is_contiguous()</td><td>检查张量是否连续存储</td></tr><tr><td>.view(shape)&#x2F;.reshape(shape)</td><td>在不改变数据的情况下，改变张量形状</td></tr><tr><td>.unsqueeze(dim)</td><td>在指定维度添加一个维度</td></tr><tr><td>.squeeze(dim)</td><td>去掉指定维度为1的维度</td></tr><tr><td>.numpy()</td><td>将张量转换为Numpy数组,仅限CPU张量， 数组和张量共享内存，修改数据互相影响</td></tr><tr><td>.clone()</td><td>数据克隆，深复制，可存放在新内存地址中</td></tr><tr><td>.flatten()</td><td>张量展平，构成一维向量</td></tr><tr><td>Tensor创建</td><td></td></tr><tr><td>torch.tensor(data)</td><td>从Python列表和numpy数组中创建张量</td></tr><tr><td>torch.as_tensor(data)</td><td>数据转换为张量（共享内存）</td></tr><tr><td>torch.zeros(size)</td><td>创建全为零的张量</td></tr><tr><td>torch.ones(size)</td><td>创建全为1的张量</td></tr><tr><td>torch.empty(size)</td><td>创建未初始化的张量</td></tr><tr><td>torch.eye(size)</td><td>创建单位矩阵</td></tr><tr><td>torch.full(size, fill_value)</td><td>创建填充指定值的张量</td></tr><tr><td>torch.manual_seed(seed)</td><td>设置随机数种子</td></tr><tr><td>torch.initial_seed()</td><td>返回当前随机种子</td></tr><tr><td>torch.rand(size)</td><td>创建服从均匀分布的随机张量，值为[0, 1]</td></tr><tr><td>torch.randn(size)</td><td>创建服从标准正态分布的随机张量</td></tr><tr><td>torch.randint(low, high, size)</td><td>创建整数随机张量</td></tr><tr><td>torch.randperm(n)</td><td>创建0到n-1的随机配列</td></tr><tr><td>torch.arange(start, end, step)</td><td>创建一维序列张量，类似Python的range函数</td></tr><tr><td>torch.linspace(start, end, steps)</td><td>创建指定范围内等间隔序列张量</td></tr><tr><td>torch.logspace(start, end, steps)</td><td>创建对数间隔序列张量</td></tr><tr><td>torch.form_numpy(ndarray)</td><td>Numpy数组转换为张量，数组和张量共享内存，修改数据互相影响</td></tr><tr><td>Tensor操作</td><td></td></tr><tr><td>torch.stack()</td><td>沿着新维度堆叠张量</td></tr><tr><td>torch.cat((x, y), dim)</td><td>指定维度连接多个张量</td></tr><tr><td>torch.matmul(x, y)&#x2F;torch.mm(input, mat2)</td><td>矩阵乘法</td></tr><tr><td>torch.bmm(input, mat2)</td><td>批量矩阵乘法</td></tr><tr><td>torch.eig(input)</td><td>计算矩阵特征值和特征向量</td></tr><tr><td>torch.svd(input)</td><td>计算矩阵的奇异值分解</td></tr><tr><td>torch.inverse(input)</td><td>计算矩阵的逆</td></tr><tr><td>torch.det(input)</td><td>计算矩阵的行列式</td></tr><tr><td>torch.trance(input)</td><td>计算矩阵的迹</td></tr><tr><td>torch.dot(x, y)</td><td>向量点积（仅适用于一维张量）</td></tr><tr><td>torch.abs(x)</td><td>求绝对值</td></tr><tr><td>torch.sqrt(x)</td><td>求平方根</td></tr><tr><td>torch.pow(x)</td><td>求幂运算</td></tr><tr><td>torch.exp(x)</td><td>求指数函数</td></tr><tr><td>torch.log(x)</td><td>求自然对数</td></tr><tr><td>torch.sum(x)</td><td>求和</td></tr><tr><td>torch.mean(x)</td><td>求均值</td></tr><tr><td>torch.max(x)</td><td>求最大值</td></tr><tr><td>torch.min(x)</td><td>求最小值</td></tr><tr><td>torch.clamp(input, min, max)</td><td>张量限制在指定范围内</td></tr><tr><td>torch.round(input)</td><td>近似，四舍五入</td></tr><tr><td>torch.floor(input)</td><td>向下取整</td></tr><tr><td>torch.ceil(input)</td><td>向上取整</td></tr><tr><td>torch.argmax(x, dim)</td><td>返回指定维度下的最大值对应索引</td></tr><tr><td>torch.softmax(x, dim)</td><td>计算指定维度下的softmax</td></tr><tr><td>torch.meshgrid()</td><td>生成网络，可用于生成坐标</td></tr></tbody></table><p>注意：  </p><ol><li>共享内存的使用，典型如张量和Numpy数组之间的转化存在共享内存，张量形状的改变也存在共享内存，共享内存存在数据互相影响。  </li><li>张量和Numpy有转换，是因为二者有相似的内存结构，所以有内置方法直接转换。如果PyTorch中Tensor和pandas里的DataFrame进行转换，需要通过Numpy作为中间步骤实现。</li></ol><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] <a href="https://study.163.com/course/introduction/1208894818.htm">深度学习与PyTorch入门实战</a><br>[2] Zhang, A., Lipton, Z. C., Li, M., &amp; Smola, A. J. (2023). <a href="https://zh.d2l.ai/index.html">Dive into Deep Learning</a>. Cambridge University Press. URL: <a href="https://d2l.ai/">https://D2L.ai</a><br>[3] <a href="https://github.com/dragen1860/Deep-Learning-with-PyTorch-book">PyTorch深度学习</a><br>[4] <a href="https://www.runoob.com/PyTorch/PyTorch-tutorial.html">菜鸟教程</a><br>[5] <a href="https://datawhalechina.github.io/thorough-PyTorch/index.html#">深入浅出PyTorch</a></p>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
            <tag> 算法 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> PyTorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorch基础教程及注意事项-数据和模型篇</title>
      <link href="/2025/08/25/PyTorch%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B%E5%8F%8A%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9-%E6%95%B0%E6%8D%AE%E5%92%8C%E6%A8%A1%E5%9E%8B%E7%AF%87/"/>
      <url>/2025/08/25/PyTorch%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B%E5%8F%8A%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9-%E6%95%B0%E6%8D%AE%E5%92%8C%E6%A8%A1%E5%9E%8B%E7%AF%87/</url>
      
        <content type="html"><![CDATA[<h2 id="数据ETL-提取、转换、加载"><a href="#数据ETL-提取、转换、加载" class="headerlink" title="数据ETL(提取、转换、加载)"></a>数据ETL(提取、转换、加载)</h2><p>数据集：  </p><ol><li>内置数据集：<br>  定义： PyTorch生态系统（专业库）中内置的常用数据集<br><a href="https://docs.pytorch.org/vision/stable/index.html">torchvision</a>:用于计算机视觉常用数据集<br>torchvision.datasets 内部常用数据集  </li><li>典型数据集：</li></ol><table><thead><tr><th>数据集</th><th>名称</th><th>下载加载命令</th><th>数据量</th><th>用途</th></tr></thead><tbody><tr><td>MNIST</td><td>手写数字图像数据集</td><td>torchvision.datasets.MNIST(root, train, download, transform)</td><td>7万张手写数字0-9的灰度图像，其中，6万张用于训练，1万张用于测试。每张图像的大小为28×28像素</td><td>图像分类</td></tr><tr><td>CIFAR-10</td><td>彩色图像数据集</td><td>torchvision.datasets.CIFAR10(root, train, download, transform)</td><td>10个类别、每个类别有6000张图像，总共有5万张训练图像和1万张测试图像，6万张32×32像素彩色图像</td><td>图像分类</td></tr><tr><td>COCO</td><td>通用物体检测、分割、关键点检测数据集</td><td>torchvision.datasets.CocoCaptions(root, anaFile, transform)</td><td>33 万张图像、150 万目标实例、80 个目标类、91 个物品类以及 25 万关键点人物</td><td>图像分割</td></tr><tr><td>ImageNet</td><td>经典图像数据集</td><td>torchvision.datasets.ImageNet(root, split, transform, loader)</td><td>120万张训练图像，5万张验证图像和10万张测试图像</td><td>图像分类和物体检测</td></tr><tr><td>STL-10</td><td>彩色图像数据集</td><td>torchvision.datasets.STL10(root, split, download, transform)</td><td>10个类组成，总共约6000+张96*96像素图像</td><td>图像识别</td></tr><tr><td>Cityscapes</td><td>城市街道场景图像</td><td>torchvision.datasets.Cityscapes(root, split, mode, transform)</td><td>50 个不同城市街景中记录的视频序列，其包含 20000 个弱注释帧和 5000 帧的高质量像素级</td><td>城市街景语义理解</td></tr></tbody></table><ol start="3"><li>自定义数据集：</li></ol><p>工具：torch.utils.data.Dataset抽象类,从自己的数据源创建自定义数据集。<br>  用法：需要继承该抽象类，并实现如下方法：<strong>len</strong>(self)(返回数据集中的样本数量)，<strong>getitem</strong>(self, idx)(通过索引返回样本)。</p><ol start="4"><li>外置数据集：一般是外部数据库，可以使用<a href="https://www.psycopg.org/docs/">psycopg2</a>等模块。</li></ol><table><thead><tr><th>数据库</th><th>模块工具</th><th>数据库驱动包</th></tr></thead><tbody><tr><td>GaussDB(DWS)</td><td><a href="https://support.huaweicloud.com/mgtg-dws/dws_01_0120.html">psycopg2</a>&#x2F;<a href="https://support.huaweicloud.com/mgtg-dws/dws_01_0171.html">PyGreSQL</a>&#x2F;psycopg2-binary</td><td>可使用开源驱动JDBC&#x2F;ODBC</td></tr><tr><td>GaussDB</td><td>psycopg2</td><td><a href="https://support.huaweicloud.com/distributed-devg-v8-gaussdb/gaussdb-12-0155.html">Psycopg</a></td></tr><tr><td>Opengauss</td><td>psycopg2</td><td><a href="https://docs.opengauss.org/zh/docs/6.0.0/docs/DeveloperGuide/%E5%8A%A0%E8%BD%BD%E9%A9%B1%E5%8A%A8_Psycopg.html">Psycopg</a></td></tr><tr><td>PostgreSQL</td><td>psycopg2&#x2F;psycopg3</td><td>Python模块工具安装后，不需要再单独在pg库侧安装驱动包</td></tr></tbody></table><ol start="5"><li>使用注意：</li></ol><ul><li>规格不同按需适配|使用时需要注意模块、模块接口、Python和数据库版本限制。  </li><li>使用时需要注意防火墙等限制，防火墙即可以阻止下载，也可以阻止连接，一般会导致连接超时报错。  </li><li>账号密码和数据库配置等信息一般是单独放置，加密保存，可以使用Python模块Crypto、cryptodome或者<a href="https://www.cnblogs.com/zzkkk1h/p/18117606">pycryptodomex</a>库中的加解密方法，获取使用信息。  </li><li>除了使用连接模块psycopg2的psycopg2.connect()连接数据库外，还可以使用<a href="https://blog.csdn.net/xc_zhou/article/details/80893289">DBUtils.PooledDB</a>包（管理数据库连接池）连接数据库，DBUtils.PooledDB包使用的时候，需要和psycopg2或者importlib一起配合使用。</li></ul><h2 id="数据加载、处理和转换"><a href="#数据加载、处理和转换" class="headerlink" title="数据加载、处理和转换"></a>数据加载、处理和转换</h2><ol><li>数据加载器：<a href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader">torch.utils.data.DataLoader</a>，从数据集中按批次加载数据，支持多线程加载加速和数据打乱。</li></ol><ul><li>关键参数：torch.utils.data.DataLoader(dataset，batch_size, shuffle，num_workers，drop_last) <ul><li>batch_size: int类型的数据， 每次加载样本的数量，如默认设置为1，那就是一行一行的喂数据给模型，效率比较慢。  </li><li>shuffle: bool数据类型， 是否需要对数据进行洗牌（通常用于训练时将数据打乱使用），如果数据有规律特征（顺序或倒序），则不应该设置为True。  </li><li>num_workers：int类型的数据，默认为0，表示使用主进程导入数据，非负数表示使用多少子进程导入数据。  </li><li>drop_last:bool数据类型, 默认为False，和batch_size配合使用，可用于数据集中不能被batch_size整除中，确认是否丢弃最后一批数据。</li></ul></li></ul><ol start="2"><li>多数据源加载：<a href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader">torch.utils.data.ConcatDataset</a>，自定义加载多数据源，可以将多数据源合并为一个数据集。</li></ol><h2 id="数据转换"><a href="#数据转换" class="headerlink" title="数据转换"></a>数据转换</h2><ol><li>目的：将原始数据转换为适合模型训练的数据格式  </li><li>组成：</li></ol><ul><li>数据预处理：数据归一化，调整数据格式、大小和数据范围，使其适合模型输入。  </li><li>数据增强：在训练时对数据做变换，例如随机剪裁&#x2F;翻转等，提高模型泛化能力，避免过拟合。</li></ul><ol start="3"><li>一般工具：torchvision视觉库，torchvision.transfroms工具，以下是典型数据转换和增强操作：<br> 基础数据变换操作</li></ol><table><thead><tr><th>函数</th><th>用途</th></tr></thead><tbody><tr><td>torchvision.transfroms.Compose()</td><td>多变换操作组合，按照顺序依次执行</td></tr><tr><td>torchvision.transfroms.Resize()</td><td>调整图像大小，保证输入到网络的图像大小一致</td></tr><tr><td>torchvision.transfroms.ToTensor()</td><td>图像转化为Tensor张量，像素数值归一化为[0,1]范围</td></tr><tr><td>torchvision.transfroms.Normalize()</td><td>图像数据标准化，使数据符合特定均值和标准差</td></tr><tr><td>torchvision.transfroms.CenterCrop()</td><td>从图像中心剪裁指定大小区域</td></tr></tbody></table><p>数据增强操作</p><table><thead><tr><th>函数</th><th>用途</th></tr></thead><tbody><tr><td>torchvision.transfroms.RandomHorizontalFlip()</td><td>随机水平翻转图像</td></tr><tr><td>torchvision.transfroms.RandomRotation()</td><td>随机旋转图像一定角度</td></tr><tr><td>torchvision.transfroms.ColorJitter()</td><td>调整图像亮度、对比度、饱和度和色调</td></tr><tr><td>torchvision.transfroms.RandomCrop()</td><td>随机裁剪指定大小的区域</td></tr><tr><td>torchvision.transfroms.RandomResizeCrop()</td><td>随机裁剪图像并调整到指定大小</td></tr></tbody></table><h2 id="模型保存，加载和部署"><a href="#模型保存，加载和部署" class="headerlink" title="模型保存，加载和部署"></a>模型保存，加载和部署</h2><ol><li>功能：训练中断时恢复训练；在不同的训练阶段比较模型性能；方便模型部署和成员之间的模型共享；可用于迁移学习。  </li><li>类型：</li></ol><ul><li>保存整个模型：torch.save(model, path), 保存模型架构和所有参数。<br>优势：完整保留模型结构。<br>劣势：文件体积大，对模型类的定义有依赖。  </li><li>保存模型参数：torch.save(model.dict(), path), 只保留模型的状态字典信息。<br>优势：文件小，可加载到不同模型架构中，兼容性好。<br>缺点：过程繁琐，使用前需要每次先创建相同架构的模型。</li></ul><ol start="3"><li>注意事项：</li></ol><ul><li>保存命名：模型和参数的保存要按照架构要求和命名规范进行，要有意义。  </li><li>设置定期保存命令，最好是每隔几轮训练迭代就保存一次检查点，防止训练出现问题。  </li><li>在保存完成后，需要测试加载能力，确保保存的模型能正常加载使用。  </li><li>训练和保存过程中，由于比较耗时，可以在此期间将模型架构、训练参数等信息做文档保存，以备查阅。  </li><li>模型文件等材料放入Git&#x2F;svn&#x2F;Dbox&#x2F;代码仓的版本管理系统中，做版本管理。  </li><li>如果无法加载保存旧的版本模型，可以查阅文档，确定当时使用的PyTorch版本后再加载，或者转换模型的格式。</li></ul><h3 id="模型加载"><a href="#模型加载" class="headerlink" title="模型加载"></a>模型加载</h3><p>跨设备模型加载：  </p><ol><li>CPU或GPU加载：先保存模型参数到指定路径中，设定模型使用设备（torch.device(“cpu)）,再将模型参数加载到模型中（torch.load(参数路径，map_location &#x3D; ‘cpu)）,最后将模型转移到指定的模型使用设备上。  </li><li>多GPU模型加载：</li></ol><ul><li>目的：调度GPU，实现计算加速， GPU 并行计算（DataParallel 或 torch.distributed）  </li><li>GPU方法和函数清单：</li></ul><table><thead><tr><th>方法函数</th><th>说明</th></tr></thead><tbody><tr><td>torch.cuda.is_available</td><td>判断GPU是否可用</td></tr><tr><td>torch.device()</td><td>创建设备对象，可用于张量设置在GPU上</td></tr><tr><td>torch.to(device)</td><td>将张量移动到指定设备上</td></tr><tr><td>torch.device(‘cuda’ if torch.cuda.is_available() else ‘cpu’)</td><td>优先使用GPU计算，没有GPU情况下用CPU计算</td></tr><tr><td>注意事项：</td><td></td></tr></tbody></table><ol><li>在设定本次计算使用的工具时，使用torch.device(‘cpu’),cpu需要小写。  </li><li>在使用GPU运算时，要求模型和数据都要在GPU或者CPU同一个设备上。  </li><li>模型和输入数据使用的设备确定时，可以在模型之前设定，也可以在使用过程中设置，张量和模型必须在同一个设备上可以使用torch.to（）工具来转移。  </li><li>GPU中专用GPU内存和共享GPU内存的差别:专用GPU内存我们通常称为“显存”，就是显卡上独立专门的物理内存。而共享GPU内存是指从系统内存中单独划出，供GPU使用的内存，是显存的补充。可以在CUDA中显式管理共享内存。</li></ol><h3 id="分布式模型训练框架和工具："><a href="#分布式模型训练框架和工具：" class="headerlink" title="分布式模型训练框架和工具："></a>分布式模型训练框架和工具：</h3><ol><li>PyTorch原生分布式能力：<a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html">torch.DistributedDataParallel</a>、<a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.DataParallel.html">torch.DataParallel</a>、<a href="https://docs.pytorch.ac.cn/docs/stable/distributed.html">torch.distributed</a>，torch.DistributedDataParallel效率更高。</li></ol><ul><li>数据并行模式支持：PyTorch支持数据并行模式，不支持流水线、Tensor、混合和自动并行模式，其1.9.0以上版本支持ZeRO，可以用于torch.DistributedDataParallel的communicationhook调用。torch.DistributedDataParallel支持通讯优化。  </li><li>计算加速支持：可以使用torch.amp实现低精度训练（1.6以上版本，FP16精度）  </li><li>内存优化支持：可以使用torch.utils.checkpointing进行重计算</li></ul><ol start="2"><li><a href="https://docs.nvidia.com/nemo-framework/user-guide/24.07/nemotoolkit/nlp/megatron.html">NeMo- Megatron</a>:英伟达开发的分布式训练模型开源框架，支持数据并行和模型并行。  </li><li><a href="https://blog.csdn.net/zwqjoy/article/details/130732601">DeepSpeed</a>:微软开发的分布式训练模型开源框架，可以和NeMo- Megatron兼容，是目前主要使用的分布式训练工具。<br> 大模型分布式训练并行技术：<a href="https://zhuanlan.zhihu.com/p/598714869">https://zhuanlan.zhihu.com/p/598714869</a></li></ol><h3 id="模型转换"><a href="#模型转换" class="headerlink" title="模型转换"></a>模型转换</h3><ol><li>版本兼容性：在<a href="https://docs.pytorch.org/docs/stable/generated/torch.save.html">torch.save()</a>中使用_use_new_zipfile_serialization来确保好的兼容性,可以确保仍然能使用1.6版本之前的旧格式。  </li><li>格式转换：可以使用torch.jit.scipt()将模型转换为TorchScript格式，再使用torch.jit.save()和torch.jit.load()加载模型。  可以解决旧版本模型加载失败的问题。  </li><li>导出格式：</li></ol><table><thead><tr><th>格式</th><th>使用命令</th><th>特点</th><th>适用场景</th></tr></thead><tbody><tr><td><a href="https://docs.pytorch.ac.cn/docs/stable/jit.html">TorchScript</a></td><td>torch.jit.trace() torch.jit.script()</td><td>Pytorch原生格式，保持动态图特性</td><td>Pytorch生态内部</td></tr><tr><td><a href="https://docs.pytorch.ac.cn/docs/stable/onnx.html">ONNX</a></td><td>torch.onnx.export()</td><td>开发标准，跨框架兼容</td><td>多框架协同环境</td></tr><tr><td><a href="https://developer.nvidia.com/zh-cn/blog/accelerating-inference-up-to-6x-faster-in-pytorch-with-torch-tensorrt/">Torch-TensorRT</a></td><td><a href="https://docs.pytorch.ac.cn/TensorRT/">import torch_tensorrt</a></td><td>nvidia优化格式</td><td>GPU推理加速</td></tr></tbody></table><ol start="4"><li>注意事项：</li></ol><ul><li>TorchScript导出前要使用model.eval()调用模型，以转换模型模式状态为评估。</li></ul><h3 id="模型部署"><a href="#模型部署" class="headerlink" title="模型部署"></a>模型部署</h3><ol><li>目的：使用AI平台(<a href="https://support.huaweicloud.com/modelarts/index.html">ModelArts</a>)，通过API调用的方式，将AI能力整合到Web等系统中，供调用使用。  </li><li>一般部署流程：训练模型-》模型优化-》格式转换-》部署环境选择-》服务封装-》性能监控  </li><li>部署方式：</li></ol><ul><li>本地部署：ONNX部署，使用onnxruntime模块(ONNX Runtime 是由微软维护的一个跨平台机器学习推理加速器)，使用onnxruntime.InferenceSession()加载模型，创建推理会话，再使用onnxruntime.InferenceSession().run()执行推理  </li><li>云端部署（优先）：使用<a href="https://fastapi.tiangolo.com/zh/tutorial/#_1">fastapi</a>模块构建REST API，通过API接口调用。  <a href="https://www.runoob.com/fastapi/fastapi-install.html">fastapi</a>工具使用。</li></ul><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] <a href="https://study.163.com/course/introduction/1208894818.htm">深度学习与PyTorch入门实战</a><br>[2] Zhang, A., Lipton, Z. C., Li, M., &amp; Smola, A. J. (2023). <a href="https://zh.d2l.ai/index.html">Dive into Deep Learning</a>. Cambridge University Press. URL: <a href="https://d2l.ai/">https://D2L.ai</a><br>[3] <a href="https://github.com/dragen1860/Deep-Learning-with-PyTorch-book">PyTorch深度学习</a><br>[4] <a href="https://www.runoob.com/PyTorch/PyTorch-tutorial.html">菜鸟教程</a><br>[5] <a href="https://datawhalechina.github.io/thorough-PyTorch/index.html#">深入浅出PyTorch</a></p>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据 </tag>
            
            <tag> AI </tag>
            
            <tag> 算法 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> PyTorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorch基础教程及注意事项-神经网络篇</title>
      <link href="/2025/08/25/PyTorch%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B%E5%8F%8A%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AF%87/"/>
      <url>/2025/08/25/PyTorch%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B%E5%8F%8A%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AF%87/</url>
      
        <content type="html"><![CDATA[<h2 id="神经网络模型"><a href="#神经网络模型" class="headerlink" title="神经网络模型"></a>神经网络模型</h2><p>定义：模仿人脑的计算模型，由连接节点（神经元）组成，节点按照层次排列。</p><ul><li>神经元（Neuron）:<ul><li>定义：神经网络基本单元，由输入（Input）、’权重（weights）、偏置(bias)、求和函数(summation function)、阈值(activation potential)、激活函数(activation function)、输出（output）构成。</li><li>用途：接收输入数据(起始点，特征向量)，将输入数据加权求和与偏置相加，通过阈值和激活函数处理后，产生输出数据（终点，预测结果）。</li></ul></li><li>网络层（Layer）:<ul><li>定义：由多个神经元组成，神经元之间的连接密度和类型构造网络配置。</li><li>组成（最简）：输入层(Input Layer，接收输入数据)、隐藏层(Hidden Layer, 数据处理)、输出层(Output Layer, 产生输出结果)。</li></ul></li></ul><h3 id="前馈神经网络-Feedforward-Neural-Networks-FNN"><a href="#前馈神经网络-Feedforward-Neural-Networks-FNN" class="headerlink" title="前馈神经网络(Feedforward Neural Networks, FNN)"></a>前馈神经网络(Feedforward Neural Networks, FNN)</h3><ol><li>定义：基础神经网络，数据从输入到输出单向流动。</li><li>特点：数据从输入层开始，经过隐藏层计算，最后到达输出层输出预测结果，数据单向流动，全过程没有反馈和循环等方向操作。</li><li>结构：输入层（网络数据入口，每个节点代表一种输入特征）、隐藏层（每层由多个神经元构成，每个神经元通过激活函数体现其非线性能力，用于获取数据的非线性特征）、输出层（网络预测结果出口，其节点个数和问题有关）。</li></ol><h3 id="卷积神经网络-Convolutional-Neural-Networks-CNN"><a href="#卷积神经网络-Convolutional-Neural-Networks-CNN" class="headerlink" title="卷积神经网络(Convolutional Neural Networks, CNN)"></a>卷积神经网络(Convolutional Neural Networks, CNN)</h3><ol><li>定义：专门处理网络拓扑结构数据的神经网络模型，是机器视觉核心技术。可以使用卷积层提取空间特征。</li><li>结构：</li></ol><ul><li>输入层（Input Layer）：原始数据图像入口，用于接收类似于图像的三维数组（图像高度、宽度和颜色通道）。</li><li>卷积层(Convolutional Layer)：根据卷积公式，用卷积核(Kernel)提取局部特征，生成特征图。</li><li>非线性激活函数层(Activation Function)：引入非线性特征，增强网络适应性。</li><li>池化层(Pooling Layer)：在卷积层后，在保留最重要特征信息情况下，通过池化技术(最大池化-区域最大值&#x2F;平均池化-区域平均值)降低特征图空间维度，减少计算和参数数量，生成池化特征图。</li><li>归一化层（Normalization Layer, 可选）：采用归一化技术（局部响应归一化&#x2F;批归一化），使多维特征图转换为一维向量，加速训练，提高模型稳定性。</li><li>正则化（Regularization, 可选）：用于防止模型过拟合。</li><li>损失函数层(Loss Function)：衡量模型预测和实际结果之间的差异。</li><li>优化器(Optimizer)：根据损失函数对参数的梯度更新模型参数。</li><li>全连接层(Fully Connected Layer)：用于综合所有提取的特征映射到输出，并进行最后的分类或回归。</li><li>输出层(Output Layer)：模型预测结果出口。</li></ul><h3 id="循环神经网络-Recurrent-Neural-Networks-RNN"><a href="#循环神经网络-Recurrent-Neural-Networks-RNN" class="headerlink" title="循环神经网络(Recurrent Neural Networks, RNN)"></a>循环神经网络(Recurrent Neural Networks, RNN)</h3><ol><li>定义：允许信息反馈循环，适用于序列数据（时间序列、语音识别、自然语言）。</li><li>特点：“记忆能力”，使用隐状态(hidden state)，在隐藏层可以保留以前时间调用的信息，进而捕获数据中的时间等前后依赖关系。</li><li>典型RNN模块：</li></ol><ul><li>torch.nn.RNN: 基本RNN单元。</li><li>torch.nn.LSTM: 长短期记忆网络(Long short-Term Memory, LSTM)，RNN的变种，能学习长期依赖关系。</li><li>torch.nn.GRU: 门控循环单元，LSTM简化版本。</li></ul><h2 id="神经网络模型训练过程简介（Training-Process）"><a href="#神经网络模型训练过程简介（Training-Process）" class="headerlink" title="神经网络模型训练过程简介（Training Process）"></a>神经网络模型训练过程简介（Training Process）</h2><ol><li>数据ETL：</li></ol><ul><li>收集和处理数据，包括数据清洗、标准化和归一化。</li><li>数据分割，包括训练集、验证集和测试集。</li></ul><ol start="2"><li>定义网络模型：</li></ol><ul><li>设计模型架构，在业务需求、设备支持、项目交付、行管规则等要求下，选择合适的模型，定义网络层、前向传播过程、激活函数等。</li><li>设置初始化模型参数（权重和偏置）。</li><li>选择损失函数：根据问题特点选择合适的损失函数（分类或回归等）。</li><li>选择优化器：根据需要选择优化算法，更新模型参数。</li></ul><ol start="3"><li>前向传播（Forward Propagation）：</li></ol><ul><li>在每次迭代中，根据输入数据通过模型传递，计算预测输出。</li><li>开启训练前需要清除梯度，调整模型进入训练模式（model.train()）。</li></ul><ol start="4"><li>计算损失(Calulate Loss)：</li></ol><ul><li>使用损失函数计算评估预测输出和实际输出之间的差异。</li></ul><ol start="5"><li>反向传播(Backpropagation)：</li></ol><ul><li>利用自动求导计算损失函数相对于模型参数（权重和偏置）的梯度。</li><li>一般调度torch.nn.MSEloss().backward()等计算。</li></ul><ol start="6"><li>参数更新(Parameter Update)：</li></ol><ul><li>调用优化器，根据计算出的梯度和优化器策略，更新模型参数。</li><li>一般通过optim.SGD().step()等更新参数。</li></ul><ol start="7"><li>迭代优化(Iteration)：</li></ol><ul><li>重新循环上述步骤，直到模型在验证集上是性能不能再提升，或者迭代达到预定次数。</li><li>此过程也是试算过程的开始，考虑到数据、方案、环境等因素的不完善，模型方案不一定有好的结果，需不断校验检查。</li></ul><ol start="8"><li>测试评估：</li></ol><ul><li>利用测试集评估模型性能，确保模型没有过拟合或者欠拟合。</li><li>计算准确率(Accuracy):计算正确预测比例（分类问题）。</li><li>测试评估前需要调整模型进入评估模式（model.eval()）,并且在评估过程中要禁用梯度计算。（torch.no_grad(), 减少不必要的计算和内存开销）,以确保模型能正确推理。</li></ul><ol start="9"><li>模型调优：</li></ol><ul><li>根据模型在测试集上的表现调参，优化模型各项配置和参数。</li></ul><ol start="10"><li>部署模型：</li></ol><ul><li>将训练好的模型，根据部署平台的使用要求，部署到生产环境中，用于实际工作。</li></ul><h2 id="PyTorch神经网络工具字典"><a href="#PyTorch神经网络工具字典" class="headerlink" title="PyTorch神经网络工具字典"></a>PyTorch神经网络工具字典</h2><p>  关键模块：torch.nn（网络模块）、torch.optim（优化器模块）、 torch.autograd(自动微分)</p><ol><li><a href="https://docs.pytorch.ac.cn/docs/stable/nn.html#module-torch.nn.parallel">torch.nn</a>模块组成：</li></ol><ul><li>关键类：torch.nn.Module类，是所有神经网络模块的基类，可以用来从这个基类派生出自己的模型类，并定义其中的网络层结构和前向传播过程。自定义神经网络模型时，需要定义这两部分：<strong>init</strong>()(定义网络层)、forward()(定义数据前向传播过程)。</li><li>预定义层（Modules）:包含各种层组件，如卷积层、线性层、池化层、归一化层、循环神经网络层、嵌入层、Dropout层、非线性激活函数（Activation Function，决定神经元是否应该被激活）等。</li><li>容器类(Containers)：由模块（torch.nn.Module）、序列(torch.nn.Sequential)、模块列表(torch.nn.ModuleList)、模块字典(torch.nn.ModuleDict)、参数列表(torch.nn.ParameterList)、参数字典(torch.nn.ParameterDict)组成。</li><li>损失函数（Loss Function）:衡量模型预测值和真实值之间的差异。</li><li>实用函数（Functional Interface）：torch.nn.functional(作用于张量上的实现和层对象相同功能的函数)。</li><li>初始化方法：torch.nn.init(权重初始化策略)。</li></ul><ol start="2"><li>torch.nn常用组件：</li></ol><ul><li>卷积层</li></ul><table><thead><tr><th>组件</th><th>描述和特点</th></tr></thead><tbody><tr><td>torch.nn.Conv2d()</td><td>2D卷积层，常用于图像</td></tr></tbody></table><ul><li>线性层</li></ul><table><thead><tr><th>组件</th><th>描述和特点</th></tr></thead><tbody><tr><td>torch.nn.Linear(in_features，out_features)</td><td>输入in_features个特征，输出out_features个特征</td></tr></tbody></table><ul><li>池化层</li></ul><table><thead><tr><th>组件</th><th>描述和特点</th></tr></thead><tbody><tr><td>torch.nn.MaxPool2d()</td><td>2D最大池化层，常用于降维</td></tr></tbody></table><ul><li>激活函数</li></ul><table><thead><tr><th>组件</th><th>描述和特点</th></tr></thead><tbody><tr><td>torch.nn.functional.relu()</td><td>定义为f(x) &#x3D; max(0, x)，常用于隐藏层</td></tr><tr><td>torch.nn.functional.sigmoid()</td><td>输出值为0和1之间，适合二分类问题</td></tr><tr><td>torch.nn.functional.tanh()</td><td>输出值在-1和1之间，适合输出层使用</td></tr><tr><td>torch.nn.functional.softmax</td><td>将输出转换为概览分布，适用多分类的输出层</td></tr></tbody></table><ul><li>损失函数</li></ul><table><thead><tr><th>组件</th><th>描述和特点</th><th>适配场景</th></tr></thead><tbody><tr><td>torch.nn.MSELoss()</td><td>均方误差（L2范数），计算输出和目标值之间的平方差</td><td>回归问题</td></tr><tr><td>torch.nn.CrossEntropyLoss()</td><td>计算输出和目标值之间的交叉熵</td><td>分类问题</td></tr><tr><td>torch.nn.BCEWithLogitsLoss()</td><td>计算Sigmoid激活和二元交叉熵的损失</td><td>二分类问题</td></tr></tbody></table><ol start="3"><li><a href="https://docs.pytorch.ac.cn/docs/stable/optim.html">torch.optim</a></li></ol><ul><li>功能：根据损失函数的梯度，在训练过程中自动化更新网络模型参数（权重和偏置），在避免局部最优的情况下，参数加速收敛到最优解，进而使模型预测结果逐步优化逼近目标值。</li><li>优化器（Optimizer）选择判断：数据是否稀疏-&gt;是否需要快速收敛</li><li>常用优化器类型：</li></ul><table><thead><tr><th>优化器名称</th><th>中文名称</th><th>调度方法</th><th>收敛速度</th><th>内存占用</th><th>超参数敏感度</th><th>特点</th><th>适用场景</th></tr></thead><tbody><tr><td>SGD</td><td>随机梯度下降</td><td>torch.optim.SGD(params, lr &#x3D; 0.01, momentum &#x3D; 0, weight_decay &#x3D; 0)</td><td>慢</td><td>低</td><td>高</td><td>简单，可添加动量加速收敛，适合和基准比较，使用梯度的移动平均值（一阶矩）</td><td>基础简单模型</td></tr><tr><td>Adam</td><td>自适用矩估计</td><td>torch.optim.Adam(params, lr &#x3D; 0.001, betas &#x3D; (0.9, 0.999), eips &#x3D; 1e-08, amsgrad &#x3D; False)</td><td>快</td><td>中</td><td>低</td><td>可自适应学习率，可计算每个参数的学习率，结合SGD和RMSprop的特点</td><td>绝大多数的深度学习任务</td></tr><tr><td>RMSprop</td><td>均方根传递</td><td>torch.optim.RMSprop(params, lr &#x3D; 0.01, alpha &#x3D; 0.99)</td><td>快</td><td>中</td><td>中</td><td>适应学习率，使用平方梯度的移动平均值来缩放梯度（二阶矩）</td><td>RNN网络</td></tr><tr><td>Adagrad</td><td>自适应学习率应梯度下降</td><td>torch.optim.Adagrad(params, lr &#x3D; 0.01, initial_accumulator_value &#x3D; 0)</td><td>先快后慢</td><td>中</td><td>高</td><td>参数独立学习率，学习率随时间减小</td><td>稀疏数据</td></tr></tbody></table><p>4 <a href="https://docs.pytorch.ac.cn/docs/stable/autograd.html">torch.autograd</a></p><ul><li>功能：各种类和函数对任意标量函数计算数学函数的导数，主要用来自动计算梯度。深度学习自动求导主要用于在神经网络计算梯度和反向传播算法实现。</li></ul><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] <a href="https://study.163.com/course/introduction/1208894818.htm">深度学习与PyTorch入门实战</a><br>[2] Zhang, A., Lipton, Z. C., Li, M., &amp; Smola, A. J. (2023). <a href="https://zh.d2l.ai/index.html">Dive into Deep Learning</a>. Cambridge University Press. URL: <a href="https://d2l.ai/">https://D2L.ai</a><br>[3] <a href="https://github.com/dragen1860/Deep-Learning-with-PyTorch-book">PyTorch深度学习</a><br>[4] <a href="https://www.runoob.com/PyTorch/PyTorch-tutorial.html">菜鸟教程</a><br>[5] <a href="https://datawhalechina.github.io/thorough-PyTorch/index.html#">深入浅出PyTorch</a></p>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
            <tag> 算法 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> PyTorch </tag>
            
            <tag> 神经网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>昇思MindSpore基础教程</title>
      <link href="/2025/08/18/%E6%98%87%E6%80%9DMindSpore%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/"/>
      <url>/2025/08/18/%E6%98%87%E6%80%9DMindSpore%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>全场景、深度学习计算框架，可支持CPU、GPU、华为AI昇腾系列处理器等硬件,可使用Linux、windows、MacOS系统。<br>教程目的：熟悉框架语法结构，熟悉从构建数据集到训练的全流程</p><h2 id="MindSpore安装"><a href="#MindSpore安装" class="headerlink" title="MindSpore安装"></a>MindSpore安装</h2><p><a href="https://www.mindspore.cn/install/#guide%5C">MindSpore安装</a><br>验证安装成功会显示如下信息：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">MindSpore version: 版本号</span><br><span class="line">The result of multiplication calculation is correct, MindSpore has been installed on platform [CPU] successfully!</span><br></pre></td></tr></table></figure><p>注意：<br>     - 版本选择2.7.0-rc1,选择2.6.0的时候会导致下载失败。<br>     - 下载请在管理员下的命令提示符下进行。</p><h2 id="Tensor-创建-属性-操作-NumPy"><a href="#Tensor-创建-属性-操作-NumPy" class="headerlink" title="Tensor: 创建-属性-操作-NumPy"></a>Tensor: 创建-属性-操作-NumPy</h2><p>张量（Tensor）是MindSpore中的基本数据结构，存储多维数组的数据结构。</p><ol><li>张量属性：形状(shape)和数据类型(dtype)<br> 形状：定义张量的维度，是tuple类型，使用张量.shape查看<br> 数据类型：使用张量.dtype查看，定义张量的数据类型和大小，包括基础数据类型、其他类型、类型转换规则，必须使用<a href="https://www.mindspore.cn/docs/zh-CN/r2.7.0rc1/api_python/mindspore/mindspore.dtype.html">mindspore.dtype</a>中定义的类型。</li><li>张量初始化：<ul><li>直接创建：mindspore.Tensor()。<a href="https://www.mindspore.cn/docs/zh-CN/r2.7.0rc1/api_python/mindspore/mindspore.Tensor.html">Tensor参考API文档</a></li><li>使用numpy创建：mindspore.Tensor(numpy.array())</li><li>从旧张量中创建新张量：mindspore.ops.OnesLike(Tensor())</li></ul></li><li>张量运算：涉及算术、线性代数、矩阵运算等。可使用类numpy的索引和切片使用方式，存在和pandas类似的连接(cancat)和合并使用方式.</li><li>与NumPy的数据转换：<ul><li>NumPy转换为Tensor: mindspore.Tensor(numpy.array())</li><li>Tensor转转换为NumPy：mindspore.Tensor.asnumpy(),Tensor和ndarray会共享内存地址。</li></ul></li><li>注意：<ul><li><p>使用前需要设置环境上下文，设置模式和目标设备类型，例如：</p></li><li><pre><code>from mindspore import contextcontext.set_context(mode=context.GRAPH_MODE, device_target=&quot;CPU&quot;)</code></pre><p>模式包括GRAPH_MODE（静态图模式）和PYNATIVE_MODE（动态图模式）两种。<br>目标设备类型包括CPU、GPU、Ascend(昇腾)</p></li><li><p><a href="https://www.mindspore.cn/docs/zh-CN/r2.7.0rc1/api_python/mindspore.ops.html#parameter%E6%93%8D%E4%BD%9C%E5%87%BD%E6%95%B0">mindspore.obs</a>提供function接口，涉及Tensor操作函数、数学运算函数、神经网络函数、微分函数、调试函数等。</p></li><li><p>使用时需要注意有些API函数中存在支持平台的限制，例如Ascend(昇腾)、GPU、CPU，有些函数只支持CPU或者GPU,有些实验性质的API只支持Ascend。</p></li><li><p>当使用 init 参数来初始化 Tensor 时，通常需要使用 Tensor.init_data 来加载 Tensor 的数据</p></li></ul></li></ol><h2 id="数据：创建-自定义-数据处理"><a href="#数据：创建-自定义-数据处理" class="headerlink" title="数据：创建-自定义-数据处理"></a>数据：创建-自定义-数据处理</h2><ol><li><a href="https://www.mindspore.cn/docs/zh-CN/r2.7.0rc1/api_python/mindspore.dataset.loading.html#%E9%87%87%E6%A0%B7%E5%99%A8-1">mindspore.dataset</a>：<br>性质：核心数据加载模块，基于Pipeline的数据引擎。<br>作用：提供数据采样、增强变换、数据批处理等功能，通过使用不同的数据加载方式，和数据集加载API配合使用。<br>数据加载方式三种：开源数据集加载、标准格式数据集加载、自定义数据集加载<br>开源数据集加载：视觉数据集、文本数据集、音频数据集<br>标准格式数据集加载：加载业界标准数据格式的数据集文件，例如TFRecord、MindRecord等格式。<br>自定义数据集加载（mindspore.dataset.GeneratorDataset）：自定义Python数据源，自定义数据读取和处理逻辑。</li><li>数据处理步骤：加载数据集、数据集操作、批处理、迭代器、数据增强（数据集样本变换）</li></ol><ul><li>数据加载：</li><li>加载数据集（自定义、开源和标准格式数据集）<ul><li>加载数据集(开源和标准格式)：先用模块提供的API加载和处理数据集import mindspore.dataset as ds。再通过使用jupyter notebook中运行linux命令下载数据集并解压，存放到指定路径中，注意数据集的目录结构。使用时需要注意使用的数据集文件所在的根目录路径，有些加载必须使用该路径才能使用数据。</li><li>加载自定义数据集：使用<a href="https://www.mindspore.cn/docs/zh-CN/r2.7.0rc1/api_python/dataset/mindspore.dataset.GeneratorDataset.html#mindspore.dataset.GeneratorDataset">GeneratorDataset接口</a>自定义数据集加载。可以先自定义数据集类(DatasetGenerator)，包含数据初始化操作__init__, 数据访问方法__getitem__, 数据量统计方法__len__等，再通过GeneratorDataset接口加载自定义数据集类访问数据集中的数据样本。</li></ul></li><li>数据集操作、批处理、迭代器、数据增强（数据集样本变换）<ul><li>数据集操作（filter&#x2F; skip）：通过使用对象方法  .filter &#x2F; .skip&#x2F; .shuffle来实现数据集的进一步过滤、跳过、混洗等操作。注意：.shuffle等方法是实例方法，使用时需要先创建实例，再调度数据集操作方法。</li><li>批处理(mindspore.dataset.Dataset.batch):将数据集中的多条数据组合为一个批数据。</li><li>迭代器(mindspore.dataset.Dataset.create_dict_iterator):创建数据集迭代器，返回字典样式的样本数据，可实现预处理过程中的数据循环输出。</li><li>数据增强：数据集样本变换（mindspore.dataset.transforms)，一种通用数据增强方法，特别是在数据量过小或在样本单一等问题场景下影响模型训练效果时，通过使用数据增强操作进一步扩展样本多样性和操作，从而提升模型的泛化能力。</li></ul></li></ul><h2 id="模型：定义-模型结构-模型层-模型参数"><a href="#模型：定义-模型结构-模型层-模型参数" class="headerlink" title="模型：定义-模型结构-模型层-模型参数"></a>模型：定义-模型结构-模型层-模型参数</h2><p>以神经网络模型的构建为例</p><ol><li>关键模块：<br> <a href="https://www.mindspore.cn/docs/zh-CN/r2.7.0rc1/api_python/mindspore.nn.html#%E5%9F%BA%E6%9C%AC%E6%9E%84%E6%88%90%E5%8D%95%E5%85%83">mindspore.nn</a>：神经网络模块，用于构建神经网络中的预定义构建块或者计算单元。<br> 其中包括基本构成单元、容器（构造神经元）、封装层、卷积神经网络层、循环神经网络层、Transformer层、嵌入层、非线性激活函数层、线性层、Dropout层（随机丢弃层）、归一化层、池化层、填充层、损失函数、优化器、动态学习率、图像处理层、公共层、工具等部分组成。</li><li>关键类：<br> mindspore.nn.Cell:MindSpore中神经网络的基本构成单元，是所有网络的基类，所有模型或神经网络层应当继承该基类，并重新其中的__init__方法和construct方法。Cell(神经元)在GRAPH_MODE（静态图模式）下将编译为一张计算图，在PYNATIVE_MODE（动态图模式）下作为神经网络的基础模块。</li></ol><ul><li>construct:定义要执行的计算逻辑，所有子类必须重写此方法。</li><li>parameters_and_names：返回当前Cell或所有子Cell的参数名称和参数本身</li></ul><ol start="3"><li>关键成员函数：</li></ol><ul><li>二维卷积神经网络层（mindspore.nn.Conv2d）：根据输入Tensor张量计算二维卷积。先根据参数建立卷积神经网络模型，再根据输入Tensor，输出Tensor.可用于在神经网络中提取特征。</li><li>全连接线性层（mindspore.nn.Dense）：根据输入Tensor，计算出线性变换后的输出Tensor， 可用于对输入张量做线性变换。使用的激活函数可以指定具体的激活函数名，例如mindspore.nn.ReLU</li><li>非线性激活函数层（mindspore.nn.ReLU）:逐元素计算修正线性单元激活函数，逐位输出各位中数值和零的最大值。输入和输出都是Tensor，在网络中添加非线性激活函数，可用于神经网络学习复杂特征。</li><li>池化层（mindspore.nn.MaxPool2d）：在输入Tensor上应用2D最大池化运算，组成2D平面，可用于数组降采样。</li><li>公共层（mindspore.nn.Flatten）：对输入的Tensor按照输入维到输出维进行展平。</li></ul><h2 id="自动微分：求导-梯度缩放-停止计算-梯度"><a href="#自动微分：求导-梯度缩放-停止计算-梯度" class="headerlink" title="自动微分：求导-梯度缩放-停止计算-梯度"></a>自动微分：求导-梯度缩放-停止计算-梯度</h2><ol><li>参数设置:<br> mindspore.Parameter：Tensor子类，当被绑定为Cell属性时，可以同Cell的方法获取。<br> mindspore.ParameterTuple：用于管理多个mindspore.Parameter，实现将网络参数存储到参数元祖集合中。</li><li>梯度计算：<br> mindspore.ops.matmul:计算输入的两个Tensor乘积，输入的两个Tensor数据类型必须一致。<br> mindspore.ops.GradOperation (get_all&#x3D;False, get_by_list&#x3D;False, sens_param&#x3D;False)，一阶导数方法，来自mindspore.ops.primitive的框架算子，一个高阶函数，为输入函数生成对应的梯度函数。可实现对输入求导（返回第一个输入的梯度和所有输入的梯度）、对参数求导和同时对输入和参数求导。其中</li></ol><ul><li>get_all为False时，只会对第一个输入求导，为True时，会对所有输入求导</li><li>get_by_list为False时，不会对权重求导，为True时，会对权重求导</li><li>sens_param对网络的输出值做缩放以改变最终梯度，配合缩放指数，确保缩放指数的维度和输出维度保持一致。</li><li>mindspore.ops.stop_gradient:用于消除某个值对梯度的影响，例如截断来自于函数输出的梯度传播，可以用来禁止网络内的算子对梯度的影响。</li></ul><ol start="3"><li>求导步骤：</li></ol><ul><li>定义使用算子定义网络结构、定义求导网络、根据具体输入值计算计算求导值。</li><li>对权重求一阶导，需要将mindspore.ops.GradOperation中的get_by_list设置为Trure.如果对某些权重不进行求导，则在定义网络结构中，对相应权重参数值mindspore.Parameter中的requires_grad设置为False.</li><li>对梯度值做缩放，需要将mindspore.ops.GradOperation中的sens_param设置为Trure，并在求导网络中定义缩放指数self.grad_wrt_output，再将该指数用于求导函数中。</li></ul><h2 id="优化模型：损失函数-优化器"><a href="#优化模型：损失函数-优化器" class="headerlink" title="优化模型：损失函数-优化器"></a>优化模型：损失函数-优化器</h2><ol><li>超参：可调整参数，用于控制模型训练优化过程，影响模型训练和收敛速度等。<br> 一般超参如下：</li></ol><ul><li>训练轮次（epoch）:训练时遍历数据集的次数，一般用于训练mindspore.train.Model.train方法中</li><li>批次大小（batch size）:用于构造训练数据集，数据集进行分批次读取训练，并设定每个批次数据大小。</li><li>学习率（learning rate）:用于优化器参数设置中，学习率偏小会导致收敛速度偏慢，过大则导致训练不收敛等不可预测问题。</li></ul><ol start="2"><li>损失函数：评价模型的预测值和真实值不一样的程度，损失函数可以直接使用mindspore.nn.L1Loss（计算预测值和目标值之间的平均绝对误差）这类损失函数定义。</li><li>优化器：用于计算和更新梯度，优化器的选择直接影响最终模型的性能。优化器在模块mindspore.nn中，mindspore的所有优化逻辑都封装在Optimizer对象中，要使用优化器，需要构建Optimizer对象，要能够保持参数状态并基于计算得到的梯度能进行参数更新。构造Optimizer对象前，需要先确定包含所有需要优化参数的迭代器，如网络中需要训练的参数parameter等。<br> 优化器可以直接使用mindspore.nn.SGD（随机梯度下降的实现）这类优化器函数定义。</li><li><a href="https://www.mindspore.cn/docs/zh-CN/r2.7.0rc1/api_python/train/mindspore.train.Model.html#mindspore.train.Model.train">mindspore.train.Model</a>：模型训练和推理高阶接口，根据用户的传入参数、损失函数、优化器，封装可训练或推理的实例。<br> train方法：模型训练接口，可根据训练执行轮次epoch，训练数据集train_dataset，开始模型训练。</li><li>模型训练四步骤：</li></ol><ul><li>定义神经网络</li><li>构建数据集</li><li>定义超参、损失函数和优化器</li><li>输入训练轮次和数据集开始模型训练。</li></ul><h2 id="保持加载：保存模型-加载权重-导出IR"><a href="#保持加载：保存模型-加载权重-导出IR" class="headerlink" title="保持加载：保存模型-加载权重-导出IR"></a>保持加载：保存模型-加载权重-导出IR</h2><h3 id="保存模型："><a href="#保存模型：" class="headerlink" title="保存模型："></a>保存模型：</h3><ol><li>主要使用Callback机制，使用API函数如下：</li></ol><ul><li><a href="https://www.mindspore.cn/docs/zh-CN/r2.7.0rc1/api_python/train/mindspore.train.ModelCheckpoint.html">mindspore.train.ModelCheckpoint</a>：checkpoint回调函数，用于在训练过程中，保存网络参数。注意：在分布式训练场景下，每个训练进程都需要指定不同的目录，保存checkpoint文件，否则可能训练失败。</li><li><a href="https://www.mindspore.cn/docs/zh-CN/r2.7.0rc1/api_python/train/mindspore.train.CheckpointConfig.html#mindspore.train.CheckpointConfig">mindspore.train.CheckpointConfig</a>：保存checkpoint配置策略</li></ul><ol start="2"><li>注意：</li></ol><ul><li>保存模型步骤：先设置checkpoint配置策略，再创建ModelCheckpoint对象，在将ModelCheckpoint对象传递给model.train训练方法，开始训练。</li><li>MindSpore为方便用户区分每次生成的CheckPoint文件，会在用户定义的前缀后添加”_”和数字加以区分。如果想要删除.ckpt文件时，请同步删除.meta 文件。</li></ul><h3 id="加载模型："><a href="#加载模型：" class="headerlink" title="加载模型："></a>加载模型：</h3><ol><li><a href="https://www.mindspore.cn/docs/zh-CN/r2.7.0rc1/api_python/mindspore/mindspore.load_checkpoint.html#mindspore.load_checkpoint">mindspore.load_checkpoint</a>:加载checkpoint文件，返回值是字典。主要用于将参数文件中的网络参数存入自定义的参数字典中，配合模型实例，将参数加载入网络中。</li><li><a href="https://www.mindspore.cn/tutorials/zh-CN/r1.3/save_load_model.html">mindspore.load_param_into_net</a>:将自定义参数字典中的参数加载到网络或优化器中，加载后，网络中的参数就是之前CheckPoint保存的参数，返回网络中没有被加载的参数列表。</li></ol><h3 id="验证模型："><a href="#验证模型：" class="headerlink" title="验证模型："></a>验证模型：</h3><ol><li>推理场景：<br> <a href="https://www.mindspore.cn/docs/zh-CN/r2.7.0rc1/api_python/train/mindspore.train.Model.html#mindspore.train.Model.train">mindspore.train.Model</a>：模型训练或推理高阶接口。 根据用户传入的参数，封装可训练或推理的实例。</li></ol><ul><li>eval方法：模型评估接口。</li><li>train方法：模型训练接口。</li><li>验证步骤：先定义验证数据集，再利用数据集，调度eval方法进行推理验证。</li></ul><ol start="2"><li>任务中断再训练或者微调场景：</li></ol><ul><li>验证步骤：先定义训练轮次和训练数据集，再利用数据集，调度train方法进行训练。可用于迁移学习。</li></ul><h3 id="导出模型："><a href="#导出模型：" class="headerlink" title="导出模型："></a>导出模型：</h3><p>通过网络和CheckPoint格式文件生成对应模型格式文件，实现在不同硬件平台上的推理。</p><ol><li><a href="https://www.mindspore.cn/docs/zh-CN/r2.7.0rc1/api_python/mindspore/mindspore.export.html#mindspore.export">mindspore.export</a>:将MindSpore网络模型导出为指定格式的文件。可导出ONNX&#x2F;AIR&#x2F;MINDIR三种格式文件。当导出文件格式为AIR、ONNX时，单个Tensor的大小不能超过2GB。</li><li>文件导出格式：</li></ol><ul><li>ONNX(Open Neural Network eXchange):一种针对机器学习所设计的开放式的文件格式，由微软提出，与环境和平台无关的标准格式，2.2 用于在不同深度学习框架共享和交换已训练好的模型。推荐的输出文件后缀是”.onnx”.</li><li>AIR(Ascend Intermediate Representation):一种Ascend模型的中间表示格式。类似ONNX，由华为提出，能更好适配昇腾AI处理器。推荐的输出文件后缀是”.air”.</li><li>MINDIR(MindSpore Native Intermediate Representation for Anf):一种MindSpore模型的中间表示格式。推荐的输出文件后缀是”.mindir”.</li></ul><ol start="3"><li>格式导出：</li></ol><ul><li><p>ONNX格式：可在第三方硬件平台上推理。导出文件名称会自动添加“.onnx”后缀。</p><p><code>export(..., file_format = &#39;ONNX&#39;)</code></p></li><li><p>AIR格式：可在昇腾AI处理器上推理。导出文件名称会自动添加“.air”后缀。<br><code>export(..., file_format = &#39;AIR&#39;)</code></p></li><li><p>MINDIR格式：可在MindSpore端侧（GPU&#x2F;CPU&#x2F;Ascend）上推理。导出文件名称会自动添加“.mindir”后缀。<br><code>export(..., file_format = &#39;MINDIR&#39;)</code></p></li></ul><h2 id="端侧推理：模型加载-植入APP-推理"><a href="#端侧推理：模型加载-植入APP-推理" class="headerlink" title="端侧推理：模型加载-植入APP-推理"></a>端侧推理：模型加载-植入APP-推理</h2><p>不同推理设备有不同的推理方法，模型可以在昇腾Ascend处理器和移动设备上进行推理，由于昇腾Ascend处理器推理配置复杂，本文主要介绍移动设备推理。</p><ol><li><a href="https://www.mindspore.cn/lite/docs/zh-CN/r2.7.0rc1/index.html">MindSpore Lite</a>:AI引擎，支持GPU&#x2F;CPU&#x2F;NPU异构调度，支持模型轻量化、全场景(IOS&#x2F;安卓&#x2F;Huawei LiteOS系统)部署，支持MindSpore、TensorFlow Lite、Caffe和ONNX 4类AI框架（不支持Pytorch）。</li><li>工作流程和步骤：</li></ol><ul><li>选择模型：可使用预置的终端模型，或者使用自己已训练好的模型。</li><li>模型转换：主要是格式转换<br>转换工具下载：按照linux和windows系统的不同，选择不同的转换工具压缩包。<br>转换工具使用：不同系统转换工具不同，执行转换命令时，–fmk参数表示输入模型的原始格式，例如MINDIR;–modeFile表示输入模型路径；–outputFile表示模型输出路径，转换后的模型会自动添加.ms后缀，转换为.ms格式。</li><li>构建环境和运行：不同系统编译和推理有差异。<br>编译构建：windows系统要比linux麻烦一点，需要下载库和模型。<br>执行推理：编译完成后，进入模型目录，调用.ms格式的模型文件</li></ul><p>基于公开来源资料mindspore教程1.3版本，详情请看<a href="https://www.mindspore.cn/tutorials/zh-CN/r1.3/custom.html#">MindSpore官网</a></p>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
            <tag> 算法 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> MindSpore </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GaussDB(DWS)数据库-巡检运维篇</title>
      <link href="/2025/08/04/GaussDB(DWS)%E6%95%B0%E6%8D%AE%E5%BA%93-%E5%B7%A1%E6%A3%80%E8%BF%90%E7%BB%B4%E7%AF%87/"/>
      <url>/2025/08/04/GaussDB(DWS)%E6%95%B0%E6%8D%AE%E5%BA%93-%E5%B7%A1%E6%A3%80%E8%BF%90%E7%BB%B4%E7%AF%87/</url>
      
        <content type="html"><![CDATA[<h3 id="基本运维动作"><a href="#基本运维动作" class="headerlink" title="基本运维动作"></a>基本运维动作</h3><ol><li><p>常用运维命令：</p><ul><li>查看集群状态或单个主机的状态：cm_ctl query -Cv；Normal:表示集群可用，主备关系正常；Degraded:表示集群可用，但是数据没有冗余备份；Unavailable:表示集群不可用；Catchup:表示集群的DN备实例正在追赶主实例的日志信息。</li><li>切换集群主备实例、实现AZ之间的相互切换：cm_ctl switchover -a</li><li>启停实例：<ul><li>注意事项<ul><li>适用场景：主机发生故障状态异常，需要停止所有实例；或单台服务器、硬盘故障，需要停止对应的实例进行检修更换等</li><li>前提条件：停止节点&#x2F;实例后，需要保证集群内至少有一个正常的CN节点、cm_server节点、gtm节点；涉及cn节点、实例后，如果没有负载均衡，需要将业务迁移至其他CN；若集群磁盘水位处于75%以上，停止节点、实例后需要重点关注磁盘水位变化；停止实例前，需要检查集群状态，保证对应实例状态正常，无catchup；停止实例前，连接集群执行checkpoint ；启停集群服务、单个主机上的所有实例或者单独启停某个实例进程</li></ul></li><li>停止模式有如下几种：<ul><li>smart: 等待用户业务结束后，集群退出</li><li>fash:不等待用户业务结束，集群退出</li><li>immediate: 不等待用户业务结束，强制集群退出。</li></ul></li><li>修复节点：<ul><li>修复前提：适用场景：DN异常、cn处于delete或者down状态</li><li>前提条件：集群安装成功，并且处于已启动状态；DN环只能损坏一个实例；集群内CMServer、CMAgent、Coordinator至少存在一个正常实例；GTM故障时，另一个GTM必须处于最高可用状态</li><li>注意实现：正常节点执行修复操作；修复涉及cn需要保障被修复的cn没有ddl业务将发生故障的主机（实例）替换为正常主机（实例）</li></ul></li></ul></li></ul></li><li><p>常用运维SQL：</p><ul><li>活跃作业语句查询，使用场景：查询此时在数据库运行的作业信息，用于确定当前作业运行的SQL、耗时、运行状态，排队状态和等待状态等信息，pgxc_stat_activity视图</li><li>作业等待查询，使用场景：查询此时在数据库运行作业的等待信息，用于确定当前作业运行过程中，在各个DN实例等待事件和阻塞状态，是在等待IO还是在等待锁等，pgxc_thread_wait_status视图</li><li>锁等待查询，使用场景：查询此时在数据库运行的作业中等锁的信息，包括等锁的语句、用户和持有锁的语句、用户，用于确定当前作业系统中调度不合理的场景，比如当一个表在进行增加表字段时，其他插入或者查询作业会阻塞。pgxc_lock_conflicts视图。</li><li>单表倾斜：通过查看表数据在各个dn的分布情况判断是否存在数据倾斜。<ul><li>倾斜表重分布处理步骤：<ul><li>创建一张新的表，并选取合适的分布列，判断一列是否可以作为分布列，可通过下面的语句查询该列的值分布情况：<code> bash select attr, cont(*) from schema.table group by atttr;</code> </li><li>将数据从旧表导入到新表：   <code> bash insert into new_table select * from old_table;</code> </li><li>删除旧表：   <code> bash drop table old_table;</code> </li><li>将新表重命名为旧表：   <code> bash alter table new_table rename to old_table;</code></li></ul></li></ul></li><li>全库查倾斜表：查询全库数据表的倾斜情况，在集群表较多时可以指定条件统计倾斜率超过10%和表大小大于100G的表倾斜信息，针对每个倾斜大表，需要按照单表的倾斜处理办法进行处理。运维建议：针对业务表建议每周例行全库运维处理倾斜表，各个节点磁盘使用率差别不超过5%。</li><li>判断需要analyze的表：识别从未做过analyze的表；识别insert、update&#x2F;delete总量超过上次统计数据量20%的表。需要固化到业务中，立即做analyze的场景：每次truncate表后执行insert数据的场景。每天插入新数据后并且业务立即只查询刚插入的数据场景。</li><li>脏页回收：<ul><li>dws用户表数据在经过频繁插入、更新、删除后，会产生脏页，脏页会占用空间。在脏页率达到一定程度时需要使用vacuum full analyze命令清理，建议每月进行一次维护</li><li>使用方法：登录需要统计的数据库，执行上面的SQL语句，找到需要进行清理的表。执行SQL命令；vacuum full analyze 业务表：</li><li>调优建议：当脏页率&gt;30%或者脏数据行数&gt;1w时，对表做脏页回收。</li></ul></li><li>内存使用：查询当前数据库节点的内存使用情况，单位MB.查询当前节点内存使用情况：   <code>bash select * from pv_total_memory_detail;  </code></li></ul></li><li><p>运维日志：</p><ul><li>数据库日志：数据库日志记录了DWS数据库服务端启动，运行或停止时出现的问题，当数据库在启动，运行或者停止的过程中出现问题时，数据库用户可以通过运行日志，快速分析问题的产生原因。</li><li>管控面日志</li><li>操作系统日志：操作系统日志可以记录系统的运行状态和异常情况，并且用于故障排除和性能分析。</li></ul></li><li><p>产品架构形态：dws数据库主要有如下部署方式：线下物理机部署ESL和云化部署HCS</p><ul><li>线下部署：<ul><li>DWS的ESL版本使用fusioninsight manager管理平台提供集群状态监控，告警管理，监控采集等功能。集群安装完成后，登录管理平台即可查看集群的状态监控指标.</li><li>数据库级别的监控指标：服务对于CPU、内存，物理读写与IO等资源的消耗趋势，反应了数据库的业务压力，需要指出的是这里的内存使用大小指的时候各个数据库实例在监控时间点消耗的内存总量。</li><li>节点级别的监控指标：提供主机级别的CPU&#x2F;内存以及磁盘使用情况的趋势图。</li><li>登录节点执行运维命令均需要在“omm”用户下执行，并且需要source环境变量。</li></ul></li><li>云化部署：<ul><li>DWS的HCS形态完成集群创建后，即可在集群管理页面看到创建的集群信息，选择集群操作选项中的监控面板功能，查看监控信息。</li><li>节点级别监控：CPU&#x2F;IO&#x2F;磁盘使用率，内存，网络等；</li><li>集群概览：集群状态，整体资源消耗利率，实例状态</li><li>实时查询：活跃会话数，活跃应用数，活跃查询数。</li></ul></li></ul></li></ol><h3 id="巡检工具及运维工具"><a href="#巡检工具及运维工具" class="headerlink" title="巡检工具及运维工具"></a>巡检工具及运维工具</h3><ol><li>巡检工具：<ul><li>不同巡检任务：</li><li>日常巡检：<ul><li>使用场景：用于集群日常维护，获取集群的健康状态，发现集群的潜在风险问题。</li><li>TOP巡检项：集群状态，负载均衡状态，CPU使用率，磁盘性能和使用率，日志空间大小，内存泄露，数据倾斜，透明大页，周期性备份等</li><li>使用规范：每单周或双周执行一次</li></ul></li><li>升级前巡检：<ul><li>使用场景：用于集群版本升级前，提前发现可能会影响集群升级的问题。</li><li>TOP巡检项：集群状态，文件系统占用率，磁盘空间空间，防火墙关闭，xid回卷，系统表是否损坏。</li><li>使用规范：升级版本前5天内执行</li></ul></li><li>扩容前巡检：<ul><li>使用场景：用于扩容操作前，提交发现可能会影响集群扩容的风险问题。</li><li>TOP巡检项:集群状态，节点间互信，磁盘使用率，磁盘的inodes使用率，数据倾斜，SCTP模块是否安装等。</li><li>使用规范：扩容操作前5天内执行</li></ul></li><li>温备前巡检（仅HCS形态支持）：<ul><li>使用场景：用于温备操作前，提交发现可能会影响温备操作的风险问题</li><li>TOP巡检项：全部11项</li><li>使用规范：温备操作前5天内执行</li></ul></li><li>深度巡检：<ul><li>使用场景：用于GaussDB集群日常维护，获取集群更深度的健康状态，发现集群的潜在风险，深度巡检必须停止业务后执行。</li><li>TOP巡检项：磁盘使用率，僵尸进程，内存泄露，残留临时表，是否有psort索引，负载均衡状态，分布键顺序，开启analyze，guc参数符合调优条件等</li><li>使用规范:每年执行一次。</li></ul></li></ul></li><li>ESL形态巡检工具：<ul><li>工具介绍：FusionInsight Tool DWS Prober是为工程师提供的一套健康检查工具，能够检查集群相关节点，服务的健康状态，提前发现集群中潜在的问题，并生成健康检查报告。由两部分组成：FusionCare和SysChecker。其中FusionCare提供对租户面节点巡检功能，SysChecker提供对管控面FusionInsight的巡检功能。</li><li>适用场景：适用于集群安装后，对集群的服务状态，节点硬件状态，操作系统配置等进行检查。</li><li>常用巡检功能：日常巡检、升级前巡检、扩容前巡检、深度巡检</li></ul></li><li>HCS形态巡检工具：<ul><li>工具介绍：Inspect插件，是为了技术支持和维护工程师提供的HCS集群界面化健康检查工具，能够检查集群相关节点，服务的健康状态，提前发现集群中的潜在问题，并生成健康检查报告。同时该插件与集群版本解耦，使用前可直接升级到最新版本。</li><li>使用场景：适合工程师在集群日常维护、升级、扩容、温备等操作前快速对集群软件、硬件、配置等进行健康检查。</li><li>日常巡检功能： 日常巡检、升级前巡检、扩容前巡检、温备前巡检、深度巡检。</li></ul></li><li>运维工具：概述：DWS提供运维工具包，针对现网高频问题和应急场景，汇总成工具包，目标是通过工具一键收集定位定界信息，用于加快问题处理和提升运维效率。<ul><li>gs_dbmonitor:<ul><li>功能描述：周期采集集群SQL级的运行状态：DDL探针，活跃语句，SQL排队，作业等待，内存使用，主备同步等信息</li><li>使用场景：实时监控系统运行状态：实时查询集群的SQL作业运行情况，实时查看异常指标，便于进一步分析集群运行情况盘点：汇总历史变化信息并转化为图表形式来分析业务和负载变化趋势，可用于系统健康度评估和业务变化分析</li></ul></li><li>gs_ccnqueue:<ul><li>功能描述：排查ccn排队作业是否有异常，输出结果包括排队的作业数，可用内存数，剩余内存数，正在执行的作业的估算内存大小，执行时间，执行用户，执行的SQL等信息</li><li>使用场景：有大量的作业在waiting in ccn queue, 查看正在运行的作业和排队作业的资源消耗情况</li></ul></li><li>gs_cpuwatcher:<ul><li>功能描述：查找集群中引起cpu高的业务SQL</li><li>使用场景：系统CPU使用率高，使用本工具抓取占用cpu高的业务SQL</li></ul></li><li>gs_memwatcher:<ul><li>功能描述：对集群内的CN&#x2F;DN的实例，进行单实例的内存监控</li><li>使用场景：系统内存&#x2F;动态内存使用率高，使用本工具抓取占用内存高的业务SQL报内存错误memory is temporarily unavailable时排查内存占用情况。监控运行过程中的内存使用率。</li></ul></li><li>gs_iowatcher:<ul><li>功能描述：监控单CN&#x2F;DN上业务SQL的IO使用情况，如果需要监控多个，可以起多个线程。</li><li>使用场景：系统IO使用率高，使用本工具抓取占用IO高的业务SQL</li></ul></li><li>gsar:<ul><li>功能描述：对指定网卡流量，重传，丢包等指标监测，以便快速定位网络问题。</li><li>使用场景：通过报错等问题，定位到可能有网络故障时，使用此工具对网络进行排查。</li></ul></li><li>gs_oscoreconfig,gs_coreanalyze<ul><li>功能描述：单节点配置os core,关闭Bbox core；解析gaussdb产生的core文件，并打印出语句，执行用户等相关信息；展示当前目录下的所有已解析的core文件结果；压缩存放解析结果的core文件夹。</li><li>使用场景：当集群内gaussdb进程产生core文件后，使用该工具分析core文件堆栈，用于分析进程异常退出的原因</li></ul></li><li>gs_diskusedcheck<ul><li>功能描述：对集群内所有磁盘的使用率进行筛选，识别超过阈值的磁盘。对单DN或单磁盘下所有DN进行磁盘使用率检查，覆盖以下场景：专有目录的大小，大文件检测</li><li>使用场景:磁盘告警或集群只读时，可使用此工具进行排查。当磁盘使用率出现倾斜时，可使用此工具进行排查。业务和负载变化，可用于系统健康度评估的参考。</li></ul></li><li>gs_tablescan:<ul><li>功能描述：快速校验集群内表文件是否有损坏或者表查询异常。</li><li>使用场景：发现存在表数据文件损坏后，使用此工具进行全库排查（磁盘故障，全局排查，数据校验）</li></ul></li></ul></li><li>TOPSQL:<ul><li>概述：TopSQL是DWS数据库内置的一款功能十分强大的性能分析工具。在生产环境中，难免会出现一些突发情况，导致查询语句出现异常中断、阻塞时间长等情况，如果当时没能记录下来，那么事后就要投入更多的人力以及时间成本，去对错位进行定位和解决，有时还往往定位不到错误的地方。为了解决这样的窘迫的情况，DWS开发了TopSQL功能，对运行中的语句记录（实时TopSQL），对运行完成的语句进行记录（历史TopSQL）</li><li>实时TopSQL：<ul><li>前提条件：<ul><li>guc参数enable_resource_track为on（默认为on）</li><li>guc参数resource_track_level为query&#x2F;perf或者operator(默认为query)</li><li>监控作业的类型为：优化估算的执行代价大于或等于resource_track_cost取值的作业。</li><li>Cgroups功能正常加载，可通过gs_cgroup -P查看控制组信息。</li><li>GUC参数enable_track_record_subsql控制是否记录存储过程、匿名块内部语句。</li><li>在上述条件中，enable_resource_track为系统级参数，用于设置是否开启资源监控功能。resource_track_level为session级参数，可以对某个session的资源监控级别进行灵活设置。</li></ul></li></ul></li><li>实时TopSQL常用视图：<ul><li>gs_session_cpu_statistics:查询实时CPU信息</li><li>gs_session_memory_statistics:查询实时memory信息</li><li>gs_wlm_session_statistics:查询当前cn的实时资源</li><li>pgxc_wlm_session_statistics：查询所有cn的实时资源</li><li>gs_wlm_operator_statistics：查询当前CN作业算子执行实时资源信息</li><li>pgxc_wlm_operator_statistics：查询所有CN作业算子执行实时资源信息</li><li>pg_session_wlmstat：查询当前用户执行作业正在运行时的负载管理信息。</li><li>pgxc_wlm_workload_records:动态负载功能开启，enable_dynamic_workload 为on时，该视图有效，查询当前用户在每个CN上，作业执行时的状态信息。</li></ul></li><li>历史TopSQL：<ul><li>前提条件：<ul><li>guc参数enable_resource_track为on（默认为on）</li><li>guc参数resource_track_level为query，perf或operator（默认为query）</li><li>guc参数enable_resource_record为on（默认为on）</li><li>guc参数resource_track_duration小于作业执行时间（默认为60s）</li><li>guc参数enable_track_record_subsql控制是否记录存储过程、匿名块内部语句（默认为on）</li><li>guc参数resource_track_subsql_duration小于存储过程中内部语句的执行时间（默认为180s）</li><li>监控作业类型为:资源监控实时视图中，记录的作业结束时的执行时间大于或等于resource_track_duration的作业</li><li>Cgroups功能正常加载，可通过gs_cgroup -P查看控制组的信息。</li></ul></li></ul></li><li>历史TopSQL常用视图：<ul><li>gs_wlm_session_history:查询当前cn最近执行作业结束后的负载记录</li><li>pgxc_wlm_session_history：查询所有cn最近执行作业结束后的负载记录</li><li>gs_wlm_session_info:数据表，查询当前cn作业执行结束后的负载记录。要查到历史记录，必须保证enable_resouce_record为on</li><li>pgxc_get_wlm_session_info_bytime:函数，对视图pgxc_wlm_session_info进行筛选查询，要查到历史记录，必须保证enable_resouce_record为on。在统计数据量很大的场景中，建议使用该函数进行查询。</li><li>gs_wlm_operator_histroy:查询当前cn作业算子最近执行资源信息。要查到记录，必须保证resource_track_level 为operator</li><li>pgxc_wlm_operator_history:查询所有cn作业算子最近执行资源信息。要查到记录，必须保证resouce_track_level为operator</li><li>gs_wlm_operator_info：数据表，查询当前cn作业算子历史执行资源信息。要查到记录，必须保证resource_track_level为operator和enable_resource_record为on</li><li>pgxc_wlm_operator_info:查询所有CN作业算子历史执行资源信息。要查到记录，必须保证resource_track_level为operator和enable_resource_record为on。</li></ul></li></ul></li></ol><h3 id="运维监控"><a href="#运维监控" class="headerlink" title="运维监控"></a>运维监控</h3><ol><li>华为云stack DWS 微服务组件：<ul><li>Controller：整个DWS的后台组件</li><li>Monitor:ECF公共组件，主要功能：集群实例的状态监控，告警&#x2F;事件上报</li><li>Event:ECF公共组件，主要功能：ECF事件&#x2F;告警管理中心，支持向SMN，OC，CTS发送事件和告警。</li><li>ECFAgent:部署在集群节点上的代理，主要功能：接收告警和事件，监控集群状态</li><li>DMSAgent:部署在集群节点上的代理，主要功能：采集数据库的资源监控信息和数据库所在节点的系统资源信息。</li></ul></li><li>告警：<ul><li>告警配置：DWS提供告警配置功能，用于提前发现集群潜在问题和故障，告警内容涵盖集群故障、资源过载、性能降级等多种故障场景，建议客户根据业务场景配置合理的告警阈值和规则，建议对紧急告警，进行短信和电话配置，便于及时关注集群告警。</li></ul></li><li>监控：<ul><li>监控上报：集群侧节点上有定时任务采集，数据仓库服务节点监控信息每隔1分钟采集一次，数据仓库整集群监控信息每隔4分钟采集一次，会在目录&#x2F;uploadtocessrc下生成*.json文件，上报成功后会将监控文件存放到uploadtocesbak进行备份，文件备份周期为2天。</li><li>异步的数据XX进程，会将数据给ces服务，OC运维监控平台从ces上获取数据进行处理展示。</li><li>监控主要用于性能问题维护，异步上报监控，监控超过阈值会上报告警，通过监控趋势提前了解集群是否需要扩容，以及潜在的性能问题风险，当前DWS已有的性能监控指标粒度比较粗，无法精确到节点上具体的性能指标监控详情，新开发的DMS功能会有比较细粒度的监控后续的监控功能会以新开发的DMS为主，会进一步完善和丰富DMS的监控功能，DWS在630就已有的性能监控会保持现状，不会有大的需求改动。</li></ul></li></ol><h3 id="业务应急"><a href="#业务应急" class="headerlink" title="业务应急"></a>业务应急</h3><ol><li>常见故障场景和应急手段：<ul><li>整体性能慢：通过应急“三板斧”，快速恢复集群性能</li><li>CPU使用率高：找到CPU占比高的语句，对相关业务进行应急查杀或者资源限制，事后进行SQL优化。</li><li>IO使用率高：找到IO占比高的语句，对相关业务进行应急查杀，事后进行SQL优化</li><li>内存报错：找到内存占比高的语句，对相关业务进行应急查杀或资源限制</li><li>锁冲突报错：找到持锁语句，应急查杀并将锁冲突业务，错峰执行。</li><li>集群只读：找到空间占比高的表或者语句，清理空间。</li></ul></li><li>整体性能慢：<ul><li>概念：数据库系统的性能管理在整个业务系统中起着很重要的作用，集群性能管理不当或在硬件、OS等故障后，容易出现集群性能降级，需要及时介入处理避免长时间对业务造成影响</li><li>问题现象：集群整体出现卡慢，业务常规查询，建表等语句劣化，性能探针出现劣化</li><li>问题影响：集群整体性能降级，造成跑批延迟，影响业务时效性</li><li>处理套路：判断性能瓶颈点（硬件&#x2F;资源&#x2F;内部等待事件等）,针对性能瓶颈点快速恢复。</li></ul></li><li>CPU使用率高：<ul><li>概念：CPU指标表示当前集群计算资源的使用情况，一般建议CPU使用率维持在60%以下，防止在主备切换后出现CPU瓶颈；当CPU使用率超过80%后，不同业务之间会有比较严重的CPU争抢，此时建议通过错峰或扩容等手段降低CPU负载。当出现CPU使用率异常突增时，会导致集群整体性能劣化，需要及时处理。</li><li>问题现象：集群CPU使用率突增，或CPU水位长期维持在80%以上，出现CPU过载</li><li>问题影响：集群整体性能降级，造成跑批延迟，影响业务时效性</li><li>处理套路：找到占用CPU高的语句或用户，针对该语句或用户处理。</li></ul></li><li>IO使用率高：<ul><li>概念：IO指标表示当前集群读写性能，对于机械硬盘应重点关注该指标，当机械盘IO使用率超过90%后，业务可能会有大量wait io出现，频繁IO等待导致集群整体性能降级。</li><li>问题现象：集群IO使用率突增，或IO使用率长期在90%以上，出现IO过载</li><li>问题影响：集群整体性能降级，造成跑批延迟，影响业务时效性</li><li>处理套路：找到占用IO高的语句或用户，同步排查硬件故障情况，针对IO占用高的语句或用户进行处理</li></ul></li><li>内存报错：<ul><li>概念：业务语句在执行过程中，大部分操作都是在动态内存中完成的，当SQL中间结果集过大或当前并发过高时，会导致集群动态可用内存不足，出现memory is temporarily unavailable报错</li><li>问题现象：集群动态内存使用率突增，出现动态内存不足告警，部分业务出现内存不足报错。</li><li>问题影响：部分业务报错</li><li>处理套路：找到占用内存占用高的语句或用户，针对内存占用高的语句或用户进行处理。</li></ul></li><li>锁冲突报错：<ul><li>概念：当对表进行查询&#x2F;DDL&#x2F;DML等任何操作时，数据库会对表进行加锁操作，在事务结束时释放。常规锁按照粒度可以分为8个等级，各个操作对应不同的锁级别，级别不同，阻塞程度不同。当互相冲突的语句执行时，后执行的语句会进入锁等待队列，表现为语句被阻塞。例如，对表进行长查询时，truncate语句会被阻塞，进入锁等待队列，表现为truncate语句执行卡住。</li><li>问题现象：表相关的业务阻塞，执行慢或出现锁等待超时报错</li><li>问题影响：部分业务报错或该表相关的业务被阻塞</li><li>处理套路：找到持锁语句，应急查杀或停用持锁业务。</li></ul></li><li>集群只读：<ul><li>概念：当集群某个磁盘完全写满，达到100%时，此时该盘对应的实例进程无法进行数据写入和xlog日志写入，并且可能导致对应的备机实例也写满，此时集群会出现不可用状态。为了避免集群不可用，当集群磁盘使用率到达90%时，会触发集群只读保护，此时只能进行查询，无法进行写入，这种情况下需要及时清理磁盘空间，将磁盘空间使用率降低到安全水位（建议80%）以下</li><li>问题现象：集群进入只读模式，写入相关的业务出现read only报错</li><li>问题影响：增删改业务报错</li><li>处理套路：找到触发只读的目录，根据对应的目录内容，找到大表或触发语句。</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> 数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GaussDB(DWS) </tag>
            
            <tag> 数据库 </tag>
            
            <tag> 数据仓库 </tag>
            
            <tag> 数据 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GaussDB(DWS)数据库-性能调优和开发实践篇</title>
      <link href="/2025/08/04/GaussDB(DWS)%E6%95%B0%E6%8D%AE%E5%BA%93-%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%92%8C%E5%BC%80%E5%8F%91%E5%AE%9E%E8%B7%B5%E7%AF%87/"/>
      <url>/2025/08/04/GaussDB(DWS)%E6%95%B0%E6%8D%AE%E5%BA%93-%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%92%8C%E5%BC%80%E5%8F%91%E5%AE%9E%E8%B7%B5%E7%AF%87/</url>
      
        <content type="html"><![CDATA[<h3 id="性能调优"><a href="#性能调优" class="headerlink" title="性能调优"></a>性能调优</h3><ol><li>定义：通过优化数据库系统的配置及SQL查询，以提高数据库性能和效率的过程。目的是消除性能瓶颈、减少响应时间、提高系统吞吐量和资源利用率，降低业务成本，从而提高系统稳定性，给用户带来更大的价值。</li><li>SQL执行计划解析, 执行计划命令：<ul><li>EXPLAIN VERBOSE + SQL语句(select&#x2F;update&#x2F;insert&#x2F;delete&#x2F;merge into&#x2F;create table as):获取详细执行信息，SQL语句不会真正执行 verbose</li><li>EXPLAIN PERFORMANCE+ SQL语句(select&#x2F;update&#x2F;insert&#x2F;delete&#x2F;merge into&#x2F;create table as):获取详细执行信息。performance</li></ul></li><li>verbose选项下打印详细计划信息中，plan information信息包括：<ul><li>E-rows:算子估算输出行数</li><li>E-distinct:单DN上算子distinct估计值</li><li>E-memory:DN上每个算子估算的内存使用量，只有DN上执行的算子才会显示。某些场景会在估算的内存使用量后面使用括号，表示该算子在内存资源充足下的自动扩展内存上限。</li><li>E-width:每个算子输出元祖的估算宽度</li><li>E-costs:每个算子估算的执行代价</li></ul></li><li>performance选项下打印执行信息中，和verbose相比，新增的相关信息：<ul><li>A-time：算子实际执行时间，在DN上输出由[]括起来的，由逗号分割的两个值，分别表示算子在不同DN上执行的最短时间和最长时间。</li><li>A-row：算子实际输出元祖数，是各个DN上算子输出元祖数总和。</li><li>Peak memory：算子消耗内存峰值，在DN上输出由[]括起来的，由逗号分割的两个值，分别表示算子在不同DN上执行的最小内存消耗和最大内存消耗。</li><li>A-width：算子每行元祖实际宽度，仅涉及重内存使用算子。</li></ul></li><li>performance选项打印执行中的相关信息：<ul><li>plan information:以表格形式显示整个执行过程中每个算子的执行概要信息。</li><li>SQL Diagnostic information:SQL自诊断信息<ul><li>verbose可诊断：统计信息未收集、分区不剪枝、SQL不下推</li><li>performance可诊断：统计信息未收集、分区不剪枝、SQL不下推、HashJoin中大表做内表、大表等值连接使用Nestloop、大表Broadcast、数据倾斜、索引不合理。</li></ul></li><li>predicate information:算子计算信息，如scan的filter条件，join的join条件</li><li>Datanode information:算子在每个DN上执行的详细信息，包括执行时间、CPU、Buffer的使用情况。<ul><li>执行时间（actual time）:如果这个值在各DN上存在较大差异，可初步判断存在计算倾斜（各DN上承担计算量差异过大）</li><li>输出元祖数（rows）:结合执行时间进一步佐证是否存在计算倾斜。</li><li>CPU执行cycle:在算子执行期间，执行所消耗的CPU cycle</li><li>Buffer命中率（hit）:针对Scan算子做数据扫描时。从性能角度看，buffer命中率越高越好，这需要增大集群的shared_buffers(行存)、cstore_buffers(列存)的配置参数。</li></ul></li><li>User Define information:性能profile信息，算子执行过程中的，关键动作性能打桩信息。</li><li>Memory information:算子执行过程中的内存消耗信息。包括内存信息和下盘信息。</li><li>Query Summary:query执行的概要信息。这部分打印总的执行时间和网络流量，包括各DN上初始化和结束阶段的最大最小执行时间、CN上的初始化、执行、结束阶段的时间、以及当前语句执行时系统可用内存、语句估算内存等信息。</li></ul></li><li>性能分析主要关注Plan information&#x2F;SQL diagnostic ioformation&#x2F;predicate information&#x2F;Datanode information这4部分信息。在大集群下，对复杂SQL，建议使用explain analyze 打印概要的实际执行信息，避免打印各个节点信息太多导致执行计划过长</li><li>执行计划类型：3种<ul><li>FQS计划（fast query shipping）<ul><li>CN直接将原语句下发的DN,各个DN单独执行，并将执行结果在CN上汇总。</li></ul></li><li>Stream计划：<ul><li>算子形态：GATHER&#x2F;REDISTRIBUTE&#x2F;BROADCAST</li><li>CN根据原语句先生成执行计划，再将计划下发到DN执行，各DN执行过程中使用Stream算子进行数据交互。</li></ul></li><li>Remote Query计划<ul><li>CN生成执行计划后，将部分原语句下发到DN,各DN单独执行，执行后将结果发送给CN，CN执行剩余计划。</li></ul></li><li>Explain执行计划:<ul><li>ANALYZE | ANALYSE :显示实际运行时间和其他统计数据</li><li>VERBOSE:显示有关计划的额外信息，例如输出列信息。</li><li>COST: 包括每个规划节点的估计总成本，以及估计的行数和每行的宽度。</li><li>CPU: 打印CPU的使用情况信息。</li><li>DETAIL:打印DN上的信息。</li><li>NODES:打印query执行的节点信息</li><li>NUM_NODES:打印执行中的节点个数信息</li><li>BUFFERS:包括缓冲区的使用情况信息</li><li>TIMING:包括实际的启动时间和花费在输出节点上的时间信息。</li><li>PLAN:是否将执行计划存储在plan_table中。</li><li>FORMAT:指定输出格式</li><li>GENERIC:显示将语句中的常数替换为参数后生成的generic计划</li></ul></li></ul></li><li>TopSQL：<ul><li>定义：将SQL的排队信息、运行信息（耗时、CPU、内存、IO、网络、空间）记录到一张系统表中，即作业级监控。</li><li>功能：<ul><li>确定影响数据库性能资源最密集的SQL查询</li><li>监控和跟踪SQL查询，随时间推演的性能变化</li><li>分析查询执行计划，以确定潜在的优化</li></ul></li><li>分类:实时&#x2F;历史, 当前CN&#x2F;全部CN,级别都是query<ul><li>实时当前CN:GS_WLM_SESSION_STATISTCS</li><li>实时全部CN:PGXC_WLM_SESSIOIN_STATISTICS</li><li>历史当前CN:GS_WLM_SESSION_INFO</li><li>历史全部CN:PGXC_WLM_SESSION_INFO</li></ul></li></ul></li><li>历史TopSQL：<ul><li>Topsql主要是通过视图进行承载，按照级别分为query&#x2F;perf&#x2F;operator</li><li>query:SQL语句的计划信息，类似于explain输出信息，记录到Topsql中。</li><li>perf:包含实际执行时间和执行行数的计划信息，类似于explain analyze输出信息，记录到Topsql中。</li><li>operator:不仅会把包含实际执行时间和执行行数的信息记录到TopSql中，还会把算子级别执行信息，记录到Topsql中.</li></ul></li><li>历史TopSQL视图记录了作业运行结束时的资源使用情况、运行状态信息和性能告警信息。<ul><li>分类：级别（query&#x2F;perf+operator）+当前CN&#x2F;全部CN</li><li>query&#x2F;perf级别当前CN: GS_WLM_SESSION_INFO</li><li>query&#x2F;perf级别全部CN: PGXC_WLM_SESSION_INFO</li><li>operator级别当前CN:GS_WLM_OPERATOR_INFO</li><li>operator级别全部CN:PGXC_WLM_OPERATOR_INFO</li></ul></li><li>TopSQL配置GUC参数：<ul><li>实时TopSQL参数：运行中的语句记录<ul><li>enable_resource_track(ON):资源实时监控开启，实时TopSQL总开关，关闭后实时TopSQL不再记录，不会出现在历史TopSQL中。</li><li>resource_track_cost(0):执行代价阈值，对当前会话语句进行资源监控的，最小执行代码。</li><li>resource_track_level(query):资源监控等级，当前会话的资源监控等级，默认为query级别。</li></ul></li><li>历史TopSQL参数：运行完成的语句记录<ul><li>enable_resource_record(on):资源监控记录归档，开启后，执行结束的记录会分布归档到相应INFO视图，CN和DN都需要设置上。</li><li>resource_track_duration(60s):作业运行时间阈值，实时TopSQL中记录的语句执行结束后，进行历史转存的最小执行时间，其判断包含排队时间和运行时间，当排队时间+运行时间&gt;resource_track_duration时，Topsql历史视图会记录作业信息。当执行完成的作业，其执行时间不小于此参数值时，作业信息会从实时视图（statistics为后缀的视图）转存到相应的历史视图。</li><li>topsql_retention_time(30天):历史数据老化周期，历史TopSQL当前CN视图（GS_WLM_SESSION_INFO、GS_WLM_OPERATOR_INFO）中数据保持时间，单位为天。</li></ul></li><li>数据流转过程：作业运行-&gt;运行信息记录实时Topsql-&gt;作业运行结束-&gt;执行信息记录历史Topsql-&gt;结束。</li></ul></li></ol><h3 id="SQL调优"><a href="#SQL调优" class="headerlink" title="SQL调优"></a>SQL调优</h3><ol><li>调优原则：也是唯一原则，资源利用最大化原则.其中资源包括CPU、内存、磁盘IO、网络IO,SQL语句应当尽量高效、节省资源开销，即以最优的执行方式实现功能。SQL语句应当充分利用资源，实现性能极致。</li><li>调优分类和流程：先静态调优，再动态调优<ul><li>静态调优：根据硬件资源和客户的业务特征，确定集群部署方案和表定义。集群部署方案和表定义一旦确定，后续改动的代价会比较大。</li><li>动态调优：根据SQL语句执行的实际情况，采取针对性干预SQL执行计划的方式，提升性能。采取的手段包括：SQL改写，GUC参数干预，Plan Hint</li></ul></li><li>静态调优手段(5种):表定义、存储类型、分布列、局部聚簇、分区表<ul><li>表定义的目的：<ul><li>表数据均匀分布在各个DN，选择合适分布列避免数据分布倾斜，防止单个DN数据过多导致集群有效容量下降。</li><li>表Scan压力均匀分布在各个DN,避免单DN的scan压力过大，形成scan的单节点瓶颈。避免把基表上的等值filter中的列作为分布列。</li></ul></li><li>存储类型：<ul><li>用途：客户业务属性决定表的存储类型；存储类型决定存储格式，进而影响I&#x2F;O操作行为。</li></ul></li><li>分类：<ul><li>行存：适合点查询（返回记录少，基于索引的简单查询），增删改比较多的场景</li><li>列存：统计分析类查询（group, join 多的场景），即席查询（查询条件列不确定，行存无法确定索引）</li></ul></li><li>分布列：<ul><li>分布列选择原则：列值应比较分撒，以便数据能够均匀分布都各个DN上。尽量不要选择存在常量等值过滤条件的列，避免DN剪枝后Scan集中到一个DN上。选择查询中的连接条件为分布列，以便join任务能够下推到DN中执行，而且可以减少DN间的通信数据量，建议选择join-condition或者group by 列为分布列。根据以上原则尽量根据业务特征选择hash分布方式，无法确定时可以选择roundrobin分布：</li></ul></li><li>分布方式：复制（Replication）、哈希（Hash）、轮询（RoundRobin）<ul><li>复制Replication:在集群中的每个DN实例上都有一份全量表数据。存在数据冗余。适用于小表、维表。join操作可减少重分布造成的网络开销。</li><li>哈希（Hash）：数据通过hash方式散列到集群的所有DN实例上。适用于数据量大的表。读写数据可充分利用各个节点IO资源，提升读写速度。</li><li>轮询（RoundRobin）：数据通过轮询方式发放到集群内所有DN实例上。适用于数据量大的表，而且各列都有严重倾斜的表。读写数据可充分利用各个节点IO资源，提升读写速度。</li><li>分布方式分析和调整<ul><li>判断数据是否存在存储倾斜：table_distribution()，不同DN的数据量，相差5%以上即可视为倾斜，相差10%以上，建议调整分布列。</li><li>在线判断数据列是否存在倾斜：table_skewness()，</li><li>调整分布列语法：<code> bash alter table table_name distribution by hash()/replication/roundrobin;</code></li></ul></li></ul></li><li>局部聚簇（Partial Cluster Key，简称PCK）：<ul><li>定义：列存储下的，一种通过min&#x2F;max稀疏索引，实现基表快速扫描的，一种索引技术。</li><li>优化原理：入库时进行局部排序，来换取查询性能</li><li>使用约束:列存表，一个列存表只能创建一个PCK。适用数据类型包括整型、时间类型和字符串类型。对于字符串数据类型，如果当前库的collate不为C，则只对表达式col &#x3D; Const起大加速查询的效果</li><li>使用场景：<br>  -业务特征：大表大批量数据导入，每次导入数据量远大于DN数*6W。<br>  -基表存在大量形如col op Const约束，其中col为列名，const为常量值，op为操作符&#x3D;，&lt;, &gt; ,&lt;&#x3D;, &gt;&#x3D;<br>  -选择选择度比较高的简单表达式的列，建立PCK</li><li>使用方法：在创建表的时候，指定PCK约束。在alter table语法中添加PCK约束（只对后续导入数据生效）</li></ul></li><li>分区表<ul><li>定义：把逻辑上的大表按照某种策略划分为几块物理块进行存储，逻辑上的大表成为分区表，每个物理块为一个分区。</li><li>原理：在查询时，通过分区剪枝技术来尽可能减少底层数据扫描。</li><li>适用场景：数据规模上的大表，业务特征为通过剪枝缩小查询范围。</li><li>优势：改善查询性能、增强可用性、方便维护。</li><li>分区键选择：将数据可以均匀映射到各个分区的列，常见分区键为时间列。</li><li>分类：range分区和list分区</li></ul></li></ul></li><li>执行计划：<ul><li>执行计划三要素：统计信息、优化器、配置参数<ul><li>统计信息（表的数据特征）：包括表的元祖数，字段宽度、null记录比率，distinct值，MCV值（most common value）、hb值（直方图，数据分布概览区间）</li><li>优化器（Cost-Based Optimization,CBO，基于代价的优化）：数据库根据大量的表数据特征，结合代价计算模型，通过代价估算，输出估算后的最优执行计划。其中统计信息是查询优化的核心输入，准确的统计信息可以帮助优化器选择最合适的查询计划。</li><li>配置参数：GUC参数和HINT信息。配置参数直接干预优化器的路径选择。</li><li>统计信息收集：使用analyze语法来收集整个表或者表的若干列统计信息。</li><li>操作：大批量数据导入、更新、删除之后，及时analyze.</li></ul></li><li>执行计划流程：<ul><li>词法&amp;语法解析：按照约定SQL语句规则，输入SQL语句从字符串转化为格式化结构（Stmt）</li><li>语义解析: 格式化结构转化为数据库可识别对象</li><li>查询重写：根据规则，将语义解析的输出，等价转化为执行上更为优化的结构。</li><li>查询优化：根据“查询重写”的输出和数据库内部的统计信息，规划SQL语句的具体执行方式。</li><li>查询执行：根据“查询优化”规划的执行路径，执行SQL查询语句。</li></ul></li></ul></li><li>动态调优：即执行态调优<ul><li>定义：先跑query，判断性能是否满足客户需求，如果不满足，则进一步分析性能瓶颈点，进行针对性优化，重新试跑，一直到满足性能目标为止。</li><li>步骤：<ul><li>判断查询相关表是否已收集统计信息</li><li>判断查询语句是否下推</li><li>收集perfromance信息进行性能分析，并做针对性优化</li><li>SQL改写优化</li></ul></li><li><strong>统计信息收集</strong>：对统计信息前后的执行计划，做对比分析<ul><li>E-rows：在没有收集统计信息的执行计划中，估计值E-row会比实际值小</li><li>执行计划：在没有收集统计信息的执行计划中，出现两个低效的Nest loop算子。</li></ul></li><li><strong>查询语句下推</strong>：<ul><li>执行计划类型：并行计算能力是DWS数据库的性能优势</li><li>优化器在分布式框架下有三种执行规划策略：<ul><li>下推语句计划：CN发送查询语句到DN直接执行，执行结果返回给CN.计划特征：<em>REMOTE_FQS_QUERY</em></li><li>分布式计划：CN先生成计划树，再发送计划树给DN执行，DN执行完成后，执行结果返回给CN.计划特征：Streaming(type: GATHER)</li><li>不下推计划：CN承担大量计算任务，导致性能劣化。优化器先将部分查询（多为基表扫描语句）下推的DN中执行，将中间结果返回给CN,CN再执行执行计划剩下的部分。执行计划特征：REMOTE_XXX + Coordinator quals</li></ul></li></ul></li><li><strong>不下推分析</strong>：<ul><li>常见不下推原因：含有shippable属性且为false的函数语句不下推。</li><li>问题定位手段：<ul><li>Explain performance&#x2F;Explain verbose：对正在执行的SQL，使用explain performance&#x2F;explain verbose,在输出的自诊断信息（SQL Diagostic information）中会提示具体的不下推原因。</li><li>TopSQL：历史执行信息会记录到系统表中，使用postgres库中的查询视图（历史全部DN的perf级）pgxc_wlm_session_info，获取历史SQL的执行信息，此表中的warning字段会记录对应的SQL语句不下推原因。</li></ul></li></ul></li><li><strong>performance分析</strong><ul><li>explain performance优化：收集query执行信息，分析可能的性能问题，针对性优化</li><li>重点关注信息：<ul><li>算子：耗时占整体执行时间高的算子</li><li>执行信息：DataNode information、Memory information、Targetlist information</li></ul></li><li>算子瓶颈和优化策略：<ul><li>Scan性能瓶颈：基表扫描元组数过多场景：增加索引，使用PCK， 使用分区</li></ul></li><li>性能提升策略：<ul><li>减少实际IO：针对点查询场景：增加索引，使用PCK(列存表)；针对范围查询场景：使用分区（优化IO）</li><li>数据在各个DN分布不均衡场景：调整分布列方式。把Scan压力分散到各个DN上：是指数据倾斜，IO压力分布不均衡，performance信息中各DN扫描时间存在明显差异，优化策略是修改分布列</li></ul></li></ul></li></ul></li><li>Join性能瓶颈：<ul><li>join方式选择不当场景：使用plan hint，增加索引</li><li>join内外表选择不当场景：使用plan hint，改写SQL</li><li>join类型：<ul><li>定义：表链接join，根据特定规则从两个其他表（真实表或者生成表）中派生出的结果集。</li><li>类型：在语法层，内连接（inner join）、外连接（outer join）、交叉连接（笛卡尔积， cross join）。inner是缺省的，left、right、full都是外连接，连接条件在on或using子句中指定。在内置实现支持：半连接（Semi join，in约束转化生成， 匹配上即命中）、反半连接（Anti Join, NOT IN约束转化生成，匹配上即排除）</li></ul></li><li>join性能提升策略：<ul><li>选择高效的join方式：通常情况下，hashjoin较为高效。改写SQL实现hashjoin,可以尝试将不等值join条件转化等值join条件。在部分特定场景下，nestloop+indexScan性能更好</li><li>选择合适的内外表：hashjoin：内表小，外表大，执行更高效。或者使用plan hint 调整内外表顺序。</li></ul></li></ul></li></ol><h3 id="plan-hint"><a href="#plan-hint" class="headerlink" title="plan hint"></a>plan hint</h3><ol><li>定义：可直接影响执行计划生成的手段，目的是通过对执行计划的调优，提升查询性能。</li><li>常见hint调优手段：<ul><li>指定scan方法</li><li>指定join方法、join顺序和join时的stream策略</li><li>指定估算行数</li><li>指定重分布过程中的倾斜信息</li><li>配置参数的hint</li></ul></li><li>使用要求：<ul><li>plan hint仅支持在select关键字后面通过如下形式指定。</li><li>可以同时指定多个hint，不同hint信息使用空格分隔。</li><li>配置参数之外的hint 只能hint当前层的计划，对于子查询计划中的hint，需要在子查询的select关键字后面指定hint信息。</li><li>在视图定义时指定hint， 该视图每次被调用时都会使用该hint信息。</li><li>在视图定义时指定hint， 该视图每次被调用时都会使用该hint信息。表只能用单个字符串表示，不能带schema；表如果存在别名，需要优先使用别名来表示该表。</li></ul></li><li>语法格式：<ul><li>在视图定义时指定hint， 该视图每次被调用时都会使用该hint信息。指定scan方法：[no] tablescan|indexscan|indexonlyscan(table [index]): no表示hint的scan方式不使用。table表示hint指定的表，只能指定一个表，如果表存在别名，应该优先使用别名进行hint。index表示使用indexscan或者indexonlyscan的hint时，指定的索引名称，当前只能指定一个。</li><li>在视图定义时指定hint， 该视图每次被调用时都会使用该hint信息。指定join方法：[no] nestloop|hashjoin|mergejoin(table_list):no表示hint的join方式不使用。table_list是hint表集合的字符串，中间不允许出现括号指定join的优先级。<ul><li>仅指定join顺序，不指定内外表顺序：leading(join_table_list)</li><li>同时指定join顺序和内外表顺序，内外表顺序仅在最外层生效：leading((join_table_list))</li></ul></li><li>在视图定义时指定hint， 该视图每次被调用时都会使用该hint信息。指定估算行数：rows(table_list #|+|-|* const):<ul><li>支持#，+，-，*四种操作符，#表示直接使用后面的行数，替换优化器中的估算行数，+、-、*表示对原来估算的行数进行加减乘操作。</li><li>运算后的行数最小值为1行。table_list为hint对应的单表或者多表join结果集，与join的hint中的table_list相同。</li><li>const可以是任意非负数，支持科学计数法</li><li>支持绝对值和相对值的hint，常用于多表的join时，中间结果集估算表不准的场景。</li></ul></li><li>在视图定义时指定hint， 该视图每次被调用时都会使用该hint信息。join顺序和join时的stream策略：[no] broadcast|redistribute(table_list):no表示hint的stream方式不使用。table为进行stream操作的单表或者多表join结果集。<ul><li>stream hint 和join hint配合使用，先hint明确join顺序，然后hint明确中间结果集的数据流动方式。</li></ul></li></ul></li></ol><h3 id="SQL改写"><a href="#SQL改写" class="headerlink" title="SQL改写"></a>SQL改写</h3><ol><li>相关子链接改写：<ul><li>场景：子查询和子链接性能较差。大部分场景，可提升为join进行优化；小部分场景，需要用户改写SQL进行优化。</li><li>改写策略：在语义等价前提下，将子链接和子查询的查询语句，提升到外层查询进行关联查询。</li></ul></li><li>join条件改写：等值join条件的join列增加非空过滤条件<ul><li>场景：等值join，而且join列存在大量的null</li><li>优化原理：null值和任何值比较的结果都是null，而且通过给关联列添加is not null，降低基表扫描输出的数据量，从而减少参与join运算的数据量</li></ul></li><li>not in改写：not in 转为not exists<ul><li>场景：子链接输出列上不存在null值，或者逻辑判断语义上不需要比较null值。</li><li>优化原理：只输出where条件为true的结果。null 和任何值的比较操作都是null。null和bool类型的逻辑运算。</li></ul></li></ol><p>基于公开来源信息, 学习资源来自<a href="https://connect.huaweicloud.com/courses/learn/Learning/sp:cloudEdu_?courseNo=course-v1:HuaweiX+CBUCNXBC006+Self-paced&courseType=1">华为云GaussDB(DWS)数据库官网</a></p>]]></content>
      
      
      <categories>
          
          <category> 数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GaussDB(DWS) </tag>
            
            <tag> 数据库 </tag>
            
            <tag> 数据仓库 </tag>
            
            <tag> 数据 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GaussDB(DWS)数据库-湖仓一体篇</title>
      <link href="/2025/08/04/GaussDB(DWS)%E6%95%B0%E6%8D%AE%E5%BA%93-%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93/"/>
      <url>/2025/08/04/GaussDB(DWS)%E6%95%B0%E6%8D%AE%E5%BA%93-%E6%B9%96%E4%BB%93%E4%B8%80%E4%BD%93/</url>
      
        <content type="html"><![CDATA[<hr><h2 id="湖仓一体"><a href="#湖仓一体" class="headerlink" title="湖仓一体"></a>湖仓一体</h2><p>湖仓一体：lake house,其出发点是通过数据仓库和数据湖的打通和融合，让数据流动起来，减少重复建设。<br>lake house架构最重要的一点，是数据仓库和数据湖的数据&#x2F;元数据无缝打通和自由流动。湖里的“显性价值”数据可以流到仓里，甚至可以直接被数据仓库使用；而仓里是“隐性价值”数据，也可以流到湖里，低成本长久保存，供未来的数据挖掘使用。</p><h2 id="湖仓介绍"><a href="#湖仓介绍" class="headerlink" title="湖仓介绍"></a>湖仓介绍</h2><h3 id="数据湖"><a href="#数据湖" class="headerlink" title="数据湖"></a>数据湖</h3><ol><li>数据湖理解<ul><li>传统用户：以hadoop集群为主，满足支持所有结构化、半结构化、无结构化的数据存储即为数据湖</li><li>云厂商：基于对象存储，以S3、OSS、OBS等构建数据底座，进行统一存储。</li><li>大数据互联网：以数据湖三剑客为主（Iceberg、Hudi、Delta   · lake）。它们可以支持比Hive更高层的Upsert、Delete、事务操作等高级特性，能基于Hive进行升级，解决准实时性的问题。</li></ul></li><li>数据湖优势：<ul><li>更好的Table format: 通过支持ACID事务，支持Schema evolution, 能够为用户提供更好的表格式。</li><li>更好的File format: 数据湖在文件格式上支持越来越多的半结构化map、Struct、Json等，并且支持越来越多的索引，进而使文件的查询和存储效率更高，并且在基于列存存储的基础上，支持更多的复杂嵌套结构。</li><li>更低的存储成本、更高的可靠性：使用对象存储，相比于本地磁盘存储、SSD存储或者云盘存储等，可以大幅降低存储成本，并且通过编码的方式能够在降低副本数据量的同时，又能保证高可靠性，可以使用户不用担心底层数据的丢失，从而获得低成本的存储。</li><li>统一的Catalog: 通过统一的catalog，实现统一的元数据管理、权限管理、统计信息管理、入湖管理等。</li></ul></li><li>湖仓融合的价值：<ul><li> 数仓加速：基于数据湖的远程IO成本很高，而且缺少一系列数仓加速手段。早期的数据湖格式多样而且不成熟，索引支持不完善，查询性能有待提升。数据湖主要针对吞吐量的优化，关注低成本和高可靠，不适用于高性能的需求。</li><li> 实时分析：传统的数据湖实时性不够，在Iceberg或者hudi的支持下可能解决分钟级别的时效性，无法解决秒级时效性的问题。</li><li> 高并发查询：对于高并发查询，不管是点查询还是聚合类查询，数仓更加擅长。比如分桶的处理，更精细的裁剪，降低扫描的数据量，提升点查询的效率。另一方面通过物化视图或者cube等相关的预聚合手段，可以提升聚合查询的性能。</li><li> 更完善数据治理：湖仓融合的数据底座，统一主数据和元数据，基于此才有可能做上层统一的数据治理</li><li> 降本增效：简化技术架构、增强整体架构可靠性，降低运维成本。</li></ul></li><li>支持数据格式：<ul><li>文本类型：支持text、CSV，高性能导入导出，支持指定分隔符（delimiter）、换行符（eol）、编码（encoding）,以及多种容错方式处理、错误表等</li><li>列存存储格式：高性能列存存储格式，用于大数据环境中高效存储和查询数据，支持多种压缩算法、编码方式，并且兼容多种引擎。</li><li>Parquet&#x2F;ORC：融合查询，复杂类型查询，支持多种压缩算法，支持多种方式写出</li><li>湖格式：hudi是一个功能丰富的存储管理平台，支持构建具有增量数据管道的流式数据湖，针对处理引擎和常规批处理，进行优化；针对数据探索、BI场景的交互式分析能力，进行优化。支持COW、MOR的导入查询，以及增量同步导入。</li></ul></li></ol><h3 id="湖格式（hudi）"><a href="#湖格式（hudi）" class="headerlink" title="湖格式（hudi）"></a>湖格式（hudi）</h3><p>hudi是一个功能丰富的存储管理平台，支持构建具有增量数据管道的流式数据湖，针对处理引擎和常规批处理，进行优化；针对数据探索、BI场景的交互式分析能力，进行优化。<br>关键能力：变更数据、实时性、数据事务、并发性、多版本能力、存储优化、表结构变更、数据管理、生态兼容。</p><ol><li>存储结构：<ul><li>Metadata:以timeline时间线的形式维护对hudi表的各项操作。</li><li>Data:使用两种存储格式存储数据</li><li>ndex:在数据更新时提供更快的老记录查询性能。</li></ul></li><li>表类型：COW和MOR<ul><li>COW(copy on write)：写入操作时进行复制，每次写入操作都会创建新的cow表，并将原表覆盖。COW表的主要优点是可以减少内存占用和提高写入性能，适合频繁进行写入操作的场景，列如批量更新、数据批量插入等。<ul><li>优点:减少内存占用：每次操作都会创建新的cow表，而不是修改原表，可以减少内存占用，提高性能。提高可扩展性，写优化的行存格式：默认为Avro格式， 空间占用较小。</li><li>缺点：需要内存管理：内存中管理原表和cow表之间的关系，因此需要额外的内存管理能力，需要进行内存管理和回收。数据写入性能较差，写优化的行存格式：默认为Avro格式。</li></ul></li><li>MOR(merge on read):读时合并，数据在写入的时候，为了尽可能保证写入速度，不同步做数据的合并操作（可以看做是异步合并），而是以append的方式，将数据写入到avro格式的日志文件中，在我们读取数据时，再启动合并策略。<ul><li>优点：写入性能高：适用于需要高性能写入的场景，如实时数据分析、流式数据处理等。在写入新数据时会将数据写入临时文件，后通过Compaction过程将临时文件合并到基础数据文件中，更新数据文件并删除旧版本。提高可扩展性，写优化的行存格式：默认为Avro格式。</li><li>缺点：资源消耗：需要定期合并整理compact，否则碎片文件较多，数据写入性能较差。读取性能较差：需要将delta log和老数据文件合并，占用空间相对较大</li></ul></li></ul></li><li>外表查询：<ul><li>hudi外表查询：支持hudi两种表类型：COW(性能优化)、MOR(性能较差)；支持hudi两种查询视图：snapshot、incremental</li><li>增量查询：针对hudi增量查询功能，可以通过设置增量查询参数，实现增量查询。</li><li>增量设置的增量参数：通过查询视图来查看已经设置哪些参数，检查是否设置正确：select * from pg_show_custom_settings();</li><li>查询hudi外表属性：读取OBS上hudi数据的hoodie.properties</li><li>查询hudi外表最大时间线：读取OBS上hudi数据最大时间线，也就是最新的提交记录。</li></ul></li><li>自动同步任务：<ul><li>自动同步：<ul><li>单表同步任务，实现外表到内表的数据合并，记录增量同步进度。（列映射，hudi增量commit time同步点）</li><li>智能调度框架，实现定时调用存储过程任务，并进行资源管控调度，提供任务启停、告警等运维能力。</li></ul></li><li>同步任务流程：创建dws内表-&gt;创建dws外表-&gt;设置同步进度-&gt;提交hudi同步任务。</li><li>设置同步进度：select set_hudi_sync_state()</li><li>提交同步任务：select hudi_sync_task_submit()</li><li>查询同步状态：select * from hudi_show_sync_state()</li></ul></li></ol><h3 id="元数据服务"><a href="#元数据服务" class="headerlink" title="元数据服务"></a>元数据服务</h3><ol><li>元数据打通：</li></ol><ul><li>从湖仓两层架构到湖仓一体，统一元数据共享数据；统一元数据，简化数据共享。<ul><li>湖仓两层架构：存算分离，底层数据文件可对上层服务共享。湖和仓的元数据隔离，共享数据仍需要ETL</li><li>湖仓一体（data lakehouse）:在存算分离的基础上，构建统一的元数据层。上层服务通过统一的元数据层，便捷高效地共享数据。</li></ul></li><li>HiveMetaStore:<ul><li>定义：Apache Hive的一个关键组件，一个元数据存储库，用于管理Hive&#x2F;spark表的元数据信息。HiveMetaStore存储了hive表的结构信息，包括表名、列名、数据类型、分区信息和表的位置信息等。HiveMetaStore的主要作用是提供元数据服务，使得hive&#x2F;spark可以对数据进行查询和分析。它还提供了一些API，可以让开发人员通过编程方式访问表的元数据。</li><li>总之，HiveMetaStore是Hive的一个重要组件，它提供了元数据管理和查询服务。</li></ul></li><li>External schema:<ul><li>定义：External schema即外部模式，dws通过创建extrenal schema来对接hivemetastore服务，每次查询主动获取hive&#x2F;spark表对象的元数据，无需dws内核通过create foreign table获取hive&#x2F;spark表的元数据。</li><li>external schema和schema的区别：<ul><li>external schema主要用于和hivemetastore建立连接，获取表对象元数据，在创建external schema时需要指定连接的所需要的各个属性值。</li><li>普通schema在创建后会将schema的信息记录到pg_namespace中，external schema创建后和普通schema一样也会记录在pg_namespace，可以通过pg_namespace中的nsptype字段区分，是external schema还是普通schema。除了存储在pg_namespace中的相关信息外，external schema连接相关的配置信息，都会记录在pg_external_namespace中。</li><li>external schema下不支持创建表对象。对象的创建是在hive或者spark中创建的。external schema 仅用于执行DML操作。</li></ul></li></ul></li></ul><ol start="2"><li>元数据访问：</li></ol><ul><li>创建Server, external schema, sql query查询</li><li>语法解析：语法解析层主要负责解析。当读取到ex.tbl表以后，连接HMS进行元数据查询。</li><li>元数据查询：从HMS中查询元数据信息，该步骤在步骤1中完成。从HMS中读取数据，主要包括列信息、分区信息、分区键信息、分隔符信息等。</li><li>数据查询（针对select）：从DFS存储中获取统计信息文件个数和文件大小，为plan生成提供依据。</li><li>查询重写、查询优化、查询执行。</li><li>查询下发：将元数据随plan下发到DN，DN收到plan以后，会将元数据进行解码后插入到syscache中</li><li>查询执行：DN访问obs对应文件，执行查询。</li></ul><p>基于公开来源信息, 学习资源来自<a href="https://connect.huaweicloud.com/courses/learn/Learning/sp:cloudEdu_?courseNo=course-v1:HuaweiX+CBUCNXBC006+Self-paced&courseType=1">华为云GaussDB(DWS)数据库官网</a></p>]]></content>
      
      
      <categories>
          
          <category> 数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GaussDB(DWS) </tag>
            
            <tag> 数据库 </tag>
            
            <tag> 数据仓库 </tag>
            
            <tag> 数据 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GaussDB(DWS)数据库-集群管理篇</title>
      <link href="/2025/08/04/GaussDB(DWS)%E6%95%B0%E6%8D%AE%E5%BA%93-%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86%E7%AF%87/"/>
      <url>/2025/08/04/GaussDB(DWS)%E6%95%B0%E6%8D%AE%E5%BA%93-%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86%E7%AF%87/</url>
      
        <content type="html"><![CDATA[<h3 id="集群创建与删除"><a href="#集群创建与删除" class="headerlink" title="集群创建与删除"></a>集群创建与删除</h3><ol><li>集群选型<ul><li>产品类型：云数仓、标准数仓、IoT数仓、实时数仓<ul><li>云数仓： 高性价比，支持冷热数据分析，存储、计算弹性伸缩，并按需、按量计价。适用于“库、仓、市、湖”一体化的融合分析业务，适合50节点以内的中小型数据仓库。</li><li>标准数仓：高性能、高扩展、高可用、易运维的企业级数据仓库，支持2048节点、20PB级超大规模数据分析能力。适用于大型企业数仓，上云后体验不变。</li><li>IoT数仓：在标准数仓基础上，提供高效的时序计算和IoT分析能力，支持实时和历史数据关联。适用于物联网、IoT等实时分析场景。</li><li>实时数仓：在大规模数据查询和分析能力基础上，提供高并发、高性能、低时延的事务处理能力。适用于HTAP混合负载场景，“一库两用，生产即分析”，支持单机部署和集群部署两种部署方式。</li></ul></li><li>选择好产品类型后，用户可以根据数据量、业务负载以及性能需求，选择能够支撑业务应用的集群规格和节点数量，CPU数和内存越大，数量越多，存储与计算能力越强。</li><li>刚开始使用DWS服务时，用户也可以先创建一个规格较小的集群，今后随着数据量和业务负载的变化，再自由扩展而不中断业务。</li></ul></li><li>增删CN:<ul><li>当用户的集群创建后，实际需要的CN数量会随着业务需求而发生变化，因此管理CN节点功能的实现，使用户可以根据实际需求动态调整集群的CN数量</li><li>集群创建时默认的CN数量为3，用户可以根据实际发放节点数量，调整CN数量，范围为2~20</li></ul></li><li>删除集群：<ul><li>当用户不再需要使用某个集群时，可以删除该集群。删除的集群无法恢复，同时集群中的用户数据、自动快照也会自动删除，而且无法再访问。删除集群时不会删除手动快照。</li><li>如果集群绑定了弹性IP，建议用户勾选“释放与集群绑定的弹性IP”,将待删除集群的弹性IP资源释放。如果选择不释放，弹性IP将保留，用户可以将该弹性IP绑定到其他DWS集群或者云资源上使用，该弹性IP将仍然按照虚拟私有云（VPC）服务的弹性公网IP计费规则进行计费。</li></ul></li></ol><h3 id="集群监控管理"><a href="#集群监控管理" class="headerlink" title="集群监控管理"></a>集群监控管理</h3><ol><li>节点监控：提供针对当前DWS中所有节点的资源使用情况明细<ul><li>概览：包含节点资源一览图<ul><li>内容：cpu资源使用率，内存资源使用率，数据盘的平均资源使用率，磁盘IO，TCP协议重传率，网络IO</li></ul></li><li>磁盘分页：提供细粒度的磁盘使用情况，说明节点各个磁盘及对应功能（数据盘，日志盘，系统盘）<ul><li>内容：磁盘容量，读速率，写速率，磁盘IO等待时间，磁盘IO服务时间，磁盘IOPS指标。</li></ul></li><li>网络分页：提供节点网卡的详细信息<ul><li>内容：展示名称，网卡状态，接收丢包数，接收速率，发送速率</li></ul></li><li>节点所有页面都可以通过“监控”列查看过去1小时，3小时，12小时，24小时，7天，15天的各个指标变化。</li></ul></li><li>性能监控：提供集群，数据库，节点三个维度相关指标过去一个月的变化趋势，并提供了监控面板供指标集中展示。<ul><li>集群维度的监控指标，包括CPU，内存，磁盘IO，网络IO，集群状态，集群中异常CN数量，SQL堆积数量。</li><li>数据库维度提供了活跃会话数，插入行数，删除行数，修改行数。</li><li>节点维度提供了所有节点相关资源使用情况，并支持对比不同节点的变化趋势。</li><li>集群监控支持查看时间： 过去1小时、3小时、12小时、24小时，7天查看时间，支持自定义时间范围。</li><li>数据库监控支持查看时间：过去1小时，3小时，12小时，24小时。</li></ul></li><li>实时查询：提供了当前系统中的会话和SQL执行情况，并提供了针对会话和查询的查杀功能。<ul><li>实时会话支持查看会话的执行时间，对应的应用名称，接入CN，锁持有状态，锁定对象可以用来排查系统中的长会话或者锁争抢问题。</li><li>实时查询提供了细粒度的查询相关资源使用情况，比如CPU，内存，IO，资源池，查询的排队状态等</li><li>会话和查询都支持根据某一条件查杀问题会话或查询。</li><li>会话：<ul><li>实时会话可以根据多条件过滤查看，当前系统中存在的锁持有的会话，当出现锁争抢是可以根据锁定对象，快速排查相关的执行SQL</li><li>实时会话主要是根据pg_stat_activity和pg_locks信息汇聚上报获取。实时会话默认是启用状态。</li></ul></li><li>查询：<ul><li>实时查询当前仅支持8.1.2以上集群使用，默认不打开，打开需要配置guc参数：enable_resource_track 需要配置为on，resource_track_cost需要根据需求配置，如果配置为0，对所有语句进行监控。</li><li>实时查询主要的是根据pg_session_wlmstat和gs_wlm_session_statistics信息汇聚上报获取。</li></ul></li></ul></li><li>资源池监控：主要反应集群资源池信息，包括CPU使用率，磁盘使用率，内存，语句并发等，可以实时反应集群资源池运行情况。</li><li>SQL诊断：<ul><li>针对已经执行完成的查询中，存在告警信息的SQL进行集中展示。</li><li>SQL诊断对于异常的查询会同步提供SQL语句和执行计划，还有语句的资源使用情况。</li><li>SQL诊断依赖历史查询功能，默认不打开，打开需要配置GUC参数。</li><li>历史查询功能主要是根据pgxc_wlm_session_info信息采集上报获取。</li></ul></li><li>SQL探针<ul><li>SQL探针工具，支持一键执行和定时执行两种探针任务等功能，并可以针对超时的探针SQL提供告警上报信息。</li></ul></li><li>表诊断：提供了集群中数据表，关键运行状态的统计数据和诊断工具。包括：<ul><li>表倾斜率：对于集群中数据表统计信息进行监控分析，展示倾斜率高于5%并且表大小TOP 50的表信息。<ul><li>造成表倾斜率高的原因为不合理的分布列选择，将引发算子计算&#x2F;数据下盘倾斜严重，导致不同的DN的处理压力不同，影响业务性能，并容易造成单DN磁盘使用率过高。</li><li>用户可以通过查询表倾斜率，根据表的大小和倾斜率，对倾斜严重的表重新选择分布列，其中8.1.0及以上集群版本，可以直接通过alter table 语法进行调整表。</li></ul></li><li>表脏页率：对于集群中数据表统计信息进行监控分析，展示脏页率高于50%并且表大小TOP 50的表信息。<ul><li>对于数据表的DML操作将影响数据表数据，导致存在无用的脏数据，过多的脏数据将占据磁盘空间，影响集群可用容量。用户可以通过查询表的脏页率，根据表的大小和脏页率，对较大表和脏页率过高的表进行处理。</li><li>对于脏页率高的表，可以通过手动执行vacuum full操作回收表空间，或者通过“智能运维”操作时执行vacuum full操作。</li></ul></li><li>DDL审核：DDL审核是SQL审核范畴，为了避免不合理的DDL设计影响实际业务运行，该工具会对DDL元数据进行规范性检测，方便用户对潜在的表定义问题提前感知，其结果也可作为性能问题定位的参考数据之一。<ul><li>DDL审核对于审核不通过的数据表，可以通过详情页面查看问题。</li></ul></li></ul></li><li>告警管理<ul><li>包含:查看告警规则，告警规则配置，告警信息订阅功能</li><li>告警规则可以提供过去一周的告警信息统计和告警信息明细，方便用户自行查看租户下的告警。该特性除了以默认值的形式提供一套DWS告警最近实践外，还允许用户根据自己的业务特点，个性化修改告警阈值。</li><li>告警管理通过消息通知服务（Simple Message Notification，SMN）发送DWS告警通知，用户可订阅告警启用通知。</li><li>告警规则配置：<ul><li>当前支持11种告警规则的配置。告警支持启停，只对部分集群生效。当前告警规则是诊断整个租户的告警规则生效。资源类有CPU,磁盘innode,磁盘使用率，磁盘I&#x2F;O时延。业务类有语句堆积告警，语句下盘量过大告警，vacuum full 执行过长告警，资源池队列阻塞告警。工具类有SQL探针执行耗时超阈值。</li></ul></li><li>dws监控系统使用典型场景：<ul><li>磁盘使用率高：配置节点数据盘使用率告警，根据实际需要配置阈值，如果发现该告警上报，则进一步排查系统的磁盘使用情况。</li><li>磁盘只读问题：当发现数据盘使用率高，先查看“工具&#x2F;表诊断&#x2F;表脏页率”，对于脏页率较高的表数据，可以通过vacuum full做清理。如果清理之后可以解决，则可以通过配置智能运维，定位执行vacuum full。如果清理之后磁盘使用率还是较高，则需要重新评估当前系统的规格是否符合业务要求。</li></ul></li></ul></li></ol><h3 id="集群备份恢复管理"><a href="#集群备份恢复管理" class="headerlink" title="集群备份恢复管理"></a>集群备份恢复管理</h3><ol><li>快照：<ul><li>定义：快照是对DWS集群在某一时间点的一次全量数据和增量数据的备份，记录了当前数据库的数据以及集群的相关信息，其中包括节点数量、节点规格和管理员用户名称等。快照创建方式包括手动创建快照和自动创建快照。</li><li>备份：创建快照会将生成的备份文件存储到指定的备份介质中。华为云支持备份介质包括OBS(Object Storage Service)、SFS(Scalable File Service)</li><li>DWS提供免费的快照存储空间，免费容量等于集群储存空间，当快照数据存储空间超过免费空间大小时，超过部分按照OBS的计费规则进行计费。</li><li>手动快照要点：<ul><li>手动快照支持集群级全量快照和schema级快照</li><li>快照级别支持“cluster”和“schema”。schema级别快照依赖版本细粒度备份的特性开关。</li><li>集群名称可选择一个指定集群，只能选择可用状态的集群。</li><li>手动快照创建成功后会一直保存，直到从控制台中将其删除（即使集群删除，手动快照也不会删除。）</li></ul></li><li>自动快照：<ul><li>集群级自动快照采用差异增量备份，第一次创建自动快照为全量备份，以后每间隔一段时间就会做一次全量备份，全量备份作为基础版本。两次全量备份之间都是做增量备份，增量备份记录基于前一次备份所发现的更改。</li><li>集群创建时，自动快照默认处于启用状态。自动增量快照默认为每8小时一次，全量快照每周日执行一次，快照保留期可设置为1-31天，默认为3天。用户也可以根据自身需求设置自动快照策略。</li><li>在策略列表中自动快照开关默认为开启状态，保留天数默认为3天。</li><li>关闭自动快照后，自动删除历史自动快照。</li><li>快照类型设置为全量快照时，快照策略可选一次性和周期性</li><li>快照策略时间需要设置为UTC，同时需要考虑业务所在时区的时差</li></ul></li><li>快照恢复：<ul><li>使用增量快照恢复时，DWS会将最近一次的全量备份到本次快照之间的所有快照，一起用于恢复集群。</li><li>恢复快照到新集群时，恢复时长是由快照备份的数据量所决定的。</li><li>恢复快照时，参数支持重新定义。其他默认参数默认与快照中的备份信息保持一致。</li><li>规格确认无误后，便可执行恢复。待新集群状态变为“可用”，表示快照已恢复成功。</li><li>集群级恢复支持恢复到当前集群。</li><li>细粒度表级恢复：支持恢复单表和多表操作，依赖细粒度备份和细粒度恢复的特性白名单</li></ul></li></ul></li></ol><h3 id="集群容灾管理"><a href="#集群容灾管理" class="headerlink" title="集群容灾管理"></a>集群容灾管理</h3><ol><li>概述：广义上，容灾是一个系统工程，包括所有与业务连续性相关的内容。对于IT而言，容灾是提供一个能防止用户业务系统遭受各种灾难影响破坏的计算机系统。狭义的容灾是指建立两套或多套功能相同的IT系统，互相之间可以进行健康状态监视和功能切换，当主要站点因为意外（如火灾、地震、城市供电中断等）停止工作时，整个应用系统可以利用辅助站点快速恢复，并继续工作。</li><li>容灾目的：容灾的主要目的是，当自然或人为的原因，导致生产系统发生灾难时，能够尽可能地保证业务的连续性。</li><li>容灾和备份的区别 ：<ul><li>容灾主要针对火灾、地震等重大自然灾害，因此生产站点和容灾站点之间，必须保证一定的安全距离；备份主要针对人为误操作、病毒感染、逻辑错误等因素，用于业务系统的数据恢复，数据备份一般是在同一数据中心进行。</li><li>容灾系统不仅保护数据，更重要的目的在于业务的连续性；而数据备份系统只保护不同时间点版本数据的可恢复。一般首次备份为全量备份，所需的备份时间会比较长，而后续增量备份则在较短时间内就可完成。</li><li>容灾的最高等级可实现RPO&#x3D;0;备份可设置一天最多24个不同时间点的自动备份策略，后续可将数据恢复至不同的备份点。</li><li>故障情况下（例如地震、火灾），容灾系统的切换时间可降低至几分钟；而备份系统的恢复时间可能几小时到几十小时。</li></ul></li><li>RPO和RTO:<ul><li>RPO(Recovery Point Objective):即数据恢复点目标，主要指的是业务系统所能容忍的数据丢失量</li><li>RTO(Recovery Time Objective):即恢复时间目标，主要指的是所能容忍的业务停止服务的最长时间，也就是从灾难发生到业务系统恢复服务功能，所需要的最短时间周期。</li></ul></li><li>双集群容灾：<ul><li>容灾原理：<ul><li>生产集群（原集群）周期性做Roach备份，备份文件被同步scp到灾备集群。灾备集群（新集群）周期性做Roach恢复，灾备集群执行恢复操作期间，需要停止集群，其余时间可对外提供查询服务。生产集群故障后，通过switchover&#x2F;failover命令将灾备集群升主，业务由灾备集群接管。</li></ul></li><li>容灾能力：GaussDB内核已具备该能力，DWS管控面已集成该能力</li><li>方案限制：<ul><li>两套集群节点数可以不同，但实例逻辑拓扑要一致，主要指总DN个数需要相同。</li><li>当前支持集群级别的数据同步，也支持细粒度的容灾，但是细粒度容灾受限于白名单使用。</li><li>要求灾备集群具有足够的磁盘空间，存放完整的全量备份集（通常要求是集群数据量的两倍以上）</li></ul></li><li>性能说明：<ul><li>RPO和RTO主要取决于增量数据同步的性能，以及增量同步的周期间隔。对于典型的主、备集群部署场景（物理机、SAS盘、集群内万兆网卡、集群间千兆网卡），在1T&#x2F;天的数据增速下（集群节点数在30个以上时），最小可达RPO 1小时，最小可达RTO 1小时。带宽不是瓶颈的情况下，增量数据同步的性能至少在 30 MB&#x2F;S&#x2F;DN.</li></ul></li></ul></li></ol><h3 id="集群弹性伸缩管理"><a href="#集群弹性伸缩管理" class="headerlink" title="集群弹性伸缩管理"></a>集群弹性伸缩管理</h3><ol><li>节点扩容：<ul><li>集群磁盘容量使用超过70%时进行扩容。</li><li>在扩容配置中，默认配置将不使用在线扩容，并在扩容后自动进行离线重分布。</li><li>如果使用在线扩容，默认将在扩容之后进行在线重分布操作。</li><li>在线扩容以及在线重分布，相比离线模式对业务影响较小。在线重分布期间，用户可以对表执行插入、更新、删除，但重分布过程仍然会短时间阻塞用户的数据更新操作，会影响用户语句的执行性能。</li><li>扩容重分布过程会消耗大量的CPU和IO资源，因此也会对用户作业性能影响较大，用户应该尽可能在停止业务情况下或业务轻载的情况下，执行扩容重分布。</li></ul></li><li>如果用户的集群是EVS盘的云数仓类型，并且只是磁盘空间出现瓶颈，计算资源比较充足，用户可以通过磁盘扩容快速缓解存储资源不足的问题，磁盘扩容过程中无需暂停业务，并且不会造成CPU、内存等资源浪费。</li><li>节点缩容：当用户的计算或者存储资源冗余，超出业务需求时，可在控制台对已有集群进行缩容操作，以便节省成本。集群缩容时只能以安全环为单位减少集群节点的个数，比如用户的集群有9个节点，每3个节点为一个安全环，那么只能选择缩3个节点和6个节点。</li></ol><h3 id="集群资源管理"><a href="#集群资源管理" class="headerlink" title="集群资源管理"></a>集群资源管理</h3><ol><li>为解决用户资源隔离，以实现业务优先级，避免复杂业务阻塞资源，引入了资源池，每个资源池指定可以使用的CPU，内存、磁盘等大小，然后将用户与资源池关联，用户在使用时就只能使用该资源池可以使用的资源，以达到资源限制的目的。</li><li>创建资源池：<br>  用户可以对资源池进行创建、删除、修改（配置，异常规则，关联用户）等操作，队列的参数表示对该资源池的限制，其中CPU有配额和限额两个维度限制。配额：当多个资源池同时在一个CPU上执行时，各自使用时间比例。限额：限定该资源池可以运行的CPU数量。</li><li>创建资源管理计划：<br>  资源管理计划用于自动化的、周期性的对资产池中的资源进行变更，以便实现灵活的资源管理，如果有多个计划，只能生效一个。</li><li>schema空间管控:<br>  模式空间管理，用于对模式空间大小的限额。</li></ol><h3 id="智能运维"><a href="#智能运维" class="headerlink" title="智能运维"></a>智能运维</h3><ol><li>概念:<br>  智能运维是DWS的常驻运维工具，可以帮助用户智能执行运维任务。智能运维会通过集群负载情况，选择合理时间窗、并发度完成用户指定的任务，在运维任务执行过程中，智能运维将时刻关注用户业务的变化，及时调整运维任务执行策略，以减轻对用户业务的影响。智能运维支持周期型和单次型任务的创建，执行时间窗可按照不同用户业务负载定制化。智能运维具备一定的高可用性，在集群异常的情况下，智能运维将重新执行失败的运维任务，若由于集群异常导致运维任务部分步骤无法完成，智能运维将尝试跳过失败的步骤，以节省用户运维时间窗的开销。</li><li>运维计划：<br>  用户可以对运维任务进行创建、删除和修改等操作。调度模式支持自动、指定目标和优先级模式。运维任务可支持单次型和周期型。周期时间窗时间设置为默认为本地时间，请您根据业务所在时区结合时差设置该项。同一天的时间段请不要重叠。</li><li>运维状态：<br>  在运维详情部分切换至运维状态模块。可查看运维任务运行的详细信息，状态包括：Waiting、Running、Finished和Canceled</li></ol><p>基于公开来源信息, 学习资源来自<a href="https://connect.huaweicloud.com/courses/learn/Learning/sp:cloudEdu_?courseNo=course-v1:HuaweiX+CBUCNXBC006+Self-paced&courseType=1">华为云GaussDB(DWS)数据库官网</a></p>]]></content>
      
      
      <categories>
          
          <category> 数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GaussDB(DWS) </tag>
            
            <tag> 数据库 </tag>
            
            <tag> 数据仓库 </tag>
            
            <tag> 数据 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GaussDB(DWS)数据库-导入导出篇</title>
      <link href="/2025/08/03/GaussDB(DWS)%E6%95%B0%E6%8D%AE%E5%BA%93-%E5%AF%BC%E5%85%A5%E5%AF%BC%E5%87%BA%E7%AF%87/"/>
      <url>/2025/08/03/GaussDB(DWS)%E6%95%B0%E6%8D%AE%E5%BA%93-%E5%AF%BC%E5%85%A5%E5%AF%BC%E5%87%BA%E7%AF%87/</url>
      
        <content type="html"><![CDATA[<h2 id="DWS外表"><a href="#DWS外表" class="headerlink" title="DWS外表"></a>DWS外表</h2><p>外表定义(Foregin table)：是对外部数据源的描述，通过使用SQL接口提供访问外部数据的能力。<br>解决问题：实现数据的导入导出，访问其他DWS集群或者其他外部组件等，扩展了DWS对其他组件进行读写的能力。<br>使用原理：利用FDW(foreign data wrapper)机制。首先定义链接信息，之后创建外表，外表的创建是用于定义DWS数据库上对应其他数据源的表结构。<br>外表创建和管理，分为手动创建和自动创建:</p><ol><li>手动创建如下：在普通表基础上，额外添加server和option信息，先建服务，再建外表。<ul><li><p>server是数据库对象，通过create server创建，存储外部数据源访问和认证信息，用于外表如何找到目标数据。</p></li><li><p>语法格式如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">create server server_name </span><br><span class="line">foreign data warpper fdw_name</span><br><span class="line">option();</span><br></pre></td></tr></table></figure></li></ul></li><li>权限控制：默认只有系统管理员有权限，如果其他人使用需要对foreign data wrapper 授权才能创建，授权语法如下： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grant usage on foreign data wrapper fdw_name to username;</span><br></pre></td></tr></table></figure></li><li>options：数据源定制描述，例如编码、压缩等，不同数据源不同外表差别大。</li><li>系统查询：通过pg_foreign_server和pg_foreign_table系统表查询创建的server和外表。</li><li>自动创建如下：<ul><li>MRS&#x2F;OBS数据源管理+Lakeformation元数据管理；</li><li>MRS&#x2F;OBS数据源管理用于对接HDFS或者OBS,自动建server；</li><li>Lakeformaion元数据管理，自动建外表，使用外部元数据直接进行数据访问。</li></ul></li></ol><h2 id="外表分类"><a href="#外表分类" class="headerlink" title="外表分类"></a>外表分类</h2><p>功能分类：HDFS外表、OBS外表、GDS外表、DLI外表等。<br>server类型分类：</p><ol><li>dfs_fdw&#x2F;hdfs_fdw外表：适应用于外部文件系统（HDFS&#x2F;OBS）上的结构化数据查询。</li><li>dist_fdw外表：适用于文件导入导出。</li><li>gc_fdw外表：适用于协同分析。</li><li>log_fdw外表：适用于dws内部使用，日志查询。</li><li>file_fdw外表：访问服务器文件 。</li></ol><h2 id="GDS-Gauss-Data-Service-工具"><a href="#GDS-Gauss-Data-Service-工具" class="headerlink" title="GDS(Gauss Data Service)工具"></a>GDS(Gauss Data Service)工具</h2><p>定义：DWS提供的数据导入导出工具</p><p>适配场景：</p><ol><li>数据迁移，同构异构集群数据迁移。</li><li>以文本数据作为来源的大数据量表导入</li><li>大数据量表导出<br>  支持导入和导出的文件格式：csv&#x2F;text&#x2F;binary&#x2F;fixed（每行数据等长）</li></ol><p>工具原理：<br>数据导入过程：GDS通过网络和数据库系统相连，CN负责任务规划和下发，GDS负责数据文件切分，然后分发给各个DN，各个DN节点负责数据并行导入，各DN收到数据分片后解析数据，根据表的分布列计算hash值并确定归属哪个DN，如果是自身就缓存到本地，否则就通过网络传给相应的DN.导出过程正好相反。<br>导入要点：</p><ol><li>导入时，GDS数量&lt;&#x3D;DN数量。</li><li>GDS导入时，服务器普通文件系统数据可以导入DWS数据库，HDFS文件系统数据暂时不可以导入DWS数据库。</li></ol><p>导出要点：</p><ol><li>按照导出目的地是否是集群内的主机，分为local模式和remote模式；目的地是集群节点所在主机上为local模式，否则为remote模式。</li><li>导出支持的数据文件格式：csv&#x2F;text&#x2F;fixed，单行数据大小需要&lt;1GB</li><li>在local模式中，数据均匀切割并生成到集群指定文件夹下，需要占用集群磁盘空间。</li><li>在remote模式中，1个GDS同一时刻只为1个集群服务，多个GDS可以并发导出。和集群在同一内网的GDS，导出速度受网络带宽影响。</li></ol><p>GDS导入操作：启动GDS服务&gt;创建外表&gt;执行导入&gt;分析错误表<br>导入操作要点：</p><ol><li>GDS导入数据目录文件过多时，可以使用正则表达式指定外表的location,选择需要的导入文件</li><li>导入过程中的错误，分为数据格式和非数据格式两种错误。数据格式错误是指缺失或多出字段值、数据类型错误或者数据编码错误等。可以通过在创建外表时，设置参数“log into error_table_name”，将导入过程中的数据格式错位信息写入指定的错误信息表中。</li></ol><p>GDS导出操作：启动GDS&gt;创建外表&gt;执行导出<br>导出操作要点：导出的文本命名格式为t1_foreign_output.data.</p><h2 id="实时数仓"><a href="#实时数仓" class="headerlink" title="实时数仓"></a>实时数仓</h2><ol><li>Flink:分布式、流批一体、开源处理引擎。</li><li>用途：在无边界和有边界数据流上进行有状态计算。无边界数据流是指源源不断产生数据，数据流没有结束，类似于kafka消息流。有边界数据流是指有开始和结束的数据流，可以对所有数据做处理。有状态计算是指在流处理过程中，可以将中间状态保留，用于后续数据处理使用。</li><li>Flink内容：组件+任务+API库</li><li>Flink组件：<ul><li>JobManager:负责分配任务、协调执行任务、协助检查点，并处理失败。</li><li>TaskManager:在集群中并行执行任务，管理任务状态和缓冲区。</li><li>Client:提交Flink作业，并与JobManager通讯。</li></ul></li><li>Flink任务：任务由多算子组成，每个算子设置各自的并行度任务<ul><li>source+transformation+sink算子组成。</li><li>source:数据流起点，从外部系统读取数据并转换为Flink可处理的内部数据结构。</li><li>transformation:对数据流进行操作，转换&#x2F;聚合&#x2F;连接&#x2F;分割数据</li><li>sink:数据流终点，将处理后的数据写入外部系统。</li></ul></li><li>Flink的API库：<ul><li>DataStream API:提供转换操作符,用于构建流处理应用核心API。</li><li>Table API&amp;SQL:提供声明式API,用类SQL方式查询流和批处理数据。</li></ul></li></ol><h2 id="dws-flink-connector工具"><a href="#dws-flink-connector工具" class="headerlink" title="dws-flink-connector工具"></a>dws-flink-connector工具</h2><ol><li>用途：可以通过Flink SQL实现从DWS中读写数据（包括增量读）</li><li>功能：<ul><li>批量读：将DWS中表作为数据源供Flink用于批读</li><li>维流join：将DWS中表作为维表供Fink维流join(即用实时流和维表join)</li><li>攒批写：将DWS中表作为结果表供Flink写入数据（一定时间一定量）</li></ul></li><li>Flink catalog：通过Flink catalog，实现Flink和DWS表相互映射。</li><li>语法说明：<ul><li>Flink SQL中的表字段必须和DWS表中有对应字段</li><li>with参数设置中，connector需要指定dws, tableName需要指定为DWS对应表名。lookupAsync表示是否异步读取</li><li>在Flink catalog中，with参数type需要指定为dws,base_url中不用带数据库名称。use catalog dws 表示使用新建catalog。show catalog表示查询所有catalog。可以直接查询数据库中的表信息，不需要在Flink中建映射表。</li></ul></li></ol><h2 id="实时增量读取"><a href="#实时增量读取" class="headerlink" title="实时增量读取"></a>实时增量读取</h2><ol><li>原理：只对变化的数据进行读取，而不重新读取整个数据集。<ul><li>好处：提高处理效率，减少资源消耗</li></ul></li><li>操作：DWS通过Binlog实现增量读取。对表做DML操作时，先进行双写，对应的DML记录到辅助表中，然后通过读取该辅助表来获取增量数据，实现数据同步和增量计算。</li><li>Binlog表语法：用Binlog表作为源表供Flink实时读取。with参数中的binlog属性需要设置为true,binlogSlotName需要设置为自定义的槽位名。</li><li>注意要点：<ul><li>DWS中只有Hstore和Hstore-opt表支持Binlog功能，表需要有主键且设置为enable_binlog &#x3D; on </li><li>如果多任务消费同一个表的Binlog数据，需要保证每个任务的binlogSlotName唯一。</li><li>为达到最高读取速度，建议Flink任务并行度和DWS集群DN数设置一致。</li><li>可以使用dws-flink-connector的sink能力来写入读取到的Binlog数据，需要注意点如下：如果要保证DN内数据写入顺序，需要设置connectionSize &#x3D; 1.如果源端有更新主键操作或者Flink聚合操作，需要将ignoreUpdateBefore设置为False(默认为True).</li></ul></li></ol><h2 id="实时数仓-1"><a href="#实时数仓-1" class="headerlink" title="实时数仓"></a>实时数仓</h2><p>Flink实时处理能力+DWS的Binlog能力。</p><p>基于公开来源信息, 学习资源来自<a href="https://connect.huaweicloud.com/courses/learn/Learning/sp:cloudEdu_?courseNo=course-v1:HuaweiX+CBUCNXBC006+Self-paced&courseType=1">华为云GaussDB(DWS)数据库官网</a></p>]]></content>
      
      
      <categories>
          
          <category> 数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GaussDB(DWS) </tag>
            
            <tag> 数据库 </tag>
            
            <tag> 数据仓库 </tag>
            
            <tag> 数据 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GaussDB(DWS)数据库-开发应用篇</title>
      <link href="/2025/08/03/GaussDB(DWS)%E6%95%B0%E6%8D%AE%E5%BA%93-%E5%BC%80%E5%8F%91%E5%BA%94%E7%94%A8%E7%AF%87/"/>
      <url>/2025/08/03/GaussDB(DWS)%E6%95%B0%E6%8D%AE%E5%BA%93-%E5%BC%80%E5%8F%91%E5%BA%94%E7%94%A8%E7%AF%87/</url>
      
        <content type="html"><![CDATA[<h3 id="DWS驱动及ODBC-JDBC开发"><a href="#DWS驱动及ODBC-JDBC开发" class="headerlink" title="DWS驱动及ODBC&#x2F;JDBC开发"></a>DWS驱动及ODBC&#x2F;JDBC开发</h3><ol><li>DWS驱动：<ul><li>驱动概念：数据库驱动是应用程序和数据库存储之间的一种接口，数据库厂商为某一开发语言环境，能够实现数据库调用而开发的类似“翻译员”功能的程序，将复杂的数据库操作和通讯抽象成为当前开发语言的访问接口。</li></ul></li><li>支持驱动类型：JDBC、ODBC等，如果同时拥有不同版本的集群或者当前没有集群，单击“下载”时下载的依然是与现有集群版本相匹配的。</li><li>驱动支持平台：JDBC没有平台限制，ODBC有支持平台限制（平台：X86、鲲鹏）</li><li>JDBC应用程序开发：<ul><li>JDBC整体架构（4层）：应用程序-&gt;JDBC Driver Interface-&gt;JDBC驱动-&gt;数据库。JAVA本身具有良好的平台移植性，这也直接导致JDBC的平台移植性比ODBC强很多。</li><li>JDBC安全配置：配置JDBC包-&gt;加载驱动-&gt;连接数据库<ul><li>gsjdbc4.jar:与PostgreSQL保持兼容的驱动包，其中类名、类结构与PostgreSQL驱动完全一致，曾经运行于PostgreSQL的应用程序可以直接移植到当前系统使用。主类名为“org.postgresql.Driver”，数据库连接的URL前缀为“jdbc:postgresql”</li><li>gsjdbc200.jar:如果同一JVM进程内需要同时访问PostgreSQL及GaussDB(DWS)，请使用此驱动包。主类名为“com.huawei.gauss200.jdbc.Driver”,数据库连接的URL前缀为“jdbc:guassdb”，其余与gsjdbc4.jar相同。</li></ul></li><li>配置注意事项：<ul><li>连接参数：第三方工具通过JDBC连接DWS时，jdbc向DWS发起连接请求，会默认添加以下配置参数，详见jdbc代码ConnectionFactoryImpl类的实现。这些参数可能会导致JDBC客户端的行为与gsql客户端的行为不一致。如果实际期望和这些配置不符，建议在Java连接设置代码中显示设定这些参数。</li><li>fetchsize:在应用程序中，如果需要使用fetchsize，必须关闭autocommit。开启autocommit，会令fetchsize失效。</li><li>autocommit:在jdbc向DWS申请连接的代码中，建议显示打开autocommit开关。如果基于性能或者其他方面考虑，需要关闭autocommit时，需要应用程序自己来保证事务的提交。例如，在指定的业务SQL执行完之后做显式提交，特别是客户端退出之前务必保证所有的事务已经提交。</li><li>CopyManager:在不使用ETL工具，数据入库实时性要求又比较高的情况下，建议在开发应用程序时，使用dws的jdbc驱动的CopyManager接口进行微批导入。</li><li>释放连接：推荐使用连接池来限制应用程序的连接数。每执行一条SQL就连接一次数据库，是一种不好的SQL编写习惯。在应用程序完成作业任务之后，应当及时断开和dws的连接，释放资源。建议在任务中设置session超时时间参数。</li><li>使用jdbc连接池，在将连接释放给连接池前，需要执行以下操作，重置会话环境。否则，可能会因为历史会话信息导致的对象冲突。如果在连接中设置了GUC参数，那么在将连接归还连接池之前，必须使用“SET SESSION AUTHORIZATION DEFAULT;RESET ALL;”将连接的状态清空。如果使用了临时表，那么在将连接归还连接池之前，必须将临时表删除。（常见报错：relation “xxx_tmp” already exists）</li></ul></li></ul></li><li>ODBC应用程序开发：<ul><li>ODBC整体架构（5层）：应用程序-&gt;标准接口（ODBC API）-&gt; 驱动程序管理器（ODBC Driver Manager）-&gt;ODBC驱动-&gt;数据库</li><li>数据源配置：Linux、windows</li><li>Linux-ODBC数据源配置：<ul><li>步骤（4个）：<ul><li>安装ODBC驱动管理器：获取UnixODBC源码包，编译安装驱动管理器。备注：驱动默认安装在“&#x2F;usr&#x2F;local”目录下，生成数据源文件到“&#x2F;usr&#x2F;local&#x2F;etc”目录下，库文件生成在“&#x2F;usr&#x2F;local&#x2F;lib”目录下</li><li>配置驱动</li><li>安全组配置</li><li>测试连接：使用isql -v GaussODBC(数据源名称)</li></ul></li></ul></li><li>windows-ODBC数据源配置：<ul><li>步骤<ul><li>配置服务器：与Linux相同</li><li>配置数据源（Windows自带驱动管理器，无需额外安装）</li></ul></li></ul></li><li>应用程序调试：<ul><li>ODBC应用程序调试需要在前面配置正确可用的环境下进行。</li></ul></li></ul></li><li>客户端连接管理<ul><li>功能描述：JDBC和ODBC驱动在连接成功后会设置session级GUC参数connection_info.该参数包含连接数据库的驱动类型、驱动版本号、当前驱动的部署路径和进程属主用户，使用json格式记录。默认只显示driver_name和driver_version，driver_path和os_user的显示由用户控制，控制连接参数为ConnectionExtraInfo.connetion_info可以在pg_stat_activity和pgxc_stat_activity中查看。</li><li>连接配置示例：<ul><li>JDBC连接：在连接URL中增加connectionExtraInfo参数。</li><li>ODBC连接：在“&#x2F;usr&#x2F;local&#x2F;etc&#x2F;odbc.ini”文件中追加ConnectionExtraInfo设置。</li></ul></li></ul></li></ol><h3 id="SQL编辑器"><a href="#SQL编辑器" class="headerlink" title="SQL编辑器"></a>SQL编辑器</h3><ol><li>SQL登录：IAM用户一键登录、自定义数据源登录<ul><li>IAM用户一键登录：<ul><li>用户可以直接使用IAM账号登录集群数据库，免除填写账号密码操作</li><li>提供集群列表树展示当前用户拥有的所有集群，可以选择某一个集群直接双击打开集群。</li><li>当前连接是用户的IAM账号直接登录，一键登录集群后，用户可以对账号进行赋权。</li><li>登录后，就可以对集群数据库做一些开发运维等操作。</li><li>限制要求：<ul><li>使用IAM账号登录，首先需要有DWS Database Access角色权限，以及当前用户必须是子账号。</li><li>对于集群版本有一些要求，集群版本要高于8.3.1.330.</li></ul></li></ul></li><li>自定义数据源登录：<ul><li>自定义数据源和传递连接方式类似，用户选择集群后，需要填用户名密码登录</li><li>在创建连接之前会先提示测试连接，测试正常后可以正常保存。</li><li>限制要求：<ul><li>自定义连接对集群版本没有限制，有的只是一些语法上的兼容性，需要用户自定义根据集群版本来编写SQL</li><li>数据源名称如果不填写，会根据集群名（用户名）来创建，注意一个用户下名称不可以重复</li></ul></li></ul></li></ul></li><li>元数据管理：<ul><li>提供了库、模式、表等图形化界面管理，而且以树形方式来层级查看。</li><li>提供树形结构来展现库、模式、表、索引等元数据列表，可以层级打开查看。</li><li>每层节点也提供右键菜单做新增、修改、删除等操作。</li><li>表提供批量操作列，索引，分区，约束信息。</li><li>表，分区，视图支持直接打开数据操作，支持根据SQL条件过滤，表和分区还支持单条数据插入，修改和新增。</li></ul></li><li>SQL分析执行：<ul><li>SQL诊断军规，SQL拦截规则：<ul><li>NULL校验：NULL值的比较只能使用IS [NOT] NULL方式，其他任何形式的逻辑判断都返回NULL。例如NULL &lt;&gt; NULL,NULL &#x3D; NULL和NULL &lt;&gt; 1 返回结果都是NULL.</li><li>COUNT(col)：count(1) 会统计NULL值（真实行数），而count（col）不会统计。</li><li>LIMIT和ORDER BY : DWS的分布式操作会导致数据跨节点流动，不带ORDER BY 的LIMIT 操作的，会导致输出结果随机。因此除非不关注结果集的稳定性，否则禁止不带ORDER BY 的LIMIT操作。</li><li>不稳定函数：子查询中不能出现uuid_generate_v1(), sys_guid(),nextval等不稳定函数，会造成结果集的不稳定。</li><li>NOT IN 校验：not in 子查询逻辑执行计划，走的是nestloop嵌套循环，在数据量大的情况下，非常容易出现性能问题；通过改写not exists之后，执行计划可以使用hashjoin哈希关联，性能能够得到极大的提升。</li><li>join 代替exists: join 相比exists和in 具有更好的代码阅读性，SQL优化器相对更容易找到更精确的执行计划。</li><li>select * : 不建议使用“select * ”这种写法，请明确指定列。</li><li>ORDER BY: 子查询中禁止使用order by </li><li>RETURNING: returning会导致语句不下推</li><li>DISTINCT ON: distinct on 会导致语句不下推</li><li>表关联数量：优化器是基于代价的优化器，表数据量越多，估算的偏差就越大，产生性能差的执行计划的风险就越大，所以每条SQL语句中关联的表个数不超过16个</li><li>schema: 访问表需要加schema。</li></ul></li></ul></li><li>脚本管理<ul><li>目录：支持使用目录来管理SQL脚本，最多支持二级目录，每级目录支持创建10个文件夹，用户只能看到自己创建的目录和脚本。</li><li>脚本：脚本保存到OBS桶中，可以在基础设置中设置默认桶地址，可选择目录进行管理，目录地址也会默认带到桶地址中。</li></ul></li></ol><h3 id="数据集成工具"><a href="#数据集成工具" class="headerlink" title="数据集成工具"></a>数据集成工具</h3><ol><li>实时同步服务：<ul><li>定义： 实时同步服务是DWS 团队根据特性孵化出的，一个简便易用、高性能的、从Kafka同步数据到DWS的服务化工具。其入库时可采用DWS内部协议，以减少对DWS集群的资源消耗，同步提升入库性能。</li></ul></li><li>创建实时同步服务实例：<ul><li>创建时填写对应参数，然后点击立即购买，等待创建完成后，就会按需在后台创建好一个资源池，后续运行的作业将会从资源池中分配一定资源供作业运行；资源池统一使用CU分配资源，规格中的CPU数量即为CU数量，内存不可直接控制，他们会按照CPU内存比按照比例分配，例如创建的实例规格为4U16GB,创建时选择3节点，那么总资源 &#x3D; 4 CU * 3 &#x3D; 12CU,每个CU内存大学4GB.</li></ul></li><li>实时同步服务连接配置：<ul><li>连接配置用于配置Kafka、DWS的连接信息，一份配置所有作业均可使用，以便于后面在提交作业时可以直接使用，不用每个作业都配置一份。</li><li>当前支持Kafka和dws两种类型的连接，连接名称只用于业务区分，无实际含义，Kafka的服务地址需要是带端口的连接串，并且保证是VPC能访问的IP;dws的连接地址是一个包含协议的完整JDBC连接串，同时也需要是能在VPC内能访问的IP.</li></ul></li></ol><h3 id="数据调度工具"><a href="#数据调度工具" class="headerlink" title="数据调度工具"></a>数据调度工具</h3><ol><li>Airflow基础：<ul><li>定义：Apache Airflow是一个开源平台，用于开发、调度和监控，面向批处理的工作流程。</li><li>是可扩展Python框架，主要特点是所有工作流都用Python代码定义，有如下优点：<ul><li>动态：Airflow管道配置为Python代码，允许动态管道生成。</li><li>可扩展：Airflow框架包含可连接多种技术的运算符。所有Airflow组件都可扩展，可轻松适应运行环境。</li><li>灵活：利用Jinja模板引擎，内置工作流参数化。</li></ul></li><li>架构组件（5）：分布式架构<ul><li>Worker: 执行分配的任务</li><li>Scheduler: 负责将必要的任务添加到队列中</li><li>Web Server: HTTP服务器，提供对DAG&#x2F;任务状态等信息的访问</li><li>Database: 存储有关任务、DAG、变量、连接等状态的信息</li><li>Celery: Broker、Result backend</li><li>Broker: 存储要执行的任务。</li><li>Result backend : 存储已完成任务的状态。</li></ul></li><li>Airflow删除：当用户不需要使用某个集群时，可以删除该集群。删除的集群无法恢复，同时集群中的用户数据，已执行任务的历史记录，也会自动删除，而且无法再访问。删除集群时，不会删除集群使用的DAG文件。</li></ul></li><li>注意要点：<ul><li>访问DWS时，建议在Airflow中新建连接，通过base_hook获取连接ID，获取对应数仓的连接信息。避免在DAG文件中，硬编码数仓密码。</li></ul></li></ol><p>基于公开来源信息, 学习资源来自<a href="https://connect.huaweicloud.com/courses/learn/Learning/sp:cloudEdu_?courseNo=course-v1:HuaweiX+CBUCNXBC006+Self-paced&courseType=1">华为云GaussDB(DWS)数据库官网</a></p>]]></content>
      
      
      <categories>
          
          <category> 数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GaussDB(DWS) </tag>
            
            <tag> 数据库 </tag>
            
            <tag> 数据仓库 </tag>
            
            <tag> 数据 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GaussDB(DWS)数据库-数据库管理篇</title>
      <link href="/2025/08/03/GaussDB(DWS)%E6%95%B0%E6%8D%AE%E5%BA%93-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%AF%87/"/>
      <url>/2025/08/03/GaussDB(DWS)%E6%95%B0%E6%8D%AE%E5%BA%93-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E7%AF%87/</url>
      
        <content type="html"><![CDATA[<h3 id="DWS数据仓库服务："><a href="#DWS数据仓库服务：" class="headerlink" title="DWS数据仓库服务："></a>DWS数据仓库服务：</h3><ol><li>特点：在线数据分析处理、即开即用、可扩展、完全托管、分析型数据库</li><li>兼容性：兼容SQL92、SQL99、SQL2003语法、兼容PostgreSQL&#x2F;Oracle&#x2F;Teradata&#x2F;Mysql等数据库生态。</li></ol><h3 id="存储引擎"><a href="#存储引擎" class="headerlink" title="存储引擎"></a>存储引擎</h3><ol><li>用途：组织和管理数据存储</li><li>使用：SQL语句从客户端发到SQL引擎，先进行语法分析，经过SQL引擎的优化器生成执行计划，SQL引擎的执行器和存储引擎交互，存储引擎支持行存和列存（普通列存表和HStore&#x2F;HStore OPT表），并分别提供存储访问接口。</li></ol><h3 id="行存储引擎"><a href="#行存储引擎" class="headerlink" title="行存储引擎"></a>行存储引擎</h3><ol><li>行存表page页面组件：页头（page header）+空闲时间（free space）+数据（heap tuple）</li><li>页头（page header）各字段存储信息如下：<ul><li>tuple:一行数据为一个tuple</li><li>free space:行指针的末尾与最新元祖起始位置之间的空余空间。</li><li>heap tuple:存储实际数据的地方。</li></ul></li></ol><h3 id="列存储引擎"><a href="#列存储引擎" class="headerlink" title="列存储引擎"></a>列存储引擎</h3><ol><li>列存储引擎的最小存储单元是CU(Compression Unit,压缩单元)，一个CU是由表中某一列的一部分数据组成的压缩数据块，可以通过CU_ID,COL_ID标识一个CU.</li><li>列存储引擎架构：辅助表+场景</li><li>辅助表用途：行存表，辅助列存储的实现，用于记录存储的元信息，或者用于提升存储效率。</li><li>辅助表分类：<ul><li>CUDesc表：用于记录CU的事务时间戳、CU大小、存储位置、magic校验码、min&#x2F;max等信息。</li><li>delta表：由表级参数enable_delta来控制是否开启。表主要用于缓存列存表的入库数据，等攒批后再刷到CU中。</li><li>查询：可以通过查询pg_class得到列存储引擎辅助表信息。</li></ul></li><li>适用场景：<ul><li>实时场景（性能）：<ul><li>Hstore表：可用于增强实时场景下的小批量DML性能，兼容列存2.0.可以切换。</li><li>Hstore opt表：与Hstore相比，增强入库和查询能力，但是不兼容老数据。</li></ul></li><li>海量数据场景（数据）：<ul><li>冷热表：自动将冷数据放到OBS服务中存储，从而降低数据存储成本，保障热数据性能。</li><li>存算分离表：将数据完全存放到OBS存储中，并根据性能和存储可以选择相应的规格。</li></ul></li><li>兼容性：Hstore表、Hstore opt表、列存2.0都可以兼容冷热表和存算分离表。</li></ul></li></ol><h3 id="表类型（6种）"><a href="#表类型（6种）" class="headerlink" title="表类型（6种）"></a>表类型（6种）</h3><p>行存表+列存表+Hstore+Hstore opt+冷热表+存算分离表</p><ol><li>行存表：<ul><li>直接使用create table建立的表，默认为行存表，使用B-Tree索引。</li><li>B-Tree索引特点：<ul><li>索引结构：B-Tree（平衡树）是一种有序树，每个节点包含多个键，并且子节点的键值范围是确定的。</li><li>索引优势：高效支持范围查询、等值查询、排序操作。</li></ul></li></ul></li><li>列存表：<ul><li>建表时指定参数orientation &#x3D; column，建立列存表。</li><li>列存参数：<ul><li>compress_level: 指定压缩级别（low, middle, high）</li><li>max_batchrows:CU内最大行数，默认6w行。</li><li>column_version:1.0&#x2F;2.0&#x2F;3.0(存算分离)</li></ul></li><li>列索引：<ul><li>Gin索引：基于B-tree树结构的倒排索引，用于存储被索引字段的value或者value的元素，适应于数组过滤、全文检索的场景。</li><li>Gist索引：通用索引接口，用于不同类型支持不同索引方式，适用于位置索引。</li><li>PSort索引：用于对该列进行聚簇排序，目的是提升查询过滤性能。</li><li>CBTree索引：列存表的B-Tree索引，原理和行存相同。</li></ul></li></ul></li><li>Hstore表：<ul><li>建表：with参数enable_hstore指定为开启，则开启Hstore表，或者通过alter修改为普遍列存表。是实时数仓中设计的表类型，用于将insert&#x2F;update&#x2F;upsert等操作实时快速入库。</li><li>功能：<ul><li>支持异步排序：当指定Psort后，对存量未排序数据在后台排序，风险是在压力大时会造成Delta膨胀。</li><li>支持小CU合并：将小CU在后台合并为一个新CU，提升实时能力。</li><li>单条或者小批量IUD(insert&#x2F;update&#x2F;delete)操作高并发实时入库，支持大批量定期入库。</li><li>支持冷热数据管理。</li></ul></li><li>适配场景：实时入库和实时查询强诉求场景，同时拥有处理传统TP场景事务能力。版本：8.2.0.100及以上集群版本支持</li><li>与普通列存表的差异：主要的辅助表Delta表的差异：<ul><li>Hstoreb表的delta表：表结构上和主表定义不一致，功能上用于持久化存储update&#x2F;delete&#x2F;insert信息。缺点是依赖后台常驻autovacuum来执行merge操作。</li><li>列存表的delta表：表结构上和列存主表定义一致，功能上用于暂存小批量insert数据，达到阈值后统一merge到主表，避免直接insert到主表产生大量CU,缺点是如果来不及merge，会导致delta表膨胀，进而影响查询性能，同时无法解决并发update的锁冲突问题。</li></ul></li><li>注意要点：<ul><li>表级参数enable_dalta和enable_hstore不能同时开启，原因是enable_delta用于普通列存表的delta表开启，与enable_hstore冲突。</li><li>Hstore表只支持col_version 2.0版本。</li></ul></li></ul></li><li>Hstroe opt表：<ul><li>建表:前提是列存表，在with参数enable_hstore_opt指定为开启。或者和enable_hstore同时指定。当hstore_opt开启时，不能通过alter关闭。opt会默认打开turbo属性，除非手动关闭。</li><li>功能：<ul><li>支持异步排序和小CU合并：和Hstore表相同，但是没有delta表膨胀的问题。</li><li>支持Bitmap columns索引：使用bitmap_columns &#x3D; “列名1，列名2”指定。此索引只针对varchar&#x2F;text类型，并且字符长度不能大于127，只正对基数特征比较明显的列。在低基数时，内部会使用bitmap配合字典压缩存储数据，在高基数时，通过bloomfilter生成hash的bit列加速过滤。</li></ul></li><li>Hstore OPT表和Hstore表在辅助表方面的差异：<ul><li>CUDesc辅助表:</li><li>Hstore OPT表结构的cudesc和hstore不一致，支持二级分区等特性。</li><li>Hstore表结构的cudesc和列存一致，因此可以切换。</li><li>Delta辅助表：</li><li>Hstore opt表结构的delta表定义和hstore一致，cudesc和hstore不一致。</li><li>而Hstore的表结构的delta表定义和列存不一致。cudesc和列存一致。</li></ul></li></ul></li><li>冷热表：<ul><li>定义：在时间场景，数据按照时间可划分为：热数据和冷数据。</li><li>热数据Hot:被频繁查询或更新，对访问的响应时间要求高的数据。</li><li>冷数据Cold:不允许更新，偶尔查询，对访问的响应时间要求不高的数据。</li><li>通过定义冷热表，将符合规则的冷数据切换到OBS上存储，按照分区自动进行冷热数据判断和迁移。</li><li>切换策略模式：<ul><li>LMT(Last Modify Time，最后修改时间)：根据分区的最后更新时间进行切换，切换数据为切换[day]天前的分区数据为冷数据，迁移到OBS表空间，其中[day]范围：0到36500天。</li><li>HPN(Hot Partition Number，热分区数量)：保留指定数量的热分区。分区顺序根据分区的序列ID（Sequence id）确定，ID由分区边界值大小生成，切换时，将数据迁移到OBS表空间。HPN范围；0到1600。</li></ul></li><li>建表：<ul><li>创建OBS tablespace，指定OBS路径</li><li>建表，选项中指定orientation &#x3D; column, cold_tablespace &#x3D;’’, storage_policy。cold_tablespace表空间为必选项，storage_policy冷热数据切换规则，必选项。</li></ul></li></ul></li><li>存算分离表：<ul><li>背景：用于实现计算层和存储层独立增加节点并行互不打扰。</li><li>建表：<ul><li>先建立OBS tablespace 表空间，和冷热表一致。</li><li>创建逻辑集群</li><li>创建表，指定col_version &#x3D; 3.0，即可创建存算分离表。</li></ul></li></ul></li><li>不同表的优劣：<ul><li>行存表：适合少量数据，对实时性要求较高的场景。</li><li>列存表1.0&#x2F;2.0: 并发能力弱于Hstore表,不推荐</li><li>Hstore:维批copy，无更新入库场景，性能要求要的情况下使用。</li><li>Hstore opt:对列式存储有实时场景需求，当前推荐版本。</li><li>冷热表：在业务系统中，用户对不同时期数据，有不同使用需求时使用，可以和Hstore OPT同时使用。</li><li>存算分离表：云原生环境下，需要分别增减计算和储存节点的场景下使用。</li></ul></li></ol><h3 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h3><ol><li>定义：是数据库系统执行过程中的一个逻辑单位，由一组有限数据库操作序列构成，包括对数据库的读写操作。</li><li>要点：<ul><li>若事务被提交后，数据库需要确保事务中的所有操作成功完成，并且结构永久保持。</li><li>若事务中有操作没成功完成，则所有操作全部回滚，恢复事务执行前的状态。</li><li>每个事务对其他事务无影响。</li><li>并非任意对数据库操作的序列都是数据库事务，事务要满足ACID特性。</li><li>在进行多个相关更改时，一个事务内执行多个语句有助于保证一致性；在所有相关更改完成前，其他会话不能看见中间状态。</li></ul></li><li>事务分类：显性事务+自动提交事务<ul><li>显性事务：begin开始事务块，所有begin命令后的所有语句都在一个事务中执行，直到给出一个显示的commit或者rollback.</li><li>自动提交事务：默认情况下，数据自动提交模式中执行事务（没有begin块）。每个语句都在自己的事务中执行并且在语句结束时隐式执行一次提交，若失败会完成一次回滚。</li></ul></li><li>事务性质ACID:<ul><li>原子性（Atomicity）:一个事务要么全做，要么全不做。</li><li>一致性（Consistency）:事务执行前后，数据都是正确的，不存在矛盾。</li><li>隔离性（Isolation）:不同事务之间不会相互影响。</li><li>持久性（Durability）:事务提交后，对数据库的改变不会消失。</li></ul></li><li>ACID实现原理：</li><li>原则性（Atomicity）:<ul><li>通过分配的唯一标识事务号（XID）区分不同事务，是单调递增数据，用于事务提交和回滚。事务在修改（insert&#x2F;update&#x2F;delete）前先获取事务号，采用64位bit的XID；通过txid_current（）查询事务号。</li><li>事务提交日志（Commit Log,CLog）:用于记录事务执行结果的状态。事务提交，CLog中记录commit;事务回滚，CLog中记录abort.</li><li>用途：查询事务修改是否有效，只需要查询事务对应的CLog状态。</li></ul></li><li>查询函数:<ul><li>pgxc_is_committed():查询事务状态</li><li>pgxc_xacts_iscommitted():查询各节点事务状态。</li><li>注意要点：CLog日志记录了事务的提交和回滚的状态，不得随意删除或者移动。</li></ul></li><li>一致性Consistency和隔离性Isolation：任何事务都感受不到有其他事务在系统中并发地执行。<ul><li>典型读取问题<ul><li>脏读：一个事务读取另一个未提交事务写入的数据。</li><li>不可重复读：一个事务重新读取之前读取过的数据，发现该数据已经被其他已提交事务修改。</li><li>幻读：一个事务重新执行一个查询，返回符合查询结果的行，发现这些行由于其他最近提交的事务而发生改变（行的增加、减少或者更新）</li></ul></li><li>隔离级别和容易出现的问题：<ul><li>未提交读（read uncommitted）:脏读+不可重复读+幻读</li><li>已提交读（read committed）：不可重复读+幻读</li><li>可重复读（rapeatable read）:幻读</li></ul></li><li>快照：<ul><li>定义：当前时刻所有活跃事务号的集合。</li><li>特点：扫描数据时，每个事务看到的只是获取快照那一刻的数据，而不是数据的当前最新状态，从而避免一个事务看到其他并发事务的更新而导致的不一致数据。</li><li>可见性：针对某条数据对当前查询中是否可见。</li><li>可见情况如下：<ul><li>快照中活跃事务的修改不可见</li><li>事务启动前提交的事务，其修改可见</li><li>事务启动后提交的事务，其修改不可见。</li></ul></li></ul></li><li>注意要点：DWS默认隔离级别为已提交读（read committed).保证隔离级别下的数据一致性。</li></ul></li><li>持久性（Durability）:<ul><li>方法：重做日志（Redo Log）,Redo Log&#x2F;WAL日志&#x2F;xlog，记录数据修改操作，用于数据恢复和持久化。</li><li>产生方法：数据修改过程中会产生redo log，默认单文件大小16M,保存在pg_xlog目录中。主要用途：归档、节点重启恢复、备份恢复、容灾。</li><li>注意要点：xlog记录数据库发生的各种事务信息，不得随意删除或者移动日志文件，否则数据库会有无法恢复的风险。</li><li>FPW(full page writes)会产生大量xlog.带索引导入会产生大量xlog，主要因为带索引导入会使数据使用xlog进行主备复制，而不带索引导入时会使用页复制进行同步。带索引导入推荐做饭：导入前先删除索引，导入完成后重建索引。</li><li>典型函数：<ul><li>pg_current_xlog_location:获取当前重做日志写入位置。</li><li>pg_xlogfile_name:获取当前写入重做日志文件名：</li><li>pg_xlogfile_name_offset:获取当前写入重做日志文件名并返回其在文件中的字节偏移量。</li></ul></li></ul></li><li>分布式事务：<ul><li>特点：分布式事务中，事务由不同服务器不同节点共同完成，所有节点事务要么全部成功，要么全部失败。</li><li>DWS通过GTM(全局事务控制器)实现分布式事务强一致性。</li><li>DWS实施方式：两阶段提交法（2PC）<ul><li>事务协调者要求所有涉及事务的节点预提交操作，并反馈是否可以提交。</li><li>事务协调者要求每个数据库提交数据，或者回滚数据。</li></ul></li><li>2PC流程分类：按照涉及节点不同<ul><li>单节点DML：根据数据分布实际情况，在一个事务中，DML操作只涉及某一个DN节点，只需要该DN以及发起事务的CN参与事务，其他节点不参与本次事务。</li><li>跨节点DML：根据数据分布实际情况，在一个事务中，DML操作涉及多个DN节点。需要多个DN以及发起事务的CN都参与事务，其他CN节点不参与事务。</li><li>DDL:分布式DDL,更新所有实例上的元数据信息。由于元数据信息是存储在所有实例上的，所以更新元数据信息需要在所有CN和DN上都更新一遍，即所有CN和DN都参与事务。</li></ul></li></ul></li></ol><h3 id="表"><a href="#表" class="headerlink" title="表"></a>表</h3><ol><li>表要素：字段类型+存储方式+分布方式+分区方式+约束+表操作</li><li>定义：关系型数据库中二维数组集合，代码存储对象之间的关系</li><li>记录：每一行为一个记录，也称元祖，由若干字段组成。</li><li>字段：域或属性，每一列为一个字段，包含两个属性：列名和数据类型。</li><li>字段数据类型：基本数据类型：数值类型+字符类型+日期时间类型<ul><li>用户自定义类型：create type</li></ul></li><li>存储方式：<ul><li>行存：orientation &#x3D; row</li><li>列存：orientatioin &#x3D; column</li></ul></li><li>分布方式：复制+哈希+轮询<ul><li>复制（replication）：每个节点拥有完整表数据</li><li>哈希（hash）:对表中的列进行哈希，根据哈希值映射到指定数据节点</li><li>轮询（roundrobin）:默认创建方式，修改默认使用参数default_distribution_mode，轮番选择数据节点保存数据。</li></ul></li><li>分区方式：range+list<ul><li>设置：partition by range&#x2F;list(字段)</li><li>其他类型分类：非日志表+临时表</li><li>非日志表（unlogged）:不记录redo 日志，通过日志量的减少提高数据写性能，没有redo日志后，出现故障数据库重启无法恢复，适合于可靠性要求不高的非核心数据。</li><li>临时表：分为会话级和事务级临时表，用来保存会话或者事务中的、临时性的、过程性的数据。表定义和数据仅当前会话可见。</li></ul></li><li>约束：<ul><li>定义方法：列约束&#x2F;表约束</li><li>约束类型：主键约束+唯一约束+非空约束+default约束</li><li>检查约束（仅支持行存表）</li><li>partial cluster key(仅支持列存表)</li></ul></li><li>表操作：建表+修改+删除+查询<ul><li>建表方式：create table as :分区表不能采用此方式创建，可根据查询结果创建，表字段和select查询字段和数据类型相关，指定with no data时，不填充数据。create table like：自动从like指定来源表中，继承所有字段、数据类型和非空约束。使用includeing&#x2F;excluding继承或不继承来源表的某些属性。</li><li>修改方式：alter table</li><li>增加字段：add column column_name data_type</li><li>修改字段类型：modify column_name data_type</li><li>修改分布方式：distribute by repliction&#x2F;roundrobin&#x2F;hash(column_name)</li><li>删除列：drop column column_name</li><li>删除方式：drop table</li><li>可以添加cascade 进行级联删除</li><li>查询命令：<ul><li>元命令：\d</li><li>系统视图：pg_tables&#x2F;xxx_part_tables&#x2F;xxx_tab_partitions</li><li>系统表：pg_class&#x2F;pg_partition</li><li>系统函数：pg_get_tabledef</li></ul></li></ul></li></ol><h3 id="分区设计"><a href="#分区设计" class="headerlink" title="分区设计"></a>分区设计</h3><ol><li>分区策略：<ul><li>表数据量比较大：小表扫描耗时不大，分区表性能收益不明显，只建议对大表采取分区方式。在列存储下，每个列都是单独文件存储，最小存储单元CU可储存6w行数据，对列分区表，建议每个分区数据不小于DN数*6w。</li><li>数据有明显区间特征字段：需要根据有明显区间性字段做表分区，时间字段最常见。</li><li>业务查询有明显区间范围特征：查询数据可落在区间范围指定分区内，才能通过分区剪枝扫描查询需要的分区，提升数据扫描效率，降低数据扫描IO开销。</li></ul></li><li>分区类型：<ul><li>range:基于数值型范围划分数据，数据范围由建表时指定的分区键决定。间隔分区表在发现记录映射不到任何分区时，会根据间隔条件（interval）自动创建分区。 </li><li>list：基于值列表划分数据，仅8.1.3及以上版本支持。</li></ul></li><li>分区优势：改善查询性能+增强可用性+方便维护+均衡I&#x2F;O</li><li>分区要点：<ul><li>针对已存在的表进行分区，最好将数据迁移完后再建索引。</li><li>若数据表已存在，建议先建立分区表，然后使用非堵塞式迁移接口。</li><li>要充分发挥分区表查询优势，必须使用分区时的字段作为过滤字段。分区键条件查询，效率高</li><li>分区后没有全局唯一性，各个分区之间有重复uuid</li><li>分区字段必须是非空的，类似于案件的立案日期和结案日期就不能作为分区字段</li><li>vacuum 或者 analyze 只对主表有作用，要分析分区表，需要分析每个分区。</li><li>分区备份可单独备份各个分区，若要备份所有分区只能备份整个schema。</li><li>数据迁移到分区表后建议禁用主键，因为若主表没有执行vaccuum操作，则执行计划会全表扫描主表，耗时长。</li></ul></li></ol><h3 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h3><ol><li>索引分类：<ul><li>按照数据组织方式：Gin索引+Gist索引+Post索引+Btree索引<ul><li>GIN索引：倒排索引，可处理包含多个键的</li><li>Gist索引：适用于几何和地理等多维数据类型和集合数据</li><li>Psort索引：列存表的局部排序索引。</li><li>Btree索引：适用类似B+树结构来存储数据的键值。</li></ul></li><li>支持情况：<ul><li>行存表：btree(默认)+gin+gist</li><li>列存表：psort(默认)+bree+gin</li></ul></li><li>按照索引方式：唯一+多字段+部分+表达式<ul><li>唯一索引：唯一索引会在每次添加数据时检查表中是否有重复值，行存表Btree索引和列存表btree索引支持唯一索引，主键约束和唯一约束都在自动创建唯一索引</li><li>多字段索引：索引键值多于一个字段的索引，最多声明32个字段</li><li>部分索引：只包含表一部分数据的索引，常用于分布不一致的表，只索引其中频率高的key</li><li>表达式索引：基于表中一个或多个字段的表达式索引。</li></ul></li><li>按照基表类型分类：<ul><li>全局索引：非分区表创建的索引</li><li>索引分区：分区表创建的索引，不支持创建部分索引。</li></ul></li></ul></li><li>重建索引：<ul><li>重建索引条件：<ul><li>索引崩溃，并且不在包含有效数据；</li><li>索引臃肿，包含大量空页或者接近空页</li><li>为索引更改存储参数，并且要求更改生效。</li></ul></li><li>重建方式：reindex+alter index name rebuild</li><li>索引使用：哪些列可以创建索引<ul><li>经常需要搜索查询的列</li><li>经常需要根据范围进行搜索的列</li><li>经常需要排序的列</li><li>经常使用where子句的列</li><li>经常出现在关键字order by&#x2F;group by &#x2F;distinct后面的字段。</li></ul></li><li>索引优缺点：<ul><li>优点如下：点查询提速显著，直接定位到需要的位置，减少无效IO。多条件组合查询，过滤大量数据，缩小扫描范围。利用倒排索引加速全文检索。利用等值条件索引查询速度快的优势，结合nestloop提高多表join效率。提供主键和唯一性索引，满足业务需要。利用btree索引天然有序的特点，优化查询计划。</li><li>缺点如下：索引页面占用额外空间，导致磁盘膨胀。每次导入数据同时更新索引，影响导入性能。索引需要记录xlog,增加日志量。索引页面没有可见性，存在垃圾数据，需要定期清理。每个索引至少一个文件，增加备份恢复、扩容等操作代价。索引索引扫描的性能不一定比顺序扫描性能好，特别是优化器判断错误，导致查询性能劣化的情况下。</li></ul></li></ul></li></ol><h3 id="视图"><a href="#视图" class="headerlink" title="视图"></a>视图</h3><ol><li>虚表：只存放视图定义，不存放视图数据，数据仍然在基本表中，若基表数据发生变化，视图数据也变化。</li><li>视图管理：创建+修改+删除<ul><li>create view：创建视图</li><li>create or replace view: 替换同名视图或创建新视图</li><li>create temp view ：创建会话级临时视图</li><li>alter view：修改视图</li><li>alter view rebuild：在视图解耦下，可使用已保留的原始语句重建视图，恢复依赖关系。</li><li>drop view :删除视图。</li></ul></li><li>可更新视图：<ul><li>背景：在使用视图过程中，为确保权限问题，需要在表上都封装一层视图，对表中数据的IUDS(insert&#x2F;update&#x2F;delete&#x2F;select)通过对应视图操作完成。</li><li>更新机制：视图相当于子查询，子查询中的实际表作为需要更新的表，对该表做merge into&#x2F;insert&#x2F;update&#x2F;delete操作。</li><li>注意要点：可更新视图定义中包含where，则该条件会限制update和delete语句修改基础表上的行。</li><li>使用限制：<ul><li>视图定义的From语句中只能有一个普通表，不能是系统表、外表、DFS表、delta表、toast表、错误表。</li><li>视图中包含可更新的列，这些列是对基础表可更新列的简单引用。</li><li>视图定义中不能包含with、distinct、group by、order by、FOR update 、FOR share 、HAVING、tablesample、limit、offset子句。</li><li>视图定义中不能包含union、intersect、excep集合操作。</li><li>视图定义的选择列表不能包含聚集函数、窗口函数、返回集合的函数。</li><li>视图上不能有触发时机为instead of的触发器。</li><li>视图定义不能包含子链接。</li><li>视图定义不能包含属性为volatile的函数（函数值可以在一次表扫描内改变的函数）</li><li>视图定义不能对表的分布键所在列起别名，或将普通列起别名为分布键列名。</li><li>视图更新操作中包含returning子句时，视图定义中的列只能来自于基础表。</li><li>视图定义包含where条件，则该条件将会限制update和delete语句修改基础表上的行。如果update语句更新行后不再满足where条件，更新后通过视图将无法查询到。</li><li>在视图上执行插入、更新或删除的用户必须在视图和表上具有相应的插入。更新或删除权限。</li></ul></li></ul></li><li>视图解耦：<ul><li>背景：一般情况下，删除视图依赖对象，使用cascade级联将删除视图。重建视图依赖对象后，如果视图量大，使用create view重建视图工作量大。</li><li>解耦机制：删除对象时，不删除依赖对象的视图和其定义，仅删除依赖信息，实现不指定cascade也可删除对象的效果（临时表和临时视图除外）。视图依赖对象重建后，根据依赖对象重建前后差异，可分为自动重建、通过alter view rebuild重建或者drop view + create view重建</li><li>视图解耦设置：<ul><li>参数view_independent &#x3D; on，支持视图解耦和视图重建。</li></ul></li><li>视图重建：<ul><li>自动重建：视图引用的列名在重建后依赖对象中存在，则视图在查询时自动重建。</li><li>alter view rebuild：视图引用的列名在重建后依赖对象中存在，可执行命令重建。</li><li>drop view+create view:视图依赖表中的列被删除或重命名，通过该方式重建。</li></ul></li><li>视图建立原则：<ul><li>业务逻辑：经常使用的数据定义为视图，简化SQL编写，在逻辑上屏蔽真实表结构的变化带来的影响。</li><li>安全逻辑：视图封装只希望业务看到的数据。通过复杂视图，用户不能通过视图修改基表数据。</li></ul></li></ul></li></ol><h3 id="序列（sequence）"><a href="#序列（sequence）" class="headerlink" title="序列（sequence）"></a>序列（sequence）</h3><ol><li>自增整数序列：按照一定规则自增的整数，取值不重复，具有唯一标识性，常被用作主键。<br>  序列管理：</li><li>创建：create sequence</li><li>创建唯一标识自动方法：<ul><li>声明字段类型为序列整型来定义唯一标识符字段：在建表时，将唯一标识符字段类型定义为serial,数据库后台会自动创建一个对应的序列sequence。</li><li>创建自定义sequence并指定字段默认值：使用create sequence自定义序列，使用nextval(‘sequence_name’)函数读取的序列值，指定为某一字段默认值。好处是更灵活，可以为序列定义cache,一次预申请多个序列值，减少和GTM交互次数，来提高性能。</li></ul></li><li>创建注意事项：<ul><li>不建议同时定义cache和maxvalue或者minvalue.因为定义cache后不能保证sequence的连续性，可能产生空洞，造成sequence号段浪费。</li><li>建议cache值不要设置过大，否则会出现缓存序列号时耗时过长的问题；建议cache的值小于10000 0000（1亿）。实际使用时应根据业务设置合理的cache值，既保证快速访问，又不会浪费序列号。</li><li>通过owner by 创建的sequence不建议用于其他表，若希望多表共享sequence，则该sequence不应该从属于特定表。</li><li>为序列sequence指定关联列后u，该列删除时，对应的sequence也会被删除。虽然数据库并不限制序列只能为一列产生默认值，但是最好不要多列共用同一个序列。</li><li>当前版本只支持在定义表的时候指定自增列，或者指定某列的默认值为nextval(“sequence_name”),不支持在已有表中增加自增列或者增加默认值为nextval(“sequence_name”)的列。</li></ul></li><li>修改：alter sequence，alter sequence 语句能够更改现有的sequence的属性，包括修改拥有者、归属列和最大值。将序列和表的指定字段进行关联，在删除字段或者器所在表的的红时候会自动删除已关联的序列。</li><li>修改注意事项：<ul><li>使用alter sequence的用户必须是该序列的所有者</li><li>当前版本仅支持修改拥有者、归属列和最大值。若要修改其他参数，可以删除重建，并用setval函数恢复当前值。</li><li>alter sequence maxvalue 不支持在事务、函数和存储过程中使用。</li><li>修改序列的最大值后，会清空该序列在所有会话中的cache</li><li>alter sequence 会阻塞nextval、currval、lastval、setval的调用。</li></ul></li><li>删除：drop sequence<ul><li>用于从当前数据库里删除序列，只有序列的所有者或者系统管理员才能删除。</li></ul></li><li>序列函数：nextval+currval+lastval+setval<ul><li>nextval():用于递增序列并返回新值，返回类型为bight</li><li>注意事项：<ul><li>为避免从同一序列获取值的并发事务被阻塞，nextval操作不回滚。这种情况将在指定值的顺序中留下未使用的“空洞”。因此,Gauss(DWS)序列对象不能用于获得“无间隙”序列。</li><li>当nextval被下推到DN上时，各DN会自动连接GTM，请求next values值，由于GTM上有最大连接数为8192的限制，这类下推会消耗过多的GTM连接数，因此对于这类语句的并发数目限制为7000&#x2F;集群DN数目。</li></ul></li><li>currval():用于返回当前会话里，最近一次nextval返回的，指定的sequence数值。</li><li>注意事项：<ul><li>如果当前会话没调用过指定sequence的nextval,调用currval报错。</li><li>currval函数默认不支持，如果要使用，需要修改参数enable_beta_featuresw&#x3D; true,并且设置后，nextval函数将不支持下推，返回类型为bight.</li></ul></li><li>lastval():用于放回当前会话里，最近一次nextval返回的值。等效于currval.</li><li>注意事项：<ul><li>如果当前会话没有调度过nextval,调用lastval会报错。</li><li>astval函数默认不支持，如果要使用，需要修改参数enable_beta_features或者lastval_supported &#x3D; true.并且设置后，nextval函数不支持下推，返回类型为bight.</li></ul></li><li>setval():用于设置序列当前值和is_called标识，放回类型为bight</li><li>注意事项：<ul><li>setval使用后，会在当前会话和GTM上立刻生效。但是如果其他会话有缓存的序列值，需要等缓存值耗尽才能感知setval的作用。由于序列的非事务的，setval造成的改变不会由于事务的回滚而撤销。</li></ul></li></ul></li><li>序列注意事项：<ul><li>新sequence序列值产生依靠GTM维护，默认情况下，每申请一个sequence值都要向GTM发送一次申请，GTM在当前值基础上加上步长值，作为新值放回给调度者。</li><li>GTM是全局唯一节点，是性能瓶颈，对大量频繁产生序列号操作，不推荐产生默认序列值。</li><li>序列函数nextval、setval等不支持回滚。setval设置新值，会被当前会话nextval立即生效，但对于其他会话，若定义cache不会立即生效，必须在用尽所有缓存值后，其变动才能被其他会话感知。为避免产生重复值，使用setval设置的新值不能是已经产生的值或者在缓存中的值。</li><li>不要在bulkload的场景中产生默认序列值。如果必须要在bulkload场景下产生默认序列值，则一定要为newSeq1定义足够大的cache，并且不要定义maxvalue或者minvalue。</li><li>sequence创建后，在每个节点都维护一张单行表，存储序列定义和当前值，但此当前值非GTM上当前值，只是保存本节点和GTM交互后的状态。如果其他节点向GTM申请新值，或调用setval修改序列状态，则不刷新本节点的单行表，由于每次申请序列值都是向GTM申请，所以对序列正确性无影响。</li></ul></li><li>序列典型问题：<ul><li>如何确定sequence和哪个表有关联：先在pg_class查找目标sequence的oid, 然后在pg_depend根据oid查依赖该sequence的对象。</li><li>如何查询sequence的当前最新值：通过currval函数可以查询sequence的当前最新值。</li><li>如何解决sequence取值超出范围的问题：可以通过创建sequence时设置cycle字段，从而使得序列达到maxvalue或者minvalue后可循环并继续下去。但是需要注意，如果定义序列为cycle，则不能保证序列的唯一性。或者通过调用setval(regclass, bight)函数对序列取值进行重置。</li></ul></li></ol><h3 id="数据脱敏-对敏感数据进行屏蔽"><a href="#数据脱敏-对敏感数据进行屏蔽" class="headerlink" title="数据脱敏(对敏感数据进行屏蔽)"></a>数据脱敏(对敏感数据进行屏蔽)</h3><ol><li>敏感数据定义：指任何泄露后可能会给社会或个人带来严重危害的数据都属于常见的敏感数据</li><li>敏感数据举例：个人身份信息、企业不适合公开信息、设备信息、银行卡号、受保护的健康信息、知识产权等属于敏感信息。</li><li>数据脱敏原因：对敏感信息通过脱敏规则进行数据变形，实现敏感数据可靠保护。常见脱敏规则为：替换、重排、加密、截断、掩码等。用户可以根据期望的脱敏算法自定义脱敏规则。</li><li>数据脱敏原则：<ul><li>尽可能为脱敏后的应用，保留脱敏前有意义信息</li><li>最大程度防止黑客破解</li></ul></li><li>数据脱敏分类：动态脱敏+静态脱敏<ul><li>动态脱敏：在访问敏感数据时，实时脱敏。优势如下：<ul><li>策略可配置。可结合自身业务场景识别敏感数据，并对业务表的指定列灵活预置脱敏策略</li><li>策略可扩展。内置脱敏函数，可涵盖大部分常见脱敏效果，支持自定义脱敏函数</li><li>敏感数据可算不可见。原始敏感数据参与运算，仅在出库时刻，返回结果时才做脱敏处理</li><li>数据访问受控。脱敏策略生效条件的用户，均对原始敏感数据不可见。</li><li>全场景数据不泄露。底座交互，可减少敏感数据传输链路潜在的泄露风险，安全可靠，而且充分识别各种恶意套取潜在场景，有效防护。</li></ul></li><li>静态脱敏：数据的“搬迁仿真替换”，是将数据抽取并进行脱敏后，下发到下游环节，可随意取用和读写，脱敏后数据和生产数据隔离，从而满足业务需求的同时保障生产数据库安全。</li></ul></li><li>数据脱敏管理：<ul><li>创建：create redaction policy </li><li>修改：alter redaction policy</li><li>删除：drop redaction policy<ul><li>查看脱敏信息：系统视图redaction_policies和redaction_columns.</li></ul></li><li>函数：内置型+扩展型<ul><li>内置型脱敏函数：优先推荐<ul><li>mask_full():全脱敏成固定值，用于实现替代。是可覆盖任何数据类型的全脱敏函数，只关注表达式返回值类型，可保证脱敏数据不泄露，但会导致脱敏结</li><li>mask_partial():针对数值类型&#x2F;字符类型&#x2F;日期或时间类型的部分脱敏，用于实现数值变换&#x2F;截断&#x2F;遮挡</li></ul></li><li>扩展型脱敏函数：可使用pl&#x2F;pgsql语言自定义脱敏函数，遵从要求如下：<ul><li>返回值和脱敏列，类型一致</li><li>函数必须定位为可下推的</li><li>参数列表除脱敏格式外，只能包含一个脱敏列</li><li>函数仅实现针对特定数据类型的格式化改写。</li></ul></li></ul></li></ul></li><li>可算不可见：<ul><li>背景：在使用数据脱敏功能时，存在先对敏感数据加工计算，再输出的情况。</li><li>功能：在数据库内使用原始敏感数据参与加工计算，只在出库时对敏感数据进行脱敏。</li><li>使用条件：需要设置参数enable_redactcol_computable &#x3D; on</li><li>脱敏策略继承：<ul><li>对insert&#x2F;update&#x2F;merge into&#x2F;create table as 语句，当子查询对某个敏感字段投影时，会触发脱敏继承，从而实现包含脱敏信息的新表和源表使用相同的脱敏策略，进而避免敏感数据在新表中数据泄露的问题。</li><li>内置创建的脱敏策略，统一命名为“inherted_rp”</li><li>脱敏策略冲突处理原则：保护用户任何敏感数据不致泄露，优先于数据脱敏效果不具有原始特征，当遇到脱敏效果冲突，都提升为通用脱敏效果mask_full.</li></ul></li></ul></li><li>防护恶意套取：<ul><li>恶意套取定义：通过已知常量值和等值&#x2F;类等值判断表达式来进行套取用户隐私数据的行为。借助等值判断形式表达式的过滤条件或投影操作试探性匹配敏感信息。</li><li>恶意套取定义：通过已知常量值和等值&#x2F;类等值判断表达式来进行套取用户隐私数据的行为。借助等值判断形式表达式的过滤条件或投影操作试探性匹配敏感信息。应对策略：数据脱敏功能采用“悲观主义”模式，任何常量等值判断都有可能存在恶意套取的风险，都应当禁止。</li><li>恶意套取定义：通过已知常量值和等值&#x2F;类等值判断表达式来进行套取用户隐私数据的行为。借助等值判断形式表达式的过滤条件或投影操作试探性匹配敏感信息。禁止使用常量恶意套取场景总结：<ul><li>脱敏字段的常量等值判断表达式、复合表达式、等价表达式</li></ul></li></ul></li></ol><h3 id="审计日志"><a href="#审计日志" class="headerlink" title="审计日志"></a>审计日志</h3><ol><li>功能：用于监视并记录在数据库系统中用户的操作行为，将操作行为的结果记录到审计日志中。</li><li>作用：提高数据库安全级别，识别安全威胁。对用户访问数据库的行为进行记录和分析。可以对事故进行追溯，防止抵赖。支持对数据库操作细粒度的筛选</li><li>管理：支持语句类型和操作类型两种方式设置审计粒度。</li><li>审计日志前提条件：<ul><li>需要审计的审计项开关已开启</li><li>数据库正常运行，并且对数据库执行增删改查操作，保证在查询时段内有审计结果产生。</li><li>数据库各个节点审计日志单独记录，如果使用LVS负载管理机制，需要根据LVS日志追溯到具体的执行节点，并且直接连接该节点查询相关审计日志。</li><li>只有拥有auditadmin属性的用户才可以查看审计记录。</li></ul></li><li>审计日志使用：<ul><li>审计查询命令：使用数据库提供的SQL函数 pg_query_audit</li><li>查询所有CN节点审计日志：pgxc_query_audit()</li><li>查询单个CN节点，也可查询所有CN节点审计日志：pg_query_audit_details()</li></ul></li></ol><p>基于公开来源信息, 学习资源来自<a href="https://connect.huaweicloud.com/courses/learn/Learning/sp:cloudEdu_?courseNo=course-v1:HuaweiX+CBUCNXBC006+Self-paced&courseType=1">华为云GaussDB(DWS)数据库官网</a></p>]]></content>
      
      
      <categories>
          
          <category> 数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GaussDB(DWS) </tag>
            
            <tag> 数据库 </tag>
            
            <tag> 数据仓库 </tag>
            
            <tag> 数据 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GaussDB(DWS)数据库-基础篇</title>
      <link href="/2025/08/03/GaussDB(DWS)%E6%95%B0%E6%8D%AE%E5%BA%93-%E5%9F%BA%E7%A1%80%E7%AF%87/"/>
      <url>/2025/08/03/GaussDB(DWS)%E6%95%B0%E6%8D%AE%E5%BA%93-%E5%9F%BA%E7%A1%80%E7%AF%87/</url>
      
        <content type="html"><![CDATA[<h2 id="软件架构"><a href="#软件架构" class="headerlink" title="软件架构"></a>软件架构</h2><p>软件架构：分为存算分离型和存算一体型，二者的区别在于DN和存储（Local-Disk）是否绑定在一起，绑定在一起为存算一体，否则为存算分离。</p><h2 id="数据组件-7种类型"><a href="#数据组件-7种类型" class="headerlink" title="数据组件(7种类型)"></a>数据组件(7种类型)</h2><ol><li>OM(运维管理模块、主备)：提供日常运维和配置管理功能，每个节点都部署</li><li>CM(集群管理模块、主备)：自动化集群管理和监控各单元的物理资源使用情况，每个节点都部署。</li><li>GTM(全局事务控制器，主备)：主要负责生成并维护全局事务ID、事务快照、时间戳等需要全局唯一的信息。DWS集群部署2个，一主一备，分布在不同节点上。</li><li>WLM(工作负载管理)：控制资源分配，防止过载对系统冲击导致的业务拥塞和系统崩溃。内置在CN和DN实例中。</li><li>CN(Coordinator Node,协调节点，多主)：主要处理请求分解、调度、结果返回。负责SQL解析和优化。决定对外业务访问能力，默认部署2个，最大支持5个。</li><li>DN(Data Node,数据节点，主备从)：负责存储业务数据（支持行存、列存、混合存储）、执行数据查询任务以及向CN返回执行结果。决定对外业务处理能力。根据节点规格，每个节点部署2-4个，最大支持1024个。</li><li>GDS Loader(多实例)：负责批量数据加载和并行加速。</li></ol><p>物理集群由3到多个节点组成，最大支持1024个，节点为ECS&#x2F;BMS.<br>数据组件分布：以最简的ECS+EVS结构为例。ECS负责计算资源（CPU+内存+DWS实例（CN+DN等））。EVS负责存储资源，每个DN挂载EVS盘。</p><h2 id="DWS资源分配"><a href="#DWS资源分配" class="headerlink" title="DWS资源分配"></a>DWS资源分配</h2><ol><li>CPU资源：20%+60%+20%：20%CPU资源用于系统运维，20%CPU资源用于数据接入入库业务，60%CPU资源用于数据分析业务,入库业务和分析业务资源隔离，互不影响。</li><li>内存资源：默认GaussDB(DWS)使用内存占主机Linux系统可用内存的80%。GaussDB 200 默认关闭操作系统的虚拟内存。</li><li>内存参数：<ul><li>max_process_memory ：一个数据库节点（DN&#x2F;CN）可用的最大物理内存</li><li>视图pv_total_memory_detail：查看一个数据库节点总的内存分配情况。</li></ul></li></ol><h2 id="业务架构"><a href="#业务架构" class="headerlink" title="业务架构"></a>业务架构</h2><p>业务下发的SQL信息是如何在GaussDB(DWS)中的各个组件运行的。CN-&gt;DN-&gt;CN</p><ol><li>业务的查询信息先下发SQL到CN节点，其中的SQL信息可以是对数据的增删改查。</li><li>CN通过优化器生成执行计划，DN按照执行计划处理数据</li><li>在分布式存储中，数据处理的DN和数据存储DN不同，数据处理过程中需要从其他DN获取数据，通过stream流（广播流、聚合流和重分布流）降低数据在DN节点间的流动。</li><li>DN返回数据处理结果给CN，CN汇总结果。</li><li>CN将汇总结果返回给业务。</li></ol><h2 id="分布式架构优点"><a href="#分布式架构优点" class="headerlink" title="分布式架构优点"></a>分布式架构优点</h2><ol><li>支持按需扩展，支持2048节点的超大规模，100PB级的数据容量.</li><li>通过多层级的并行计算引擎，基于鲲鹏CPU的优化，软硬协同，性能相比于X86提升30%。</li><li>通过支持事务ACID,实现全场景数据的一致性数据保障，支持双集群容灾，全组件HA设计，来实现高可用。</li><li>兼容标准SQL 2003、JDBC和ODBC接口，全图形化的运维管理和开发工具，来实现高兼容性。</li></ol><h2 id="高性能"><a href="#高性能" class="headerlink" title="高性能"></a>高性能</h2><p>高斯数据库实现高性能的技术：全并行架构+分布式优化+行列混合引擎</p><ol><li>全并行架构：目的是解决如何利用x86的多核计算资源，如何解决鲲鹏众核的资源利用问题。解决方法：从大到小<ul><li>MPP(节点并行)：在集群内并行，通过使用分布式执行框架，支持1000以上的服务器，万级CPU的并行计算 </li><li>SMP(算子并行)：在查询内并行，通过多线程并行算法，从而实现在核心算子内的并行执行。众核支持，和NUMA架构优化。</li><li>SIMD(指令级并行)：操作数归并，通过SIMD和向量化引擎    ，实现一个指令执行一批数据的操作，指令可以是x86或者鲲鹏指令.</li><li>LLVM(动态编译)：指令数减少，通过将热点函数预编译成机器码，实现减少SQL执行指令数，从而提升性能。</li></ul></li><li>分布式优化：用于分布式架构下最优执行计划的生成。<ul><li>分布式查询重写:<ul><li>解决问题：单机SQL逻辑无法实现分布式执行的问题</li><li>解决方法：利用分布式查询重写技术，在分布式下消除NestLoop和子查询等查询瓶颈。</li></ul></li><li>分布式计划生成：<ul><li>解决问题：单机统计信息不能全面反应分布式数据特征</li><li>解决方案：基于Poisson估算模型，单点和全局cost估算模型，local和Global结合数据处理估算模型，实现单机+全局的自动统计信息收集。</li></ul></li><li>分布式倾斜处理：<ul><li>解决问题：数据倾斜导致的分布式执行出现木桶效应.</li><li>解决方案：针对静态模型，使用分布式倾斜估算模型；针对动态模型，使用动态倾斜处理方案RLBT（Runtime Load Balance Technology）</li></ul></li></ul></li><li>行列混合引擎：分为查询引擎和存储引擎。查询引擎分为行存+列存<ul><li>行存：适合高并发+短事务场景，例如点查询、数据更新、实时数据接入、并发增删改。</li><li>列存：适合分析AP场景，例如分析统计分组聚合、统计分析、批量加载、访问大量行少数列。</li><li>Delta列存：适合实时分析场景，例如实时分析同时进行实时插入和更新、实时插入更新进入行存Delta、实时分析基于列存+行存Delta<br>注意：Delta表是列存表附带的行存表，若创建列存表同时开启Delta表,插入列存表的数据也会以行存的形式保存。</li></ul></li></ol><h2 id="高扩展"><a href="#高扩展" class="headerlink" title="高扩展"></a>高扩展</h2><p>逻辑集群+异构扩展</p><ol><li>逻辑集群实现如下功能：通过使用CN+DN<ul><li>逻辑统一+业务隔离：用逻辑集群实现DN层的计算存储资源隔离，从而实现业务隔离。</li><li>数据共享：将不同逻辑集群的公共数据放到同一个逻辑集群中</li><li>计算弹性：可以利用空闲集群的计算资源用于其他业务的作业。</li></ul></li><li>异构扩展：用于冷数据的低成本管理<ul><li>功能：用本地盘做性能加速，用OBS做冷数据区，实现数据存储异构，自动冷热数据迁移（2年以上冷数据）。<br>结果：分层存储+成本最优：按需选择存储和计算引擎，实现冷热数据的动态切换。</li></ul></li></ol><h2 id="高可用"><a href="#高可用" class="headerlink" title="高可用"></a>高可用</h2><p>主备从HA技术+多租户资源管理+可信安全+多层次多类型备份</p><h3 id="主备从HA技术"><a href="#主备从HA技术" class="headerlink" title="主备从HA技术"></a>主备从HA技术</h3><p>功能：数据三重保护（主+备+从备）+容忍单副本故障+两副本提供HA保障。<br>主备流程：<br>正常情况：主机和备机通过日志+数据页流复制实现强同步，主机和从备仅保持连接，从备不占用额外存储资源<br>主机故障：集群管理器感知并仲裁备机升为主机，升级后的备机和从备进行主从强同步。<br>备机故障：主机自动感知，主机的未同步日志和数据发送给从备，实现主从强同步，主备同步利用内核底层实现主从同步切换，事务层不感知</p><h3 id="多租户资源管理"><a href="#多租户资源管理" class="headerlink" title="多租户资源管理"></a>多租户资源管理</h3><p>和企业组织结构匹配+管理租户资源（计算+存储）+租户资源隔离（容器技术）+租户资源监控</p><h3 id="多层级多类型备份"><a href="#多层级多类型备份" class="headerlink" title="多层级多类型备份"></a>多层级多类型备份</h3><p>多种介质：云备份推荐使用OBS备份，支持OBS&#x2F;NBU&#x2F;华为数据一体机<br>全量+增量备份：全量物理备份、差异增量、累积增量等类型备份<br>完全在线：备份期间不加锁，业务SQL无影响<br>全局一致性：备份全局一致性快照<br>细颗粒备份恢复：支持集群+schema级+表级备份恢复，支持就地集群恢复。<br>安全：加密传输。</p><h2 id="融合分析"><a href="#融合分析" class="headerlink" title="融合分析"></a>融合分析</h2><p>支持直接读写HDFS&#x2F;OBS&#x2F;PostGIS数据：<br>数据源互通：可以读取Oracle&#x2F;Spark&#x2F;Hive数据库<br>外表机制：支持HDFS&#x2F;OBS&#x2F;MPP外表，读取HDFS&#x2F;OBS数据。<br>兼容性：兼容SQL2003、JDBC&#x2F;ODBC、SQL2003访问HDFS和OBS</p><h2 id="智能运维"><a href="#智能运维" class="headerlink" title="智能运维"></a>智能运维</h2><p>适应场景：支持扩容加节点+扩容重分布+空间回收Vacuum full<br>快照策略：手动快照+自动快照<br>存储介质选择：OBS + NBU</p><p>学习资源来自<a href="https://connect.huaweicloud.com/courses/learn/Learning/sp:cloudEdu_?courseNo=course-v1:HuaweiX+CBUCNXBC006+Self-paced&courseType=1">华为云GaussDB(DWS)数据库官网</a></p>]]></content>
      
      
      <categories>
          
          <category> 数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GaussDB(DWS) </tag>
            
            <tag> 数据库 </tag>
            
            <tag> 数据仓库 </tag>
            
            <tag> 数据 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2025/04/25/hello-world/"/>
      <url>/2025/04/25/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      <categories>
          
          <category> 测试 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Typora </tag>
            
            <tag> Markdown </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
